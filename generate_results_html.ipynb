{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# 1) Family assignments\n",
    "##############################################################################\n",
    "# Note: You said “gemma & gemini are both google.” So any model name \n",
    "# containing \"gemma\" or \"gemini\" is also mapped to Google in this dict.\n",
    "\n",
    "from model_name_subs import MODEL_NAME_SUBS\n",
    "\n",
    "model_to_family = {\n",
    "    'google/gemini-2.0-flash-001': 'Google',\n",
    "    'anthropic/claude-3.7-sonnet': 'Anthropic',\n",
    "    'anthropic/claude-3.5-sonnet': 'Anthropic',\n",
    "    'deepseek/deepseek-chat-v3-0324': 'DeepSeek',\n",
    "    'google/gemma-2-9b-it': 'Google',\n",
    "    'deepseek/deepseek-r1': 'DeepSeek',\n",
    "    'anthropic/claude-3.5-haiku-20241022': 'Anthropic',\n",
    "    'openai/gpt-4o-mini': 'OpenAI',\n",
    "    'openai/gpt-4.5-preview': 'OpenAI',\n",
    "    'mistralai/mistral-small-3.1-24b-instruct-2503': 'Mistral',\n",
    "    'meta-llama/llama-3.1-8b-instruct': 'Meta-Llama',\n",
    "    'meta-llama/llama-3.1-70b-instruct': 'Meta-Llama',\n",
    "    'meta-llama/llama-3.1-405b-instruct': 'Meta-Llama',\n",
    "    'google/gemma-3-27b-it': 'Google',\n",
    "    'qwen/qwq-32b': 'Qwen',\n",
    "    'openai/chatgpt-4o-latest': 'OpenAI',\n",
    "    'cohere/command-a': 'Cohere',\n",
    "    'mistralai/mistral-nemo': 'Mistral',\n",
    "    'mistralai/mistral-small-24b-instruct-2501': 'Mistral',\n",
    "    'meta-llama/llama-3.2-3b-instruct': 'Meta-Llama',\n",
    "    'gemini-2.5-pro-exp-03-25': 'Google',  # 'gemini' => Google\n",
    "    'google/gemma-3-4b-it': 'Google',\n",
    "    'google/gemma-3-12b-it': 'Google',\n",
    "    'sam-paech/Darkest-muse-v1': 'Sam-Paech',\n",
    "    'ifable/gemma-2-Ifable-9B': 'Google',  # 'gemma' => Google\n",
    "    'ToastyPigeon/Gemma-3-Starshine-12B': 'Google',  # 'Gemma' => Google\n",
    "    'allura-org/Gemma-3-Glitter-12B': 'Google',       # 'Gemma' => Google\n",
    "    'liquid/lfm-7b': 'Liquid',\n",
    "    'chatgpt-4o-latest': 'OpenAI',\n",
    "    'anthropic/claude-3-haiku': 'Anthropic',\n",
    "    'rekaai/reka-flash-3:free': 'Reka',\n",
    "    'meta-llama/llama-3.2-1b-instruct': 'Meta-Llama',\n",
    "    'google/gemma-3-4b-it:free': 'Google',\n",
    "    'x-ai/grok-3-beta': 'grok-3-beta',\n",
    "    'x-ai/grok-3-mini-beta': 'grok-3-mini-beta',\n",
    "}\n",
    "\n",
    "##############################################################################\n",
    "# Family colors to match the above\n",
    "##############################################################################\n",
    "family_colors = {\n",
    "    'Google':     '#8a5cf5',\n",
    "    'Anthropic':  '#ffc13b',\n",
    "    'DeepSeek':   '#1eb980',\n",
    "    'OpenAI':     '#ff5c8d',\n",
    "    'Mistral':    '#ff6e40',\n",
    "    'Meta-Llama': '#1e3d59',\n",
    "    'Qwen':       '#b2df8a',\n",
    "    'Cohere':     '#bebada',\n",
    "    'Sam-Paech':  '#f28e2c',\n",
    "    'Liquid':     '#767676',\n",
    "    'Reka':       '#fb8072',\n",
    "    # If not in dictionary, default to \"Other\"\n",
    "    'Other':      '#cccccc'\n",
    "}\n",
    "\n",
    "\n",
    "MODELS_TO_IGNORE = [\n",
    "        'mistralai/ministral-3b',\n",
    "        'ministral-3b',\n",
    "        'google/gemma-3-4b-it:free'\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Available Models ---\n",
      "Available models (sorted by ELO):\n",
      "1. o3 (ELO: 1774)\n",
      "2. DeepSeek R1 (ELO: 1623)\n",
      "3. DeepSeek Chat v3 (ELO: 1488)\n",
      "4. ChatGPT-4o Latest (ELO: 1480)\n",
      "5. openai/gpt-4.1 (ELO: 1449)\n",
      "6. openrouter/optimus-alpha (ELO: 1429)\n",
      "7. Gemini 2.5 Pro Exp (ELO: 1406)\n",
      "8. Claude 3.5 Sonnet (ELO: 1391)\n",
      "9. ChatGPT-4o Latest (ELO: 1384)\n",
      "10. openrouter/quasar-alpha (ELO: 1379)\n",
      "11. Reka Flash 3 (Free) (ELO: 1377)\n",
      "12. QwQ 32B (ELO: 1366)\n",
      "13. Claude 3.7 Sonnet (ELO: 1363)\n",
      "14. Gemma 3 27B (ELO: 1275)\n",
      "15. GPT-4.5 Preview (ELO: 1239)\n",
      "16. Grok 3 Beta (ELO: 1207)\n",
      "17. openai/gpt-4.1-mini (ELO: 1205)\n",
      "18. Command A (ELO: 1189)\n",
      "19. Claude 3.5 Haiku (ELO: 1177)\n",
      "20. Darkest Muse v1 (ELO: 1168)\n",
      "21. Gemma 3 12B (ELO: 1155)\n",
      "22. Gemma 3 Glitter 12B (ELO: 1149)\n",
      "23. Gemini 2.0 Flash (ELO: 1148)\n",
      "24. Gemma 3 4B (ELO: 1098)\n",
      "25. Gemma 2 Ifable 9B (ELO: 1059)\n",
      "26. accounts/fireworks/models/deepseek-v3 (ELO: 1057)\n",
      "27. openai/gpt-4.1-nano (ELO: 953)\n",
      "28. mistralai/mistral-large-2411 (ELO: 952)\n",
      "29. mistralai/pixtral-large-2411 (ELO: 931)\n",
      "30. Gemma 3 Starshine 12B (ELO: 859)\n",
      "31. Mistral Nemo (ELO: 855)\n",
      "32. GPT-4o Mini (ELO: 841)\n",
      "33. Llama 3.1 405B (ELO: 822)\n",
      "34. meta-llama/llama-4-maverick (ELO: 816)\n",
      "35. Gemma 2 9B (ELO: 807)\n",
      "36. LFM 7B (ELO: 728)\n",
      "37. Llama 3.1 70B (ELO: 691)\n",
      "38. meta-llama/llama-4-scout (ELO: 669)\n",
      "39. Mistral Small 3.1 24B (ELO: 661)\n",
      "40. openai/gpt-4-0314 (ELO: 625)\n",
      "41. Llama 3.1 8B (ELO: 583)\n",
      "42. Mistral Small 24B (ELO: 581)\n",
      "43. Claude 3 Haiku (ELO: 562)\n",
      "44. Llama 3.2 3B (ELO: 460)\n",
      "45. openai/gpt-3.5-turbo-0613 (ELO: 270)\n",
      "46. Llama 3.2 1B (ELO: 24)\n",
      "------------------------\n",
      "\n",
      "Calculating aggregated metrics and N-grams...\n",
      "Extracting text from runs (grouped by prompt)...\n",
      "Extracted text for 47 models from 47 runs.\n",
      "Calculating metrics and extracting N-grams per model...\n",
      "\n",
      "  Processing anthropic/claude-3.7-sonnet (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for anthropic/claude-3.7-sonnet: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for anthropic/claude-3.7-sonnet: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for anthropic/claude-3.7-sonnet: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6327, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: thornfield (2695.6x), flickered (1842.2x), gestured (1333.6x), viewport (1247.5x), dismissively (1089.6x), zora (973.3x), materializes (872.4x), squinted (846.3x), murmured (806.2x), hissed (749.1x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing anthropic/claude-3.5-sonnet (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for anthropic/claude-3.5-sonnet: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for anthropic/claude-3.5-sonnet: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for anthropic/claude-3.5-sonnet: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 4921, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: flickered (2263.7x), absently (1997.9x), gestured (1248.6x), buzzes (1158.7x), mari (717.0x), muttered (655.7x), ached (646.8x), dreads (520.4x), tightens (442.4x), grins (419.1x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing google/gemini-2.0-flash-001 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for google/gemini-2.0-flash-001: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for google/gemini-2.0-flash-001: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for google/gemini-2.0-flash-001: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6208, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (77860.8x), datapad (12926.5x), rasped (4118.2x), glinting (2043.8x), flickered (1810.7x), stammered (1695.0x), gestured (1507.5x), grunted (1340.0x), crackled (1257.7x), vibrated (1251.0x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing deepseek/deepseek-chat-v3-0324 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for deepseek/deepseek-chat-v3-0324: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for deepseek/deepseek-chat-v3-0324: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for deepseek/deepseek-chat-v3-0324: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 4414, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: veyra (986931663.5x), exhaled (4116.8x), flickered (3310.5x), exhales (2797.2x), smirked (1924.7x), hums (1803.0x), stilled (1689.5x), glinting (1609.6x), smirks (1603.6x), hummed (1599.8x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing google/gemma-2-9b-it (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for google/gemma-2-9b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for google/gemma-2-9b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for google/gemma-2-9b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 4120, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: aethel (220539586.9x), elara (88673.5x), kaito (4350.8x), stammered (3894.7x), crackled (2980.3x), glinting (2235.2x), flickered (2002.3x), crackles (1982.0x), cloying (1696.5x), purred (1413.7x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing deepseek/deepseek-r1 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for deepseek/deepseek-r1: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for deepseek/deepseek-r1: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for deepseek/deepseek-r1: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5352, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: veyra (1375598086.1x), talis (11406.3x), thrummed (10808.8x), thrums (9677.8x), guttered (9201.3x), rasped (8821.3x), kael (7390.1x), glinted (6543.6x), glints (2975.6x), memetic (2942.6x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing anthropic/claude-3.5-haiku-20241022 (Responses from 30 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for anthropic/claude-3.5-haiku-20241022: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for anthropic/claude-3.5-haiku-20241022: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for anthropic/claude-3.5-haiku-20241022: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 4016, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: memetic (6102.5x), flickered (4665.3x), keter (2658.8x), hummed (2296.9x), imperceptibly (1663.3x), murmured (1191.5x), muttered (978.6x), millisecond (956.6x), tendrils (793.2x), voss (754.3x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing openai/gpt-4o-mini (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for openai/gpt-4o-mini: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for openai/gpt-4o-mini: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for openai/gpt-4o-mini: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5999, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (19972.4x), glinted (3906.7x), glinting (3015.8x), shimmered (2875.9x), flickered (2865.6x), thrumming (2058.2x), crackled (1809.5x), keter (1674.4x), hargrove (1639.6x), creaked (1623.1x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing openai/gpt-4.5-preview (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for openai/gpt-4.5-preview: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for openai/gpt-4.5-preview: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for openai/gpt-4.5-preview: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6451, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: rasped (3661.8x), conspiratorially (3152.7x), murmured (2086.8x), flickered (1932.1x), shimmered (1599.7x), glinting (1537.7x), appreciatively (1458.7x), uncertainly (1379.3x), shyly (1337.3x), skeptically (1313.6x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing mistralai/mistral-small-3.1-24b-instruct-2503 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for mistralai/mistral-small-3.1-24b-instruct-2503: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for mistralai/mistral-small-3.1-24b-instruct-2503: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for mistralai/mistral-small-3.1-24b-instruct-2503: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 7900, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (133027.4x), kael (5141.6x), flickered (3978.4x), steeling (3406.7x), gleamed (1389.2x), foghorn (1357.9x), sparkled (1092.4x), furrowed (1054.0x), unreadable (1034.4x), creaked (1016.6x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing meta-llama/llama-3.1-8b-instruct (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for meta-llama/llama-3.1-8b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for meta-llama/llama-3.1-8b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for meta-llama/llama-3.1-8b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 4709, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (18732.3x), glinting (5895.8x), kael (3804.3x), creaked (3008.9x), crinkling (2549.9x), flickered (1873.2x), gleamed (1569.8x), sparkled (1543.0x), wafted (1485.9x), beeped (1238.9x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing meta-llama/llama-3.1-70b-instruct (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for meta-llama/llama-3.1-70b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for meta-llama/llama-3.1-70b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for meta-llama/llama-3.1-70b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 4502, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (11374.4x), glinting (7900.6x), sparkled (2498.5x), flickered (2022.1x), gleamed (1977.1x), wafted (1604.0x), akira (1541.8x), glint (1089.9x), lyra (1055.1x), hesitated (1001.5x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing meta-llama/llama-3.1-405b-instruct (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for meta-llama/llama-3.1-405b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for meta-llama/llama-3.1-405b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for meta-llama/llama-3.1-405b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 4531, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (24231.4x), mirthless (9999.5x), kaelin (8625.3x), glinting (6422.4x), wafted (1820.9x), amnesiac (1684.8x), flickered (1657.9x), elyria (1506.9x), sparkled (1400.7x), scavenged (1285.3x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing google/gemma-3-27b-it (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for google/gemma-3-27b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for google/gemma-3-27b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for google/gemma-3-27b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 7049, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: kaelen (677452777.6x), xylos (119550490.2x), unsettlingly (4919.8x), valerius (3664.4x), sunstone (1826.5x), thrum (1708.5x), hellhound (1565.4x), keter (1494.9x), stammered (1451.5x), hemlock (1431.1x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing qwen/qwq-32b (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for qwen/qwq-32b: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for qwen/qwq-32b: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for qwen/qwq-32b: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6126, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: veyra (359092214.9x), thrums (6197.9x), glinting (3720.3x), flickered (3539.7x), hissed (3257.6x), glinted (3143.0x), kael (2201.3x), kestrel (2109.9x), flinches (1809.0x), throbbed (1766.8x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing openai/chatgpt-4o-latest (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for openai/chatgpt-4o-latest: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for openai/chatgpt-4o-latest: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for openai/chatgpt-4o-latest: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5622, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: exhales (4580.4x), exhaled (4112.2x), flickered (2439.5x), shimmered (2262.2x), smirked (2256.4x), smirks (2100.8x), gestured (1978.0x), unreadable (1924.4x), gleamed (1744.5x), murmured (1662.2x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing cohere/command-a (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for cohere/command-a: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for cohere/command-a: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for cohere/command-a: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6691, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: kaira (10013.0x), creaked (1844.8x), flickered (1579.2x), smirks (1487.4x), bioluminescent (1295.3x), crackled (1234.0x), unreadable (1119.3x), glinting (1096.9x), lila (869.7x), twitched (853.4x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing mistralai/mistral-nemo (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for mistralai/mistral-nemo: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for mistralai/mistral-nemo: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for mistralai/mistral-nemo: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 7013, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (74827.9x), drawled (2214.5x), kael (1700.3x), flickered (1439.0x), glinting (1374.3x), hummed (1264.4x), steeling (1245.2x), coiling (1017.0x), stammered (979.7x), grunted (774.5x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing mistralai/mistral-small-24b-instruct-2501 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for mistralai/mistral-small-24b-instruct-2501: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for mistralai/mistral-small-24b-instruct-2501: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for mistralai/mistral-small-24b-instruct-2501: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 7660, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (26078.6x), steeling (6393.8x), flickered (2347.1x), kael (1733.3x), creaked (1523.2x), crackles (1396.3x), lyra (1088.6x), trickling (932.5x), tensing (887.7x), nodded (867.1x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing meta-llama/llama-3.2-3b-instruct (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for meta-llama/llama-3.2-3b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for meta-llama/llama-3.2-3b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for meta-llama/llama-3.2-3b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 4759, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (35257.4x), glinting (7702.4x), crinkling (2889.9x), sparkled (1998.6x), flickered (1933.5x), kael (1847.8x), wafted (1804.3x), gleamed (1525.0x), glint (1177.0x), shiver (1122.2x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing gemini-2.5-pro-exp-03-25 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for gemini-2.5-pro-exp-03-25: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for gemini-2.5-pro-exp-03-25: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for gemini-2.5-pro-exp-03-25: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 7886, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: kaelen (533131545.9x), thrummed (6216.1x), unnervingly (3672.1x), unsettlingly (3184.8x), valerius (2372.1x), memetic (2115.3x), thrum (2027.6x), conspiratorially (1965.5x), flickered (1806.8x), griz (1693.7x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing unsloth/gemma-3-12b-it (Responses from 11 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for unsloth/gemma-3-12b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 279 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for unsloth/gemma-3-12b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for unsloth/gemma-3-12b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6843, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: squeak (3963.9x), unsettling (2054.2x), radiating (1604.4x), flicker (1589.6x), tremor (1532.8x), relentless (883.1x), crumbling (880.4x), paused (715.3x), gaze (628.2x), defiance (568.5x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing google/gemma-3-4b-it (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for google/gemma-3-4b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for google/gemma-3-4b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for google/gemma-3-4b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6509, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: xylos (428054705.4x), veridia (235430088.0x), elara (11659.1x), seraphina (9929.1x), unsettlingly (7266.4x), slicking (4353.1x), veridian (4063.8x), prickle (2829.7x), unnervingly (2665.8x), shimmered (2206.5x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing google/gemma-3-12b-it (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for google/gemma-3-12b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for google/gemma-3-12b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for google/gemma-3-12b-it: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 7150, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: oakhaven (217138119.6x), xylosian (197398290.5x), elara (95242.8x), unsettlingly (6701.8x), unnervingly (2458.7x), kenji (2448.8x), thimbles (1877.0x), humorless (1664.8x), shimmered (1526.3x), thrum (1481.0x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing sam-paech/Darkest-muse-v1 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for sam-paech/Darkest-muse-v1: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for sam-paech/Darkest-muse-v1: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for sam-paech/Darkest-muse-v1: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 8184, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: rasped (12780.6x), prickle (7625.2x), woodsmoke (5245.3x), elara (4816.7x), prickling (4015.1x), rasp (3575.6x), glinted (3385.9x), lamplight (3197.8x), kaito (2905.3x), rasping (2777.3x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing ifable/gemma-2-Ifable-9B (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for ifable/gemma-2-Ifable-9B: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for ifable/gemma-2-Ifable-9B: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for ifable/gemma-2-Ifable-9B: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5324, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: kaelen (406949444.4x), xylos (375645640.9x), elara (53594.1x), aethelred (22870.4x), thrummed (16971.9x), fathomless (8064.2x), kaito (7921.8x), rasped (6463.9x), thrum (6039.3x), throbbed (3465.4x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing ToastyPigeon/Gemma-3-Starshine-12B (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for ToastyPigeon/Gemma-3-Starshine-12B: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for ToastyPigeon/Gemma-3-Starshine-12B: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for ToastyPigeon/Gemma-3-Starshine-12B: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 7973, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (20462.4x), stammered (1523.7x), flickered (1470.7x), gestured (1064.7x), evangeline (948.1x), grunted (946.5x), unreadable (906.4x), foghorn (821.7x), nodded (812.1x), rhys (805.3x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing allura-org/Gemma-3-Glitter-12B (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for allura-org/Gemma-3-Glitter-12B: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for allura-org/Gemma-3-Glitter-12B: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for allura-org/Gemma-3-Glitter-12B: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 7934, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: kaelen (486077355.7x), xylos (190958961.2x), elara (84435.3x), chronal (8902.5x), unsettlingly (3214.8x), shimmered (2237.1x), valerius (1696.1x), gestured (1369.2x), unreadable (1332.2x), stammered (1149.7x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing liquid/lfm-7b (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for liquid/lfm-7b: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for liquid/lfm-7b: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for liquid/lfm-7b: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6230, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (35842.6x), kael (5924.2x), glinted (3359.4x), crinkling (2168.4x), glinting (2074.7x), crackled (1926.5x), flickered (1450.8x), cacophony (1293.3x), flicker (1166.2x), clinking (1061.2x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing chatgpt-4o-latest (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for chatgpt-4o-latest: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for chatgpt-4o-latest: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for chatgpt-4o-latest: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5956, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: shimmered (3317.8x), flickered (2094.7x), gleamed (1628.2x), exhales (1282.5x), creaked (1276.7x), hums (1085.0x), blinked (1076.7x), hissed (962.9x), gestured (791.2x), squinted (788.9x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing anthropic/claude-3-haiku (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for anthropic/claude-3-haiku: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for anthropic/claude-3-haiku: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for anthropic/claude-3-haiku: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5008, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: whirred (4415.6x), furrowing (3198.6x), furrowed (2683.9x), murmured (2227.5x), glinting (1934.3x), gestured (1612.8x), purred (1573.0x), stammered (1516.7x), placating (1331.5x), amara (1139.8x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing rekaai/reka-flash-3:free (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for rekaai/reka-flash-3:free: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for rekaai/reka-flash-3:free: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for rekaai/reka-flash-3:free: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5225, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: veyra (1820691275.4x), vorne (264293894.8x), elara (19425.0x), thrums (6652.5x), drawled (5275.3x), krell (4552.9x), glinted (3855.5x), hissed (3717.2x), flickered (3313.7x), shimmered (2270.6x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing meta-llama/llama-3.2-1b-instruct (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for meta-llama/llama-3.2-1b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for meta-llama/llama-3.2-1b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for meta-llama/llama-3.2-1b-instruct: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5290, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (21951.0x), glinting (4971.9x), arachne (4505.7x), crinkling (3117.9x), kael (2960.3x), erebus (1984.5x), creaked (1783.8x), twinge (1664.1x), flickered (1622.5x), unease (1464.3x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing openai/gpt-3.5-turbo-0613 (Responses from 31 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for openai/gpt-3.5-turbo-0613: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for openai/gpt-3.5-turbo-0613: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for openai/gpt-3.5-turbo-0613: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 3400, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: flickered (2873.6x), stammered (2139.7x), glint (1755.4x), unease (1684.0x), smirks (1450.0x), dimly (1122.1x), unreadable (1106.9x), lurked (992.6x), flickering (944.9x), unfazed (917.0x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing openai/gpt-4-0314 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for openai/gpt-4-0314: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for openai/gpt-4-0314: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for openai/gpt-4-0314: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5378, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: renn (2930.4x), stammered (2060.1x), creaked (1414.0x), smirks (1357.2x), glinting (1226.1x), foghorn (1166.5x), flickered (1109.5x), murmured (1045.9x), hesitated (928.9x), hesitates (682.2x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing openrouter/quasar-alpha (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for openrouter/quasar-alpha: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for openrouter/quasar-alpha: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for openrouter/quasar-alpha: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6671, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: prickled (6894.8x), prickling (3674.5x), shimmered (3163.1x), thudded (3154.9x), flickered (1910.1x), unbothered (1409.0x), smirks (1392.2x), crackled (1382.1x), lounged (1315.4x), crackles (1102.9x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing mistralai/mistral-large-2411 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for mistralai/mistral-large-2411: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for mistralai/mistral-large-2411: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for mistralai/mistral-large-2411: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5641, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: vespera (730816078.0x), elara (33175.8x), kael (8260.2x), flickered (3317.6x), smirks (1658.0x), creaked (1550.2x), misting (1291.8x), astrid (1122.0x), grins (847.6x), buzzes (833.6x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing meta-llama/llama-4-scout (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for meta-llama/llama-4-scout: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for meta-llama/llama-4-scout: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for meta-llama/llama-4-scout: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6966, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: glinting (4888.0x), twinkled (3831.1x), crinkling (3764.5x), fidgeted (3626.2x), kael (2078.8x), creaked (1557.6x), flickered (1481.5x), unease (1262.9x), wafted (1057.6x), wariness (1057.6x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing meta-llama/llama-4-maverick (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for meta-llama/llama-4-maverick: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for meta-llama/llama-4-maverick: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for meta-llama/llama-4-maverick: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5298, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: steepling (160115283.0x), elara (70608.6x), glinting (4868.4x), wariness (3294.6x), crinkling (2261.5x), flickered (2180.6x), wafted (1812.0x), unease (1504.7x), beeped (1255.8x), throaty (1226.9x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing x-ai/grok-3-beta (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for x-ai/grok-3-beta: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for x-ai/grok-3-beta: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for x-ai/grok-3-beta: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 7022, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: vorn (19231.9x), glinted (4068.0x), glinting (3768.4x), thudded (3345.4x), drawled (3339.7x), shimmered (2635.3x), memetic (2286.7x), flickered (1880.8x), kael (1816.3x), viewport (1481.9x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing openrouter/optimus-alpha (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for openrouter/optimus-alpha: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for openrouter/optimus-alpha: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for openrouter/optimus-alpha: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5937, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: prickling (2862.5x), flickered (2418.1x), shimmered (1848.1x), lamplight (1646.5x), glinting (1453.5x), grinned (1096.7x), gestured (1077.3x), scavenged (1054.5x), grins (1048.7x), flickers (1023.1x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing mistralai/pixtral-large-2411 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for mistralai/pixtral-large-2411: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for mistralai/pixtral-large-2411: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for mistralai/pixtral-large-2411: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6244, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (29272.4x), kael (10870.7x), kaito (6755.3x), flickered (2341.8x), creaked (1172.4x), stammered (1138.8x), smirks (1125.4x), glinting (1016.6x), twitched (1004.4x), crackles (948.3x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing openai/gpt-4.1-mini (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for openai/gpt-4.1-mini: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for openai/gpt-4.1-mini: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for openai/gpt-4.1-mini: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5606, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: flickered (3948.6x), gleamed (2941.4x), shimmered (2179.5x), glinting (1795.8x), scavenged (1776.6x), creaked (1537.6x), twitched (1467.8x), flickering (1063.4x), steadying (950.2x), flicker (882.1x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing openai/gpt-4.1 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for openai/gpt-4.1: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for openai/gpt-4.1: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for openai/gpt-4.1: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 5997, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: flickered (3128.4x), callused (2895.5x), shimmered (1828.4x), glinting (1597.8x), unblinking (1538.0x), creaked (1504.8x), gestured (1132.4x), pipette (1114.2x), grunted (1114.2x), scavenged (1043.2x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing openai/gpt-4.1-nano (Responses from 31 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for openai/gpt-4.1-nano: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for openai/gpt-4.1-nano: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for openai/gpt-4.1-nano: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6190, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: prickled (7280.5x), flickered (5126.5x), shimmered (5010.0x), prickling (3880.0x), flickering (2166.5x), gleamed (1502.5x), flicker (1371.3x), smirks (1357.0x), glinting (1313.4x), flickers (1176.6x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing o3 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for o3: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for o3: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for o3: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 7864, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: clanged (5541.5x), rasped (4239.2x), glimmered (3256.2x), shimmered (1851.9x), flagstones (1767.6x), keter (1347.8x), flickered (1258.2x), flickers (1258.2x), hissed (1250.6x), lamplight (1237.4x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "  Processing accounts/fireworks/models/deepseek-v3 (Responses from 32 prompts)...\n",
      "      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\n",
      "      Extracting 2-grams...      ERROR calculating N-grams for accounts/fireworks/models/deepseek-v3: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "      Extracting top repetitive words (multi-prompt)...\n",
      "        Found 1000 repetitive words meeting criteria.\n",
      "      Calculating other metrics (length, vocab, slop)...\n",
      "      ERROR calculating vocab complexity for accounts/fireworks/models/deepseek-v3: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Loaded 1000 items from data/slop_list.json\n",
      "Loaded 200 items from data/slop_list_bigrams.json\n",
      "Loaded 200 items from data/slop_list_trigrams.json\n",
      "      ERROR calculating slop score for accounts/fireworks/models/deepseek-v3: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\eirik/nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\eirik\\\\git\\\\creative-writing-bench-hill-climb\\\\venv\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\eirik\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "    Metrics - Avg Len: 6564, Vocab K: Error, Slop: Error, Repetition (multi-prompt): Error\n",
      "    Top multi-prompt repetitive words: elara (25503.9x), eira (7512.2x), kael (3310.4x), overanalyzing (3063.6x), creaked (2347.3x), unreadable (1952.9x), flickered (1854.8x), gleamed (1381.7x), keter (1277.3x), glinting (1073.6x)\n",
      "    No bigrams met the multi-prompt criteria.\n",
      "    No trigrams met the multi-prompt criteria.\n",
      "\n",
      "Merging metrics with ELO data...\n",
      "  Note: Model 'unsloth/gemma-3-12b-it' found in runs but not in ELO data. Added entry.\n",
      "\n",
      "Normalizing ELO scores...\n",
      "  Normalized ELO scores for 46 models using anchor models.\n",
      "\n",
      "--- Aggregated Metrics Results (CSV Format) ---\n",
      "model_name,elo_score,creative_writing_score,avg_length,vocab_complexity,slop_score,repetition_score\n",
      "o3,1622.3,17.53,7864,Error,Error,Error\n",
      "DeepSeek R1,1500.0,17.09,5352,Error,Error,Error\n",
      "DeepSeek Chat v3,1390.1,16.32,4414,Error,Error,Error\n",
      "ChatGPT-4o Latest,1383.1,16.98,5956,Error,Error,Error\n",
      "openai/gpt-4.1,1358.1,16.80,5997,Error,Error,Error\n",
      "openrouter/optimus-alpha,1341.9,16.75,5937,Error,Error,Error\n",
      "Gemini 2.5 Pro Exp,1323.6,17.20,7886,Error,Error,Error\n",
      "Claude 3.5 Sonnet,1311.4,15.63,4921,Error,Error,Error\n",
      "ChatGPT-4o Latest,1305.8,16.35,5622,Error,Error,Error\n",
      "openrouter/quasar-alpha,1301.4,16.69,6671,Error,Error,Error\n",
      "Reka Flash 3 (Free),1300.1,16.00,5225,Error,Error,Error\n",
      "QwQ 32B,1290.8,16.48,6126,Error,Error,Error\n",
      "Claude 3.7 Sonnet,1288.0,16.60,6327,Error,Error,Error\n",
      "Gemma 3 27B,1216.9,16.39,7049,Error,Error,Error\n",
      "GPT-4.5 Preview,1187.4,16.31,6451,Error,Error,Error\n",
      "Grok 3 Beta,1161.6,16.64,7022,Error,Error,Error\n",
      "openai/gpt-4.1-mini,1160.3,15.35,5606,Error,Error,Error\n",
      "Command A,1147.0,16.10,6691,Error,Error,Error\n",
      "Claude 3.5 Haiku,1137.1,12.64,4016,Error,Error,Error\n",
      "Darkest Muse v1,1129.5,16.04,8184,Error,Error,Error\n",
      "Gemma 3 12B,1119.3,15.98,7150,Error,Error,Error\n",
      "Gemma 3 Glitter 12B,1114.4,15.74,7934,Error,Error,Error\n",
      "Gemini 2.0 Flash,1113.6,15.68,6208,Error,Error,Error\n",
      "Gemma 3 4B,1072.8,15.94,6509,Error,Error,Error\n",
      "Gemma 2 Ifable 9B,1041.7,15.26,5324,Error,Error,Error\n",
      "accounts/fireworks/models/deepseek-v3,1040.1,15.87,6564,Error,Error,Error\n",
      "openai/gpt-4.1-nano,954.8,14.54,6190,Error,Error,Error\n",
      "mistralai/mistral-large-2411,954.4,13.42,5641,Error,Error,Error\n",
      "mistralai/pixtral-large-2411,937.1,13.55,6244,Error,Error,Error\n",
      "Gemma 3 Starshine 12B,878.8,12.48,7973,Error,Error,Error\n",
      "Mistral Nemo,875.7,12.40,7013,Error,Error,Error\n",
      "GPT-4o Mini,863.9,14.06,5999,Error,Error,Error\n",
      "Llama 3.1 405B,849.0,11.53,4531,Error,Error,Error\n",
      "meta-llama/llama-4-maverick,843.8,12.25,5298,Error,Error,Error\n",
      "Gemma 2 9B,836.3,11.16,4120,Error,Error,Error\n",
      "LFM 7B,772.2,11.99,6230,Error,Error,Error\n",
      "Llama 3.1 70B,742.2,10.84,4502,Error,Error,Error\n",
      "meta-llama/llama-4-scout,724.6,11.00,6966,Error,Error,Error\n",
      "Mistral Small 3.1 24B,718.0,10.16,7900,Error,Error,Error\n",
      "openai/gpt-4-0314,688.7,12.15,5378,Error,Error,Error\n",
      "Llama 3.1 8B,654.5,10.56,4709,Error,Error,Error\n",
      "Mistral Small 24B,652.6,10.10,7660,Error,Error,Error\n",
      "Claude 3 Haiku,637.3,11.43,5008,Error,Error,Error\n",
      "Llama 3.2 3B,554.3,9.28,4759,Error,Error,Error\n",
      "openai/gpt-3.5-turbo-0613,399.5,8.72,3400,Error,Error,Error\n",
      "Llama 3.2 1B,200.0,7.27,5290,Error,Error,Error\n",
      "unsloth/gemma-3-12b-it,N/A,0.00,6843,Error,Error,Error\n",
      "\n",
      "Saving updated ELO data with metrics (and N-grams) to elo_results_with_metrics_repro.json...\n",
      "Save successful.\n",
      "\n",
      "--- Generating Slop Profile String for JS ---\n",
      "\n",
      "----- BEGIN SLOP PROFILE STRING -----\n",
      "##### o3\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/o3__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/o3__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for o3' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/o3__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/o3__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for o3' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>QwQ 32B (distance=0.743)</div>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.750)</div>\n",
      "<div class='slop-similar'>DeepSeek R1 (distance=0.750)</div>\n",
      "<div class='slop-similar'>DeepSeek Chat v3 (distance=0.763)</div>\n",
      "<div class='slop-similar'>Reka Flash 3 (Free) (distance=0.769)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>clanged</span> <span class='slop-word-item'>rasped</span> <span class='slop-word-item'>glimmered</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>flagstones</span> <span class='slop-word-item'>keter</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>lamplight</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>exhaled</span> <span class='slop-word-item'>exhales</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>tilts</span> <span class='slop-word-item'>rippled</span> <span class='slop-word-item'>fluttered</span> <span class='slop-word-item'>lacquered</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>steadied</span> <span class='slop-word-item'>hisses</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>twitched</span> <span class='slop-word-item'>sputtered</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>mutters</span> <span class='slop-word-item'>yawned</span> <span class='slop-word-item'>torchlight</span> <span class='slop-word-item'>trembles</span> <span class='slop-word-item'>dripped</span> <span class='slop-word-item'>gloved</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>smudged</span> <span class='slop-word-item'>unravels</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>flicked</span> <span class='slop-word-item'>metronome</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>sternum</span> <span class='slop-word-item'>pivoted</span> <span class='slop-word-item'>shelving</span> <span class='slop-word-item'>inhales</span> <span class='slop-word-item'>plinth</span> <span class='slop-word-item'>grins</span> <span class='slop-word-item'>flinch</span> <span class='slop-word-item'>blinked</span> <span class='slop-word-item'>blinks</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### DeepSeek R1\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/DeepSeek R1__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/DeepSeek R1__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for DeepSeek R1' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/DeepSeek R1__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/DeepSeek R1__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for DeepSeek R1' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Reka Flash 3 (Free) (distance=0.563)</div>\n",
      "<div class='slop-similar'>QwQ 32B (distance=0.588)</div>\n",
      "<div class='slop-similar'>Grok 3 Beta (distance=0.674)</div>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.723)</div>\n",
      "<div class='slop-similar'>DeepSeek Chat v3 (distance=0.723)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>veyra</span> <span class='slop-word-item'>talis</span> <span class='slop-word-item'>thrummed</span> <span class='slop-word-item'>thrums</span> <span class='slop-word-item'>guttered</span> <span class='slop-word-item'>rasped</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>glinted</span> <span class='slop-word-item'>glints</span> <span class='slop-word-item'>memetic</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>keter</span> <span class='slop-word-item'>grazes</span> <span class='slop-word-item'>gleamed</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>clattered</span> <span class='slop-word-item'>bioluminescent</span> <span class='slop-word-item'>twitched</span> <span class='slop-word-item'>exhales</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>liang</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>viewport</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>gloved</span> <span class='slop-word-item'>hisses</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>frayed</span> <span class='slop-word-item'>bergamot</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>squinted</span> <span class='slop-word-item'>lunged</span> <span class='slop-word-item'>purred</span> <span class='slop-word-item'>jabbed</span> <span class='slop-word-item'>stiffened</span> <span class='slop-word-item'>trembled</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>clattering</span> <span class='slop-word-item'>reeked</span> <span class='slop-word-item'>snorted</span> <span class='slop-word-item'>voss</span> <span class='slop-word-item'>threadbare</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>murmured</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### DeepSeek Chat v3\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/DeepSeek Chat v3__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/DeepSeek Chat v3__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for DeepSeek Chat v3' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/DeepSeek Chat v3__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/DeepSeek Chat v3__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for DeepSeek Chat v3' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.629)</div>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.652)</div>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.667)</div>\n",
      "<div class='slop-similar'>Command A (distance=0.703)</div>\n",
      "<div class='slop-similar'>openrouter/optimus-alpha (distance=0.710)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>veyra</span> <span class='slop-word-item'>exhaled</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>exhales</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>stilled</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>coiling</span> <span class='slop-word-item'>twitched</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>tilts</span> <span class='slop-word-item'>voss</span> <span class='slop-word-item'>groaned</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>squinted</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>hisses</span> <span class='slop-word-item'>grins</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>snorted</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>stiffened</span> <span class='slop-word-item'>flicked</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>sighed</span> <span class='slop-word-item'>tugged</span> <span class='slop-word-item'>glanced</span> <span class='slop-word-item'>blinked</span> <span class='slop-word-item'>glowed</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>coiled</span> <span class='slop-word-item'>murmur</span> <span class='slop-word-item'>rusted</span> <span class='slop-word-item'>flinch</span> <span class='slop-word-item'>mutter</span> <span class='slop-word-item'>leans</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### ChatGPT-4o Latest\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/ChatGPT-4o Latest__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/ChatGPT-4o Latest__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for ChatGPT-4o Latest' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/ChatGPT-4o Latest__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/ChatGPT-4o Latest__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for ChatGPT-4o Latest' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.652)</div>\n",
      "<div class='slop-similar'>DeepSeek Chat v3 (distance=0.652)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-mini (distance=0.652)</div>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.667)</div>\n",
      "<div class='slop-similar'>Command A (distance=0.696)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>gleamed</span> <span class='slop-word-item'>exhales</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>blinked</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>squinted</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>exhaled</span> <span class='slop-word-item'>smudged</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>flinch</span> <span class='slop-word-item'>faintly</span> <span class='slop-word-item'>mutters</span> <span class='slop-word-item'>glowed</span> <span class='slop-word-item'>pulsed</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>coiled</span> <span class='slop-word-item'>tilts</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>squinting</span> <span class='slop-word-item'>unnaturally</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>kessler</span> <span class='slop-word-item'>whispered</span> <span class='slop-word-item'>leans</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>groaned</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>glancing</span> <span class='slop-word-item'>clung</span> <span class='slop-word-item'>grinning</span> <span class='slop-word-item'>nods</span> <span class='slop-word-item'>clenched</span> <span class='slop-word-item'>spiraling</span> <span class='slop-word-item'>grins</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>rusted</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### openai/gpt-4.1\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4.1__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4.1__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for openai/gpt-4.1' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4.1__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4.1__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for openai/gpt-4.1' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>openrouter/optimus-alpha (distance=0.545)</div>\n",
      "<div class='slop-similar'>openrouter/quasar-alpha (distance=0.644)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-mini (distance=0.659)</div>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.689)</div>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.703)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>flickered</span> <span class='slop-word-item'>callused</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>unblinking</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>pipette</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>grins</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>glances</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>falters</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>gloved</span> <span class='slop-word-item'>glancing</span> <span class='slop-word-item'>leans</span> <span class='slop-word-item'>darting</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>hourglass</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>darted</span> <span class='slop-word-item'>coaxing</span> <span class='slop-word-item'>shrugs</span> <span class='slop-word-item'>blinked</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>hunched</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>barked</span> <span class='slop-word-item'>flicked</span> <span class='slop-word-item'>battered</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>ducked</span> <span class='slop-word-item'>trembling</span> <span class='slop-word-item'>faintest</span> <span class='slop-word-item'>clutching</span> <span class='slop-word-item'>addendum</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### openrouter/optimus-alpha\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openrouter__optimus-alpha__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openrouter__optimus-alpha__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for openrouter/optimus-alpha' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openrouter__optimus-alpha__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openrouter__optimus-alpha__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for openrouter/optimus-alpha' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>openai/gpt-4.1 (distance=0.545)</div>\n",
      "<div class='slop-similar'>openrouter/quasar-alpha (distance=0.636)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-mini (distance=0.674)</div>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.696)</div>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.703)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>prickling</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>lamplight</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>grins</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>intoned</span> <span class='slop-word-item'>squinted</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>glances</span> <span class='slop-word-item'>gloved</span> <span class='slop-word-item'>splayed</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>glowed</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>glanced</span> <span class='slop-word-item'>lira</span> <span class='slop-word-item'>darted</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>blinked</span> <span class='slop-word-item'>stutters</span> <span class='slop-word-item'>lunged</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>clatter</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>leans</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>battered</span> <span class='slop-word-item'>hunched</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>flicked</span> <span class='slop-word-item'>ducked</span> <span class='slop-word-item'>pulsed</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>lingered</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>echoing</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>shrugs</span> <span class='slop-word-item'>faintly</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Gemini 2.5 Pro Exp\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemini 2.5 Pro Exp__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemini 2.5 Pro Exp__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Gemini 2.5 Pro Exp' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemini 2.5 Pro Exp__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemini 2.5 Pro Exp__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Gemini 2.5 Pro Exp' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Gemma 3 Glitter 12B (distance=0.652)</div>\n",
      "<div class='slop-similar'>Gemma 3 12B (distance=0.689)</div>\n",
      "<div class='slop-similar'>Gemma 3 4B (distance=0.710)</div>\n",
      "<div class='slop-similar'>Gemma 3 27B (distance=0.723)</div>\n",
      "<div class='slop-similar'>Gemini 2.0 Flash (distance=0.737)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>kaelen</span> <span class='slop-word-item'>thrummed</span> <span class='slop-word-item'>unnervingly</span> <span class='slop-word-item'>unsettlingly</span> <span class='slop-word-item'>valerius</span> <span class='slop-word-item'>memetic</span> <span class='slop-word-item'>thrum</span> <span class='slop-word-item'>conspiratorially</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>griz</span> <span class='slop-word-item'>prickle</span> <span class='slop-word-item'>thrumming</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>fractionally</span> <span class='slop-word-item'>imperceptibly</span> <span class='slop-word-item'>warred</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>infuriatingly</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>fizzing</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>motes</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>cobblestones</span> <span class='slop-word-item'>cloying</span> <span class='slop-word-item'>aris</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>impassive</span> <span class='slop-word-item'>faintly</span> <span class='slop-word-item'>unnerving</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>anomalous</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>thorne</span> <span class='slop-word-item'>rasp</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>precariously</span> <span class='slop-word-item'>imperceptible</span> <span class='slop-word-item'>silhouetted</span> <span class='slop-word-item'>radiating</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>clang</span> <span class='slop-word-item'>silas</span> <span class='slop-word-item'>tremor</span> <span class='slop-word-item'>hitches</span> <span class='slop-word-item'>unspoken</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Claude 3.5 Sonnet\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3.5 Sonnet__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3.5 Sonnet__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Claude 3.5 Sonnet' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3.5 Sonnet__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3.5 Sonnet__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Claude 3.5 Sonnet' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Claude 3.7 Sonnet (distance=0.806)</div>\n",
      "<div class='slop-similar'>openai/gpt-4-0314 (distance=0.806)</div>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.829)</div>\n",
      "<div class='slop-similar'>openai/gpt-3.5-turbo-0613 (distance=0.835)</div>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.841)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>flickered</span> <span class='slop-word-item'>absently</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>mari</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>ached</span> <span class='slop-word-item'>dreads</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>grins</span> <span class='slop-word-item'>writhing</span> <span class='slop-word-item'>whispered</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>containment</span> <span class='slop-word-item'>materialized</span> <span class='slop-word-item'>salvaged</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>glanced</span> <span class='slop-word-item'>whispers</span> <span class='slop-word-item'>sighed</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>redacted</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>trembling</span> <span class='slop-word-item'>ripples</span> <span class='slop-word-item'>gleaming</span> <span class='slop-word-item'>glances</span> <span class='slop-word-item'>chen</span> <span class='slop-word-item'>tremor</span> <span class='slop-word-item'>nodding</span> <span class='slop-word-item'>nods</span> <span class='slop-word-item'>weathered</span> <span class='slop-word-item'>momentarily</span> <span class='slop-word-item'>humming</span> <span class='slop-word-item'>shadows</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>pauses</span> <span class='slop-word-item'>leans</span> <span class='slop-word-item'>paused</span> <span class='slop-word-item'>perched</span> <span class='slop-word-item'>echoed</span> <span class='slop-word-item'>wiping</span> <span class='slop-word-item'>practiced</span> <span class='slop-word-item'>strings</span> <span class='slop-word-item'>smiled</span> <span class='slop-word-item'>temporal</span> <span class='slop-word-item'>crimson</span> <span class='slop-word-item'>grin</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### ChatGPT-4o Latest\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/ChatGPT-4o Latest__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/ChatGPT-4o Latest__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for ChatGPT-4o Latest' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/ChatGPT-4o Latest__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/ChatGPT-4o Latest__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for ChatGPT-4o Latest' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>DeepSeek Chat v3 (distance=0.629)</div>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.667)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-mini (distance=0.681)</div>\n",
      "<div class='slop-similar'>openrouter/quasar-alpha (distance=0.681)</div>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.689)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>exhales</span> <span class='slop-word-item'>exhaled</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>gleamed</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>clenches</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>squinted</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>stiffly</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>tilts</span> <span class='slop-word-item'>twitched</span> <span class='slop-word-item'>dryly</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>grins</span> <span class='slop-word-item'>exhaling</span> <span class='slop-word-item'>lurched</span> <span class='slop-word-item'>calliope</span> <span class='slop-word-item'>groaned</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>wiry</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>blinked</span> <span class='slop-word-item'>blinks</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>henshaw</span> <span class='slop-word-item'>lunged</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>sighed</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>smirk</span> <span class='slop-word-item'>clenched</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>darrow</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>glanced</span> <span class='slop-word-item'>flinch</span> <span class='slop-word-item'>chuckles</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### openrouter/quasar-alpha\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openrouter__quasar-alpha__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openrouter__quasar-alpha__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for openrouter/quasar-alpha' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openrouter__quasar-alpha__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openrouter__quasar-alpha__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for openrouter/quasar-alpha' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>openai/gpt-4.1-mini (distance=0.613)</div>\n",
      "<div class='slop-similar'>openrouter/optimus-alpha (distance=0.636)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1 (distance=0.644)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-nano (distance=0.644)</div>\n",
      "<div class='slop-similar'>Command A (distance=0.681)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>prickled</span> <span class='slop-word-item'>prickling</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>thudded</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>unbothered</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>lounged</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>gleamed</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>shyly</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>shakily</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>coiling</span> <span class='slop-word-item'>warily</span> <span class='slop-word-item'>exhales</span> <span class='slop-word-item'>steadied</span> <span class='slop-word-item'>faintly</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>trembling</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>blinked</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>exhaled</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>coiled</span> <span class='slop-word-item'>sharpens</span> <span class='slop-word-item'>guttural</span> <span class='slop-word-item'>softens</span> <span class='slop-word-item'>grins</span> <span class='slop-word-item'>anomalous</span> <span class='slop-word-item'>battered</span> <span class='slop-word-item'>swirling</span> <span class='slop-word-item'>gasped</span> <span class='slop-word-item'>snorted</span> <span class='slop-word-item'>trembled</span> <span class='slop-word-item'>crusted</span> <span class='slop-word-item'>mingling</span> <span class='slop-word-item'>gloved</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Reka Flash 3 (Free)\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Reka Flash 3 (Free)__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Reka Flash 3 (Free)__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Reka Flash 3 (Free)' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Reka Flash 3 (Free)__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Reka Flash 3 (Free)__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Reka Flash 3 (Free)' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>DeepSeek R1 (distance=0.563)</div>\n",
      "<div class='slop-similar'>QwQ 32B (distance=0.563)</div>\n",
      "<div class='slop-similar'>Grok 3 Beta (distance=0.710)</div>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.723)</div>\n",
      "<div class='slop-similar'>DeepSeek Chat v3 (distance=0.743)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>veyra</span> <span class='slop-word-item'>vorne</span> <span class='slop-word-item'>elara</span> <span class='slop-word-item'>thrums</span> <span class='slop-word-item'>drawled</span> <span class='slop-word-item'>krell</span> <span class='slop-word-item'>glinted</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>twitched</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>bioluminescent</span> <span class='slop-word-item'>fogging</span> <span class='slop-word-item'>creaks</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>slithered</span> <span class='slop-word-item'>reeked</span> <span class='slop-word-item'>calloused</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>foghorn</span> <span class='slop-word-item'>purred</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>clattered</span> <span class='slop-word-item'>lunged</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>hisses</span> <span class='slop-word-item'>clattering</span> <span class='slop-word-item'>glowed</span> <span class='slop-word-item'>rasp</span> <span class='slop-word-item'>falters</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>coiled</span> <span class='slop-word-item'>faintly</span> <span class='slop-word-item'>dais</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>quickened</span> <span class='slop-word-item'>reeking</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>crumpled</span> <span class='slop-word-item'>sigil</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### QwQ 32B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/QwQ 32B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/QwQ 32B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for QwQ 32B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/QwQ 32B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/QwQ 32B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for QwQ 32B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Reka Flash 3 (Free) (distance=0.563)</div>\n",
      "<div class='slop-similar'>DeepSeek R1 (distance=0.588)</div>\n",
      "<div class='slop-similar'>Grok 3 Beta (distance=0.667)</div>\n",
      "<div class='slop-similar'>Command A (distance=0.710)</div>\n",
      "<div class='slop-similar'>DeepSeek Chat v3 (distance=0.710)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>veyra</span> <span class='slop-word-item'>thrums</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>glinted</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>kestrel</span> <span class='slop-word-item'>flinches</span> <span class='slop-word-item'>throbbed</span> <span class='slop-word-item'>blares</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>lunged</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>twitched</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>stilled</span> <span class='slop-word-item'>bioluminescent</span> <span class='slop-word-item'>creaks</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>coiling</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>hisses</span> <span class='slop-word-item'>trembled</span> <span class='slop-word-item'>hitches</span> <span class='slop-word-item'>pivoted</span> <span class='slop-word-item'>fraying</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>tilts</span> <span class='slop-word-item'>why&#x27;re</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>mutters</span> <span class='slop-word-item'>torchlight</span> <span class='slop-word-item'>grins</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>rasp</span> <span class='slop-word-item'>glyphs</span> <span class='slop-word-item'>coiled</span> <span class='slop-word-item'>stiffened</span> <span class='slop-word-item'>lingered</span> <span class='slop-word-item'>flinch</span> <span class='slop-word-item'>glowed</span> <span class='slop-word-item'>dimmed</span> <span class='slop-word-item'>snorts</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Claude 3.7 Sonnet\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3.7 Sonnet__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3.7 Sonnet__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Claude 3.7 Sonnet' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3.7 Sonnet__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3.7 Sonnet__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Claude 3.7 Sonnet' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>DeepSeek Chat v3 (distance=0.776)</div>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.782)</div>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.782)</div>\n",
      "<div class='slop-similar'>Command A (distance=0.794)</div>\n",
      "<div class='slop-similar'>Gemma 3 Starshine 12B (distance=0.806)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>thornfield</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>viewport</span> <span class='slop-word-item'>dismissively</span> <span class='slop-word-item'>zora</span> <span class='slop-word-item'>materializes</span> <span class='slop-word-item'>squinted</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>voss</span> <span class='slop-word-item'>impassive</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>mutters</span> <span class='slop-word-item'>unnaturally</span> <span class='slop-word-item'>callum</span> <span class='slop-word-item'>whispered</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>clutched</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>blinked</span> <span class='slop-word-item'>harlow</span> <span class='slop-word-item'>northside</span> <span class='slop-word-item'>mendez</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>heartbeats</span> <span class='slop-word-item'>containment</span> <span class='slop-word-item'>sipped</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>momentarily</span> <span class='slop-word-item'>mutter</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>forearms</span> <span class='slop-word-item'>materialized</span> <span class='slop-word-item'>rimmed</span> <span class='slop-word-item'>methodically</span> <span class='slop-word-item'>rustling</span> <span class='slop-word-item'>flinch</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>sighed</span> <span class='slop-word-item'>lingered</span> <span class='slop-word-item'>glanced</span> <span class='slop-word-item'>gleam</span> <span class='slop-word-item'>blackwood</span> <span class='slop-word-item'>overthinking</span> <span class='slop-word-item'>gasps</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Gemma 3 27B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 27B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 27B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Gemma 3 27B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 27B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 27B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Gemma 3 27B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Gemma 3 Glitter 12B (distance=0.605)</div>\n",
      "<div class='slop-similar'>Gemma 3 12B (distance=0.605)</div>\n",
      "<div class='slop-similar'>Gemma 3 4B (distance=0.629)</div>\n",
      "<div class='slop-similar'>Gemini 2.0 Flash (distance=0.674)</div>\n",
      "<div class='slop-similar'>Gemini 2.5 Pro Exp (distance=0.723)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>kaelen</span> <span class='slop-word-item'>xylos</span> <span class='slop-word-item'>unsettlingly</span> <span class='slop-word-item'>valerius</span> <span class='slop-word-item'>sunstone</span> <span class='slop-word-item'>thrum</span> <span class='slop-word-item'>hellhound</span> <span class='slop-word-item'>keter</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>hemlock</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>rasp</span> <span class='slop-word-item'>calloused</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>rhys</span> <span class='slop-word-item'>vibrated</span> <span class='slop-word-item'>bioluminescent</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>hana</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>alistair</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>tiber</span> <span class='slop-word-item'>hulking</span> <span class='slop-word-item'>cloying</span> <span class='slop-word-item'>mumbled</span> <span class='slop-word-item'>unsettling</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>imperceptible</span> <span class='slop-word-item'>hemmings</span> <span class='slop-word-item'>wildflowers</span> <span class='slop-word-item'>obsidian</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>raspy</span> <span class='slop-word-item'>silas</span> <span class='slop-word-item'>unnerving</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>radiating</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>murmur</span> <span class='slop-word-item'>silken</span> <span class='slop-word-item'>impeccably</span> <span class='slop-word-item'>weariness</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>flinch</span> <span class='slop-word-item'>clung</span> <span class='slop-word-item'>cataloging</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### GPT-4.5 Preview\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/GPT-4.5 Preview__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/GPT-4.5 Preview__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for GPT-4.5 Preview' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/GPT-4.5 Preview__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/GPT-4.5 Preview__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for GPT-4.5 Preview' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.703)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-mini (distance=0.717)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-nano (distance=0.717)</div>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.750)</div>\n",
      "<div class='slop-similar'>openrouter/quasar-alpha (distance=0.750)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>rasped</span> <span class='slop-word-item'>conspiratorially</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>appreciatively</span> <span class='slop-word-item'>uncertainly</span> <span class='slop-word-item'>shyly</span> <span class='slop-word-item'>skeptically</span> <span class='slop-word-item'>gleamed</span> <span class='slop-word-item'>dryly</span> <span class='slop-word-item'>quickens</span> <span class='slop-word-item'>mischievously</span> <span class='slop-word-item'>dismissively</span> <span class='slop-word-item'>stiffly</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>uneasily</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>purred</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>quickening</span> <span class='slop-word-item'>coiling</span> <span class='slop-word-item'>steadying</span> <span class='slop-word-item'>glancing</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>glanced</span> <span class='slop-word-item'>warily</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>faintly</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>restlessly</span> <span class='slop-word-item'>savoring</span> <span class='slop-word-item'>softly</span> <span class='slop-word-item'>gloved</span> <span class='slop-word-item'>thoughtfully</span> <span class='slop-word-item'>wearily</span> <span class='slop-word-item'>sighed</span> <span class='slop-word-item'>snarls</span> <span class='slop-word-item'>ominously</span> <span class='slop-word-item'>theatrically</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>hesitantly</span> <span class='slop-word-item'>lazily</span> <span class='slop-word-item'>quickened</span> <span class='slop-word-item'>sheepishly</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>tinny</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Grok 3 Beta\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Grok 3 Beta__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Grok 3 Beta__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Grok 3 Beta' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Grok 3 Beta__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Grok 3 Beta__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Grok 3 Beta' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>QwQ 32B (distance=0.667)</div>\n",
      "<div class='slop-similar'>DeepSeek R1 (distance=0.674)</div>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.681)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-mini (distance=0.710)</div>\n",
      "<div class='slop-similar'>Reka Flash 3 (Free) (distance=0.710)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>vorn</span> <span class='slop-word-item'>glinted</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>thudded</span> <span class='slop-word-item'>drawled</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>memetic</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>viewport</span> <span class='slop-word-item'>wiry</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>scuffing</span> <span class='slop-word-item'>bioluminescent</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>calloused</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>gnawed</span> <span class='slop-word-item'>craggy</span> <span class='slop-word-item'>creaks</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>coiling</span> <span class='slop-word-item'>ached</span> <span class='slop-word-item'>croaked</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>twitched</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>squinted</span> <span class='slop-word-item'>mutters</span> <span class='slop-word-item'>rasp</span> <span class='slop-word-item'>loomed</span> <span class='slop-word-item'>concordance</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>smirk</span> <span class='slop-word-item'>creak</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>obsidian</span> <span class='slop-word-item'>visors</span> <span class='slop-word-item'>retorts</span> <span class='slop-word-item'>hunched</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>snorts</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### openai/gpt-4.1-mini\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4.1-mini__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4.1-mini__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for openai/gpt-4.1-mini' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4.1-mini__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4.1-mini__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for openai/gpt-4.1-mini' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.605)</div>\n",
      "<div class='slop-similar'>openrouter/quasar-alpha (distance=0.613)</div>\n",
      "<div class='slop-similar'>Command A (distance=0.629)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-nano (distance=0.644)</div>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.652)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>flickered</span> <span class='slop-word-item'>gleamed</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>twitched</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>steadying</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>blinked</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>exhaled</span> <span class='slop-word-item'>faintly</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>warily</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>cobblestones</span> <span class='slop-word-item'>clatter</span> <span class='slop-word-item'>sparkled</span> <span class='slop-word-item'>creak</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>trembled</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>flicked</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>lingered</span> <span class='slop-word-item'>flicking</span> <span class='slop-word-item'>unyielding</span> <span class='slop-word-item'>glanced</span> <span class='slop-word-item'>clenched</span> <span class='slop-word-item'>gleaming</span> <span class='slop-word-item'>ominously</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>mutters</span> <span class='slop-word-item'>rusted</span> <span class='slop-word-item'>shrugged</span> <span class='slop-word-item'>whispered</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>darted</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>unspoken</span> <span class='slop-word-item'>addendum</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Command A\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Command A__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Command A__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Command A' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Command A__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Command A__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Command A' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.580)</div>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.629)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-mini (distance=0.629)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-nano (distance=0.667)</div>\n",
      "<div class='slop-similar'>openrouter/quasar-alpha (distance=0.681)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>kaira</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>bioluminescent</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>lila</span> <span class='slop-word-item'>twitched</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>faintly</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>cobblestones</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>trembled</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>voss</span> <span class='slop-word-item'>clutched</span> <span class='slop-word-item'>smirk</span> <span class='slop-word-item'>groaned</span> <span class='slop-word-item'>torchlight</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>sighed</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>slung</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>shrugging</span> <span class='slop-word-item'>lyra</span> <span class='slop-word-item'>elias</span> <span class='slop-word-item'>mara</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>clatter</span> <span class='slop-word-item'>clench</span> <span class='slop-word-item'>glanced</span> <span class='slop-word-item'>unyielding</span> <span class='slop-word-item'>overthinking</span> <span class='slop-word-item'>replaying</span> <span class='slop-word-item'>clung</span> <span class='slop-word-item'>flicking</span> <span class='slop-word-item'>softens</span> <span class='slop-word-item'>smirking</span> <span class='slop-word-item'>mingling</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Claude 3.5 Haiku\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3.5 Haiku__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3.5 Haiku__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Claude 3.5 Haiku' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3.5 Haiku__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3.5 Haiku__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Claude 3.5 Haiku' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Claude 3.5 Sonnet (distance=0.846)</div>\n",
      "<div class='slop-similar'>Claude 3.7 Sonnet (distance=0.863)</div>\n",
      "<div class='slop-similar'>openai/gpt-4-0314 (distance=0.863)</div>\n",
      "<div class='slop-similar'>Gemma 2 9B (distance=0.868)</div>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.873)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>memetic</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>keter</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>imperceptibly</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>millisecond</span> <span class='slop-word-item'>tendrils</span> <span class='slop-word-item'>voss</span> <span class='slop-word-item'>recursive</span> <span class='slop-word-item'>subtext</span> <span class='slop-word-item'>momentarily</span> <span class='slop-word-item'>impossibly</span> <span class='slop-word-item'>obsidian</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>pulsed</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>holographic</span> <span class='slop-word-item'>unspoken</span> <span class='slop-word-item'>reshape</span> <span class='slop-word-item'>entanglement</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>crackling</span> <span class='slop-word-item'>nuanced</span> <span class='slop-word-item'>weathered</span> <span class='slop-word-item'>anomalous</span> <span class='slop-word-item'>unconsciously</span> <span class='slop-word-item'>gleaming</span> <span class='slop-word-item'>archival</span> <span class='slop-word-item'>tremor</span> <span class='slop-word-item'>containment</span> <span class='slop-word-item'>dissonance</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>whispered</span> <span class='slop-word-item'>translucent</span> <span class='slop-word-item'>kira</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>clutching</span> <span class='slop-word-item'>microscopic</span> <span class='slop-word-item'>temporal</span> <span class='slop-word-item'>subtly</span> <span class='slop-word-item'>makeshift</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>drifted</span> <span class='slop-word-item'>synchronized</span> <span class='slop-word-item'>abort</span> <span class='slop-word-item'>predatory</span> <span class='slop-word-item'>intricate</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Darkest Muse v1\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Darkest Muse v1__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Darkest Muse v1__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Darkest Muse v1' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Darkest Muse v1__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Darkest Muse v1__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Darkest Muse v1' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Gemma 2 Ifable 9B (distance=0.794)</div>\n",
      "<div class='slop-similar'>Gemini 2.0 Flash (distance=0.800)</div>\n",
      "<div class='slop-similar'>Gemma 3 12B (distance=0.800)</div>\n",
      "<div class='slop-similar'>Gemma 3 Glitter 12B (distance=0.818)</div>\n",
      "<div class='slop-similar'>Gemini 2.5 Pro Exp (distance=0.818)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>rasped</span> <span class='slop-word-item'>prickle</span> <span class='slop-word-item'>woodsmoke</span> <span class='slop-word-item'>elara</span> <span class='slop-word-item'>prickling</span> <span class='slop-word-item'>rasp</span> <span class='slop-word-item'>glinted</span> <span class='slop-word-item'>lamplight</span> <span class='slop-word-item'>kaito</span> <span class='slop-word-item'>rasping</span> <span class='slop-word-item'>cloying</span> <span class='slop-word-item'>acrid</span> <span class='slop-word-item'>rasps</span> <span class='slop-word-item'>skittering</span> <span class='slop-word-item'>flagstones</span> <span class='slop-word-item'>spiderweb</span> <span class='slop-word-item'>wheezed</span> <span class='slop-word-item'>thrum</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>obsidian</span> <span class='slop-word-item'>sibilant</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>bioluminescent</span> <span class='slop-word-item'>guttural</span> <span class='slop-word-item'>acheron</span> <span class='slop-word-item'>croaked</span> <span class='slop-word-item'>sputtered</span> <span class='slop-word-item'>snaked</span> <span class='slop-word-item'>overripe</span> <span class='slop-word-item'>gnarled</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>sickly</span> <span class='slop-word-item'>vibrated</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>precariously</span> <span class='slop-word-item'>purred</span> <span class='slop-word-item'>phosphorescent</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>chipped</span> <span class='slop-word-item'>reeked</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>squinted</span> <span class='slop-word-item'>coppery</span> <span class='slop-word-item'>cobblestones</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>tinny</span> <span class='slop-word-item'>calloused</span> <span class='slop-word-item'>scavenged</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Gemma 3 12B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 12B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 12B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Gemma 3 12B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 12B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 12B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Gemma 3 12B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Gemma 3 Glitter 12B (distance=0.491)</div>\n",
      "<div class='slop-similar'>Gemma 3 4B (distance=0.571)</div>\n",
      "<div class='slop-similar'>Gemma 3 27B (distance=0.605)</div>\n",
      "<div class='slop-similar'>Gemini 2.0 Flash (distance=0.621)</div>\n",
      "<div class='slop-similar'>Gemini 2.5 Pro Exp (distance=0.689)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>oakhaven</span> <span class='slop-word-item'>xylosian</span> <span class='slop-word-item'>elara</span> <span class='slop-word-item'>unsettlingly</span> <span class='slop-word-item'>unnervingly</span> <span class='slop-word-item'>kenji</span> <span class='slop-word-item'>thimbles</span> <span class='slop-word-item'>humorless</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>thrum</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>imperceptible</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>impassive</span> <span class='slop-word-item'>rasp</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>rhys</span> <span class='slop-word-item'>unsettling</span> <span class='slop-word-item'>hana</span> <span class='slop-word-item'>hulking</span> <span class='slop-word-item'>thorne</span> <span class='slop-word-item'>chronos</span> <span class='slop-word-item'>cloying</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>lyra</span> <span class='slop-word-item'>clinking</span> <span class='slop-word-item'>impeccably</span> <span class='slop-word-item'>shimmering</span> <span class='slop-word-item'>mumbled</span> <span class='slop-word-item'>rippled</span> <span class='slop-word-item'>meticulously</span> <span class='slop-word-item'>sputtered</span> <span class='slop-word-item'>grumbles</span> <span class='slop-word-item'>wildflowers</span> <span class='slop-word-item'>clung</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>stillness</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>mournful</span> <span class='slop-word-item'>labyrinthine</span> <span class='slop-word-item'>radiating</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>tremor</span> <span class='slop-word-item'>intricately</span> <span class='slop-word-item'>flickering</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Gemma 3 Glitter 12B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 Glitter 12B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 Glitter 12B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Gemma 3 Glitter 12B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 Glitter 12B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 Glitter 12B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Gemma 3 Glitter 12B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Gemma 3 12B (distance=0.491)</div>\n",
      "<div class='slop-similar'>Gemini 2.0 Flash (distance=0.588)</div>\n",
      "<div class='slop-similar'>Gemma 3 27B (distance=0.605)</div>\n",
      "<div class='slop-similar'>Gemma 3 4B (distance=0.636)</div>\n",
      "<div class='slop-similar'>Gemini 2.5 Pro Exp (distance=0.652)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>kaelen</span> <span class='slop-word-item'>xylos</span> <span class='slop-word-item'>elara</span> <span class='slop-word-item'>chronal</span> <span class='slop-word-item'>unsettlingly</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>valerius</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>lyra</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>unsettling</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>mumbled</span> <span class='slop-word-item'>impassive</span> <span class='slop-word-item'>obsidian</span> <span class='slop-word-item'>rhys</span> <span class='slop-word-item'>mournful</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>thorne</span> <span class='slop-word-item'>hulking</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>clinking</span> <span class='slop-word-item'>radiating</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>intricately</span> <span class='slop-word-item'>rasp</span> <span class='slop-word-item'>wiry</span> <span class='slop-word-item'>cobblestones</span> <span class='slop-word-item'>wren</span> <span class='slop-word-item'>hydroponics</span> <span class='slop-word-item'>imperceptible</span> <span class='slop-word-item'>clang</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>chronos</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>scoffs</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>lunged</span> <span class='slop-word-item'>clung</span> <span class='slop-word-item'>gaze</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Gemini 2.0 Flash\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemini 2.0 Flash__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemini 2.0 Flash__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Gemini 2.0 Flash' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemini 2.0 Flash__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemini 2.0 Flash__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Gemini 2.0 Flash' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Gemma 3 Glitter 12B (distance=0.588)</div>\n",
      "<div class='slop-similar'>Gemma 3 12B (distance=0.621)</div>\n",
      "<div class='slop-similar'>Gemma 2 9B (distance=0.659)</div>\n",
      "<div class='slop-similar'>Gemma 3 Starshine 12B (distance=0.674)</div>\n",
      "<div class='slop-similar'>Gemma 3 27B (distance=0.674)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>datapad</span> <span class='slop-word-item'>rasped</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>vibrated</span> <span class='slop-word-item'>valerius</span> <span class='slop-word-item'>hulking</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>calloused</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>imperceptible</span> <span class='slop-word-item'>kaito</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>sputtered</span> <span class='slop-word-item'>hydroponics</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>precariously</span> <span class='slop-word-item'>acrid</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>guttural</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>gleaming</span> <span class='slop-word-item'>raspy</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>labyrinthine</span> <span class='slop-word-item'>retorts</span> <span class='slop-word-item'>unwavering</span> <span class='slop-word-item'>shimmering</span> <span class='slop-word-item'>obsidian</span> <span class='slop-word-item'>clang</span> <span class='slop-word-item'>elysium</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>sighed</span> <span class='slop-word-item'>wiry</span> <span class='slop-word-item'>groaned</span> <span class='slop-word-item'>lunged</span> <span class='slop-word-item'>clutched</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>gaze</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Gemma 3 4B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 4B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 4B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Gemma 3 4B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 4B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 4B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Gemma 3 4B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Gemma 3 12B (distance=0.571)</div>\n",
      "<div class='slop-similar'>Gemma 3 27B (distance=0.629)</div>\n",
      "<div class='slop-similar'>Gemma 3 Glitter 12B (distance=0.636)</div>\n",
      "<div class='slop-similar'>Gemini 2.5 Pro Exp (distance=0.710)</div>\n",
      "<div class='slop-similar'>Gemini 2.0 Flash (distance=0.717)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>xylos</span> <span class='slop-word-item'>veridia</span> <span class='slop-word-item'>elara</span> <span class='slop-word-item'>seraphina</span> <span class='slop-word-item'>unsettlingly</span> <span class='slop-word-item'>slicking</span> <span class='slop-word-item'>veridian</span> <span class='slop-word-item'>prickle</span> <span class='slop-word-item'>unnervingly</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>imperceptible</span> <span class='slop-word-item'>silvanus</span> <span class='slop-word-item'>chronos</span> <span class='slop-word-item'>bioluminescent</span> <span class='slop-word-item'>disconcertingly</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>unsettling</span> <span class='slop-word-item'>viewport</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>silas</span> <span class='slop-word-item'>sputtered</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>insistent</span> <span class='slop-word-item'>obsidian</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>impassive</span> <span class='slop-word-item'>clinking</span> <span class='slop-word-item'>mumbled</span> <span class='slop-word-item'>cobblestones</span> <span class='slop-word-item'>intricately</span> <span class='slop-word-item'>foghorn</span> <span class='slop-word-item'>hana</span> <span class='slop-word-item'>mournful</span> <span class='slop-word-item'>lyra</span> <span class='slop-word-item'>slicked</span> <span class='slop-word-item'>shimmering</span> <span class='slop-word-item'>meticulously</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>disconcerting</span> <span class='slop-word-item'>thorne</span> <span class='slop-word-item'>wiry</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>radiating</span> <span class='slop-word-item'>unwavering</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>glint</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Gemma 2 Ifable 9B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 2 Ifable 9B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 2 Ifable 9B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Gemma 2 Ifable 9B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 2 Ifable 9B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 2 Ifable 9B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Gemma 2 Ifable 9B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Gemma 2 9B (distance=0.769)</div>\n",
      "<div class='slop-similar'>Gemini 2.0 Flash (distance=0.782)</div>\n",
      "<div class='slop-similar'>Gemini 2.5 Pro Exp (distance=0.794)</div>\n",
      "<div class='slop-similar'>LFM 7B (distance=0.794)</div>\n",
      "<div class='slop-similar'>Darkest Muse v1 (distance=0.794)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>kaelen</span> <span class='slop-word-item'>xylos</span> <span class='slop-word-item'>elara</span> <span class='slop-word-item'>aethelred</span> <span class='slop-word-item'>thrummed</span> <span class='slop-word-item'>fathomless</span> <span class='slop-word-item'>kaito</span> <span class='slop-word-item'>rasped</span> <span class='slop-word-item'>thrum</span> <span class='slop-word-item'>throbbed</span> <span class='slop-word-item'>thrumming</span> <span class='slop-word-item'>bioluminescent</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>calloused</span> <span class='slop-word-item'>rasp</span> <span class='slop-word-item'>chillingly</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>labyrinthine</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>wizened</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>discordant</span> <span class='slop-word-item'>honeyed</span> <span class='slop-word-item'>obsidian</span> <span class='slop-word-item'>laced</span> <span class='slop-word-item'>hushed</span> <span class='slop-word-item'>guttural</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>vibrated</span> <span class='slop-word-item'>lilt</span> <span class='slop-word-item'>nonchalance</span> <span class='slop-word-item'>cloying</span> <span class='slop-word-item'>unspoken</span> <span class='slop-word-item'>grudging</span> <span class='slop-word-item'>mirroring</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>luminescence</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>purred</span> <span class='slop-word-item'>sliver</span> <span class='slop-word-item'>silken</span> <span class='slop-word-item'>terran</span> <span class='slop-word-item'>theatricality</span> <span class='slop-word-item'>languid</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>meticulously</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### accounts/fireworks/models/deepseek-v3\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/accounts__fireworks__models__deepseek-v3__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/accounts__fireworks__models__deepseek-v3__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for accounts/fireworks/models/deepseek-v3' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/accounts__fireworks__models__deepseek-v3__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/accounts__fireworks__models__deepseek-v3__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for accounts/fireworks/models/deepseek-v3' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Command A (distance=0.580)</div>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.580)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-mini (distance=0.605)</div>\n",
      "<div class='slop-similar'>ChatGPT-4o Latest (distance=0.652)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-nano (distance=0.659)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>eira</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>overanalyzing</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>gleamed</span> <span class='slop-word-item'>keter</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>hargrove</span> <span class='slop-word-item'>voss</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>faintly</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>smirk</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>falters</span> <span class='slop-word-item'>groaned</span> <span class='slop-word-item'>spiraling</span> <span class='slop-word-item'>ominously</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>glanced</span> <span class='slop-word-item'>mutters</span> <span class='slop-word-item'>mutter</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>clutched</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>darting</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>blinked</span> <span class='slop-word-item'>trembling</span> <span class='slop-word-item'>rustle</span> <span class='slop-word-item'>guttural</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### openai/gpt-4.1-nano\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4.1-nano__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4.1-nano__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for openai/gpt-4.1-nano' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4.1-nano__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4.1-nano__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for openai/gpt-4.1-nano' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>openai/gpt-4.1-mini (distance=0.644)</div>\n",
      "<div class='slop-similar'>openrouter/quasar-alpha (distance=0.644)</div>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.659)</div>\n",
      "<div class='slop-similar'>Command A (distance=0.667)</div>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.689)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>prickled</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>prickling</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>gleamed</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>lidded</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>pallor</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>flicked</span> <span class='slop-word-item'>alleyways</span> <span class='slop-word-item'>steadying</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>trembling</span> <span class='slop-word-item'>twitched</span> <span class='slop-word-item'>cobblestones</span> <span class='slop-word-item'>darting</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>tightens</span> <span class='slop-word-item'>clang</span> <span class='slop-word-item'>gravelly</span> <span class='slop-word-item'>scoffs</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>fluttered</span> <span class='slop-word-item'>shyly</span> <span class='slop-word-item'>shimmering</span> <span class='slop-word-item'>seeped</span> <span class='slop-word-item'>blinked</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>unyielding</span> <span class='slop-word-item'>gnawing</span> <span class='slop-word-item'>swirling</span> <span class='slop-word-item'>softly</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>faint</span> <span class='slop-word-item'>clutching</span> <span class='slop-word-item'>shadowed</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### mistralai/mistral-large-2411\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/mistralai__mistral-large-2411__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/mistralai__mistral-large-2411__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for mistralai/mistral-large-2411' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/mistralai__mistral-large-2411__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/mistralai__mistral-large-2411__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for mistralai/mistral-large-2411' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.545)</div>\n",
      "<div class='slop-similar'>openai/gpt-4-0314 (distance=0.659)</div>\n",
      "<div class='slop-similar'>Mistral Nemo (distance=0.667)</div>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.681)</div>\n",
      "<div class='slop-similar'>Mistral Small 24B (distance=0.681)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>vespera</span> <span class='slop-word-item'>elara</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>misting</span> <span class='slop-word-item'>astrid</span> <span class='slop-word-item'>grins</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>lyra</span> <span class='slop-word-item'>twitched</span> <span class='slop-word-item'>gleaming</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>grimy</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>nods</span> <span class='slop-word-item'>scoffs</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>inscrutable</span> <span class='slop-word-item'>growls</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>coursing</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>gasps</span> <span class='slop-word-item'>disheveled</span> <span class='slop-word-item'>smirk</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>evelyn</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>sighed</span> <span class='slop-word-item'>scribbling</span> <span class='slop-word-item'>clink</span> <span class='slop-word-item'>figurine</span> <span class='slop-word-item'>rustling</span> <span class='slop-word-item'>glowed</span> <span class='slop-word-item'>containment</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>echoing</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>clatter</span> <span class='slop-word-item'>pounding</span> <span class='slop-word-item'>leaned</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### mistralai/pixtral-large-2411\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/mistralai__pixtral-large-2411__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/mistralai__pixtral-large-2411__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for mistralai/pixtral-large-2411' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/mistralai__pixtral-large-2411__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/mistralai__pixtral-large-2411__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for mistralai/pixtral-large-2411' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>mistralai/mistral-large-2411 (distance=0.545)</div>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.580)</div>\n",
      "<div class='slop-similar'>openai/gpt-4-0314 (distance=0.605)</div>\n",
      "<div class='slop-similar'>Command A (distance=0.629)</div>\n",
      "<div class='slop-similar'>Mistral Nemo (distance=0.629)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>kaito</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>twitched</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>rhys</span> <span class='slop-word-item'>tensing</span> <span class='slop-word-item'>scoffs</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>grins</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>nods</span> <span class='slop-word-item'>belied</span> <span class='slop-word-item'>grimy</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>smirk</span> <span class='slop-word-item'>doodling</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>gasps</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>dimly</span> <span class='slop-word-item'>gleaming</span> <span class='slop-word-item'>unyielding</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>chimed</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>glanced</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>pounding</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>darting</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Gemma 3 Starshine 12B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 Starshine 12B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 Starshine 12B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Gemma 3 Starshine 12B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 Starshine 12B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 3 Starshine 12B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Gemma 3 Starshine 12B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Gemini 2.0 Flash (distance=0.674)</div>\n",
      "<div class='slop-similar'>Gemma 3 Glitter 12B (distance=0.696)</div>\n",
      "<div class='slop-similar'>Gemma 2 9B (distance=0.710)</div>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.710)</div>\n",
      "<div class='slop-similar'>Mistral Nemo (distance=0.723)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>evangeline</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>foghorn</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>rhys</span> <span class='slop-word-item'>impassive</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>clinking</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>lunged</span> <span class='slop-word-item'>hulking</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>dictating</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>scoffed</span> <span class='slop-word-item'>trembling</span> <span class='slop-word-item'>aurelia</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>sighed</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>savoring</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>silas</span> <span class='slop-word-item'>gleaming</span> <span class='slop-word-item'>scavengers</span> <span class='slop-word-item'>darting</span> <span class='slop-word-item'>mumbled</span> <span class='slop-word-item'>clasped</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>jolt</span> <span class='slop-word-item'>containment</span> <span class='slop-word-item'>kaleidoscope</span> <span class='slop-word-item'>obsidian</span> <span class='slop-word-item'>shrugged</span> <span class='slop-word-item'>clutched</span> <span class='slop-word-item'>radiating</span> <span class='slop-word-item'>widened</span> <span class='slop-word-item'>swirling</span> <span class='slop-word-item'>rustling</span> <span class='slop-word-item'>thorne</span> <span class='slop-word-item'>glared</span> <span class='slop-word-item'>hoarse</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Mistral Nemo\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Mistral Nemo__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Mistral Nemo__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Mistral Nemo' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Mistral Nemo__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Mistral Nemo__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Mistral Nemo' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.629)</div>\n",
      "<div class='slop-similar'>mistralai/mistral-large-2411 (distance=0.667)</div>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.674)</div>\n",
      "<div class='slop-similar'>Mistral Small 24B (distance=0.689)</div>\n",
      "<div class='slop-similar'>Mistral Small 3.1 24B (distance=0.696)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>drawled</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>steeling</span> <span class='slop-word-item'>coiling</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>lyra</span> <span class='slop-word-item'>writhing</span> <span class='slop-word-item'>unyielding</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>gleaming</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>growled</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>hums</span> <span class='slop-word-item'>pounding</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>grimy</span> <span class='slop-word-item'>furrowed</span> <span class='slop-word-item'>ominously</span> <span class='slop-word-item'>echoing</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>gnawing</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>darting</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>lunged</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>gasps</span> <span class='slop-word-item'>clutched</span> <span class='slop-word-item'>scoffed</span> <span class='slop-word-item'>flicking</span> <span class='slop-word-item'>hissed</span> <span class='slop-word-item'>coaxing</span> <span class='slop-word-item'>smirked</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>rustle</span> <span class='slop-word-item'>sighed</span> <span class='slop-word-item'>trembled</span> <span class='slop-word-item'>conspiratorial</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>flicker</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### GPT-4o Mini\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/GPT-4o Mini__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/GPT-4o Mini__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for GPT-4o Mini' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/GPT-4o Mini__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/GPT-4o Mini__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for GPT-4o Mini' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.710)</div>\n",
      "<div class='slop-similar'>accounts/fireworks/models/deepseek-v3 (distance=0.717)</div>\n",
      "<div class='slop-similar'>LFM 7B (distance=0.717)</div>\n",
      "<div class='slop-similar'>Command A (distance=0.750)</div>\n",
      "<div class='slop-similar'>openai/gpt-4.1-nano (distance=0.750)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>glinted</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>shimmered</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>thrumming</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>keter</span> <span class='slop-word-item'>hargrove</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>furrowed</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>tousled</span> <span class='slop-word-item'>steadier</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>exhilaration</span> <span class='slop-word-item'>steadying</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>clinking</span> <span class='slop-word-item'>sparkled</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>igniting</span> <span class='slop-word-item'>mingling</span> <span class='slop-word-item'>ominously</span> <span class='slop-word-item'>gnawed</span> <span class='slop-word-item'>interjected</span> <span class='slop-word-item'>acrid</span> <span class='slop-word-item'>conspiratorial</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>glancing</span> <span class='slop-word-item'>flickers</span> <span class='slop-word-item'>falters</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>trudged</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>smirking</span> <span class='slop-word-item'>intoxicating</span> <span class='slop-word-item'>mischief</span> <span class='slop-word-item'>echoed</span> <span class='slop-word-item'>smirk</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>lacing</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>seeped</span> <span class='slop-word-item'>coursing</span> <span class='slop-word-item'>swirling</span> <span class='slop-word-item'>gaze</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Llama 3.1 405B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.1 405B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.1 405B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Llama 3.1 405B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.1 405B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.1 405B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Llama 3.1 405B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Llama 3.1 70B (distance=0.528)</div>\n",
      "<div class='slop-similar'>Llama 3.1 8B (distance=0.554)</div>\n",
      "<div class='slop-similar'>Llama 3.2 3B (distance=0.580)</div>\n",
      "<div class='slop-similar'>meta-llama/llama-4-maverick (distance=0.588)</div>\n",
      "<div class='slop-similar'>Llama 3.2 1B (distance=0.629)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>mirthless</span> <span class='slop-word-item'>kaelin</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>wafted</span> <span class='slop-word-item'>amnesiac</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>elyria</span> <span class='slop-word-item'>sparkled</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>erebus</span> <span class='slop-word-item'>frazzled</span> <span class='slop-word-item'>newhaven</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>snorted</span> <span class='slop-word-item'>darting</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>twinge</span> <span class='slop-word-item'>reeled</span> <span class='slop-word-item'>swirled</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>lingered</span> <span class='slop-word-item'>containment</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>creaking</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>rustling</span> <span class='slop-word-item'>trepidation</span> <span class='slop-word-item'>jolt</span> <span class='slop-word-item'>dimly</span> <span class='slop-word-item'>unyielding</span> <span class='slop-word-item'>eerie</span> <span class='slop-word-item'>clutched</span> <span class='slop-word-item'>piqued</span> <span class='slop-word-item'>nonchalant</span> <span class='slop-word-item'>makeshift</span> <span class='slop-word-item'>scribbled</span> <span class='slop-word-item'>gazed</span> <span class='slop-word-item'>glassy</span> <span class='slop-word-item'>gruff</span> <span class='slop-word-item'>anomalous</span> <span class='slop-word-item'>whispered</span> <span class='slop-word-item'>flicking</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### meta-llama/llama-4-maverick\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/meta-llama__llama-4-maverick__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/meta-llama__llama-4-maverick__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for meta-llama/llama-4-maverick' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/meta-llama__llama-4-maverick__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/meta-llama__llama-4-maverick__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for meta-llama/llama-4-maverick' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Llama 3.1 405B (distance=0.588)</div>\n",
      "<div class='slop-similar'>Llama 3.1 8B (distance=0.588)</div>\n",
      "<div class='slop-similar'>Llama 3.1 70B (distance=0.596)</div>\n",
      "<div class='slop-similar'>Llama 3.2 3B (distance=0.596)</div>\n",
      "<div class='slop-similar'>Llama 3.2 1B (distance=0.629)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>steepling</span> <span class='slop-word-item'>elara</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>wariness</span> <span class='slop-word-item'>crinkling</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>wafted</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>beeped</span> <span class='slop-word-item'>throaty</span> <span class='slop-word-item'>wavers</span> <span class='slop-word-item'>sparkled</span> <span class='slop-word-item'>labyrinthine</span> <span class='slop-word-item'>lingered</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>trepidation</span> <span class='slop-word-item'>vibrated</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>dimly</span> <span class='slop-word-item'>acrid</span> <span class='slop-word-item'>conspiratorial</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>creaking</span> <span class='slop-word-item'>wryly</span> <span class='slop-word-item'>wafting</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>clang</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>pang</span> <span class='slop-word-item'>jolt</span> <span class='slop-word-item'>snorts</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>swirled</span> <span class='slop-word-item'>burly</span> <span class='slop-word-item'>nonchalant</span> <span class='slop-word-item'>glimmer</span> <span class='slop-word-item'>navigated</span> <span class='slop-word-item'>scribbled</span> <span class='slop-word-item'>snorted</span> <span class='slop-word-item'>beeps</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>lingers</span> <span class='slop-word-item'>heaving</span> <span class='slop-word-item'>otherworldly</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Gemma 2 9B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 2 9B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 2 9B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Gemma 2 9B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 2 9B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Gemma 2 9B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Gemma 2 9B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Gemini 2.0 Flash (distance=0.659)</div>\n",
      "<div class='slop-similar'>LFM 7B (distance=0.681)</div>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.689)</div>\n",
      "<div class='slop-similar'>Gemma 3 Starshine 12B (distance=0.710)</div>\n",
      "<div class='slop-similar'>Gemma 3 Glitter 12B (distance=0.710)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>aethel</span> <span class='slop-word-item'>elara</span> <span class='slop-word-item'>kaito</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>cloying</span> <span class='slop-word-item'>purred</span> <span class='slop-word-item'>hulking</span> <span class='slop-word-item'>purrs</span> <span class='slop-word-item'>conspiratorial</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>throaty</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>silken</span> <span class='slop-word-item'>rasp</span> <span class='slop-word-item'>scoffs</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>saccharine</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>throngs</span> <span class='slop-word-item'>wiry</span> <span class='slop-word-item'>mumbled</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>swirling</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>guttural</span> <span class='slop-word-item'>hoarse</span> <span class='slop-word-item'>retorts</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>obsidian</span> <span class='slop-word-item'>shimmering</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>hushed</span> <span class='slop-word-item'>twinkling</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>laced</span> <span class='slop-word-item'>murmur</span> <span class='slop-word-item'>gravelly</span> <span class='slop-word-item'>trembling</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>gnawing</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>clung</span> <span class='slop-word-item'>whirlwind</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### LFM 7B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/LFM 7B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/LFM 7B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for LFM 7B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/LFM 7B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/LFM 7B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for LFM 7B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Gemma 2 9B (distance=0.681)</div>\n",
      "<div class='slop-similar'>GPT-4o Mini (distance=0.717)</div>\n",
      "<div class='slop-similar'>Gemini 2.0 Flash (distance=0.723)</div>\n",
      "<div class='slop-similar'>meta-llama/llama-4-maverick (distance=0.737)</div>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.743)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>glinted</span> <span class='slop-word-item'>crinkling</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>clinking</span> <span class='slop-word-item'>nonchalance</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>acrid</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>wariness</span> <span class='slop-word-item'>belied</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>scavenged</span> <span class='slop-word-item'>labyrinthine</span> <span class='slop-word-item'>undercurrent</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>unspoken</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>navigated</span> <span class='slop-word-item'>lingered</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>laced</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>rasp</span> <span class='slop-word-item'>piqued</span> <span class='slop-word-item'>fleeting</span> <span class='slop-word-item'>growled</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>fidgeting</span> <span class='slop-word-item'>pragmatist</span> <span class='slop-word-item'>dimly</span> <span class='slop-word-item'>creaking</span> <span class='slop-word-item'>elysium</span> <span class='slop-word-item'>otherworldly</span> <span class='slop-word-item'>infernal</span> <span class='slop-word-item'>unsettling</span> <span class='slop-word-item'>bustling</span> <span class='slop-word-item'>coiled</span> <span class='slop-word-item'>precariously</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>conspiratorial</span> <span class='slop-word-item'>grizzled</span> <span class='slop-word-item'>gravelly</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Llama 3.1 70B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.1 70B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.1 70B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Llama 3.1 70B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.1 70B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.1 70B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Llama 3.1 70B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Llama 3.1 405B (distance=0.528)</div>\n",
      "<div class='slop-similar'>Llama 3.2 3B (distance=0.528)</div>\n",
      "<div class='slop-similar'>Llama 3.1 8B (distance=0.545)</div>\n",
      "<div class='slop-similar'>Llama 3.2 1B (distance=0.571)</div>\n",
      "<div class='slop-similar'>meta-llama/llama-4-maverick (distance=0.596)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>sparkled</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>gleamed</span> <span class='slop-word-item'>wafted</span> <span class='slop-word-item'>akira</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>lyra</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>newhaven</span> <span class='slop-word-item'>impassive</span> <span class='slop-word-item'>warily</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>dimly</span> <span class='slop-word-item'>snorted</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>lingered</span> <span class='slop-word-item'>twinge</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>wavered</span> <span class='slop-word-item'>trepidation</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>darting</span> <span class='slop-word-item'>grizzled</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>faltered</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>swirled</span> <span class='slop-word-item'>pang</span> <span class='slop-word-item'>piqued</span> <span class='slop-word-item'>unyielding</span> <span class='slop-word-item'>nonchalant</span> <span class='slop-word-item'>unnerving</span> <span class='slop-word-item'>intently</span> <span class='slop-word-item'>makeshift</span> <span class='slop-word-item'>anomalous</span> <span class='slop-word-item'>unspoken</span> <span class='slop-word-item'>comms</span> <span class='slop-word-item'>navigated</span> <span class='slop-word-item'>creaking</span> <span class='slop-word-item'>dripping</span> <span class='slop-word-item'>glances</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>exertion</span> <span class='slop-word-item'>crackling</span> <span class='slop-word-item'>jolt</span> <span class='slop-word-item'>rustling</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### meta-llama/llama-4-scout\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/meta-llama__llama-4-scout__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/meta-llama__llama-4-scout__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for meta-llama/llama-4-scout' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/meta-llama__llama-4-scout__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/meta-llama__llama-4-scout__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for meta-llama/llama-4-scout' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>meta-llama/llama-4-maverick (distance=0.636)</div>\n",
      "<div class='slop-similar'>Llama 3.2 3B (distance=0.644)</div>\n",
      "<div class='slop-similar'>Llama 3.1 8B (distance=0.659)</div>\n",
      "<div class='slop-similar'>Llama 3.2 1B (distance=0.667)</div>\n",
      "<div class='slop-similar'>Llama 3.1 70B (distance=0.689)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>glinting</span> <span class='slop-word-item'>twinkled</span> <span class='slop-word-item'>crinkling</span> <span class='slop-word-item'>fidgeted</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>wafted</span> <span class='slop-word-item'>wariness</span> <span class='slop-word-item'>sparkled</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>lingered</span> <span class='slop-word-item'>wryly</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>clang</span> <span class='slop-word-item'>throaty</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>reeked</span> <span class='slop-word-item'>labyrinthine</span> <span class='slop-word-item'>ached</span> <span class='slop-word-item'>twinge</span> <span class='slop-word-item'>warily</span> <span class='slop-word-item'>anomalous</span> <span class='slop-word-item'>afoot</span> <span class='slop-word-item'>clanging</span> <span class='slop-word-item'>winced</span> <span class='slop-word-item'>trepidation</span> <span class='slop-word-item'>vibrate</span> <span class='slop-word-item'>quickened</span> <span class='slop-word-item'>snorted</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>reeled</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>vipers</span> <span class='slop-word-item'>newfound</span> <span class='slop-word-item'>darting</span> <span class='slop-word-item'>creaking</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>husky</span> <span class='slop-word-item'>glimmer</span> <span class='slop-word-item'>manipulator</span> <span class='slop-word-item'>coaxing</span> <span class='slop-word-item'>jolt</span> <span class='slop-word-item'>flickering</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Mistral Small 3.1 24B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Mistral Small 3.1 24B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Mistral Small 3.1 24B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Mistral Small 3.1 24B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Mistral Small 3.1 24B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Mistral Small 3.1 24B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Mistral Small 3.1 24B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Mistral Small 24B (distance=0.667)</div>\n",
      "<div class='slop-similar'>mistralai/mistral-large-2411 (distance=0.681)</div>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.681)</div>\n",
      "<div class='slop-similar'>Mistral Nemo (distance=0.696)</div>\n",
      "<div class='slop-similar'>Llama 3.1 8B (distance=0.723)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>steeling</span> <span class='slop-word-item'>gleamed</span> <span class='slop-word-item'>foghorn</span> <span class='slop-word-item'>sparkled</span> <span class='slop-word-item'>furrowed</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>grunted</span> <span class='slop-word-item'>shivered</span> <span class='slop-word-item'>lyra</span> <span class='slop-word-item'>blackwood</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>smirk</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>widened</span> <span class='slop-word-item'>sneer</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>fluttered</span> <span class='slop-word-item'>untamed</span> <span class='slop-word-item'>pounding</span> <span class='slop-word-item'>gruff</span> <span class='slop-word-item'>gnawing</span> <span class='slop-word-item'>unyielding</span> <span class='slop-word-item'>clanging</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>burly</span> <span class='slop-word-item'>curled</span> <span class='slop-word-item'>warily</span> <span class='slop-word-item'>belied</span> <span class='slop-word-item'>downcast</span> <span class='slop-word-item'>nods</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>coldness</span> <span class='slop-word-item'>buzzes</span> <span class='slop-word-item'>mournful</span> <span class='slop-word-item'>narrowed</span> <span class='slop-word-item'>disheveled</span> <span class='slop-word-item'>rustling</span> <span class='slop-word-item'>wavering</span> <span class='slop-word-item'>arcane</span> <span class='slop-word-item'>inscrutable</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>gleaming</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### openai/gpt-4-0314\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4-0314__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4-0314__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for openai/gpt-4-0314' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4-0314__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-4-0314__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for openai/gpt-4-0314' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.605)</div>\n",
      "<div class='slop-similar'>mistralai/mistral-large-2411 (distance=0.659)</div>\n",
      "<div class='slop-similar'>openai/gpt-3.5-turbo-0613 (distance=0.674)</div>\n",
      "<div class='slop-similar'>Llama 3.1 405B (distance=0.703)</div>\n",
      "<div class='slop-similar'>Mistral Nemo (distance=0.703)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>renn</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>foghorn</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>hesitates</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>grudging</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>sighed</span> <span class='slop-word-item'>glanced</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>dimly</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>containment</span> <span class='slop-word-item'>smirking</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>whispered</span> <span class='slop-word-item'>gleaming</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>unyielding</span> <span class='slop-word-item'>scribbled</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>flicking</span> <span class='slop-word-item'>piqued</span> <span class='slop-word-item'>makeshift</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>aback</span> <span class='slop-word-item'>trembling</span> <span class='slop-word-item'>euclid</span> <span class='slop-word-item'>pounding</span> <span class='slop-word-item'>grins</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>heaving</span> <span class='slop-word-item'>clenched</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>audible</span> <span class='slop-word-item'>narrowing</span> <span class='slop-word-item'>camaraderie</span> <span class='slop-word-item'>unspoken</span> <span class='slop-word-item'>eerie</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Llama 3.1 8B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.1 8B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.1 8B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Llama 3.1 8B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.1 8B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.1 8B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Llama 3.1 8B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Llama 3.2 3B (distance=0.519)</div>\n",
      "<div class='slop-similar'>Llama 3.1 70B (distance=0.545)</div>\n",
      "<div class='slop-similar'>Llama 3.2 1B (distance=0.545)</div>\n",
      "<div class='slop-similar'>Llama 3.1 405B (distance=0.554)</div>\n",
      "<div class='slop-similar'>meta-llama/llama-4-maverick (distance=0.588)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>crinkling</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>gleamed</span> <span class='slop-word-item'>sparkled</span> <span class='slop-word-item'>wafted</span> <span class='slop-word-item'>beeped</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>darting</span> <span class='slop-word-item'>labyrinthine</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>faltered</span> <span class='slop-word-item'>darted</span> <span class='slop-word-item'>trepidation</span> <span class='slop-word-item'>navigated</span> <span class='slop-word-item'>lingered</span> <span class='slop-word-item'>creaking</span> <span class='slop-word-item'>nonchalant</span> <span class='slop-word-item'>coaxing</span> <span class='slop-word-item'>quickened</span> <span class='slop-word-item'>twinge</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>snorted</span> <span class='slop-word-item'>alleyway</span> <span class='slop-word-item'>wavered</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>flicking</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>dimly</span> <span class='slop-word-item'>makeshift</span> <span class='slop-word-item'>scribbled</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>pang</span> <span class='slop-word-item'>growled</span> <span class='slop-word-item'>otherworldly</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>strode</span> <span class='slop-word-item'>gazed</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>jolt</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Mistral Small 24B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Mistral Small 24B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Mistral Small 24B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Mistral Small 24B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Mistral Small 24B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Mistral Small 24B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Mistral Small 24B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.659)</div>\n",
      "<div class='slop-similar'>Mistral Small 3.1 24B (distance=0.667)</div>\n",
      "<div class='slop-similar'>mistralai/mistral-large-2411 (distance=0.681)</div>\n",
      "<div class='slop-similar'>Mistral Nemo (distance=0.689)</div>\n",
      "<div class='slop-similar'>Llama 3.1 8B (distance=0.723)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>steeling</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>crackles</span> <span class='slop-word-item'>lyra</span> <span class='slop-word-item'>trickling</span> <span class='slop-word-item'>tensing</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>hummed</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>crackled</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>intoxicating</span> <span class='slop-word-item'>whirlwind</span> <span class='slop-word-item'>sneer</span> <span class='slop-word-item'>palpable</span> <span class='slop-word-item'>allure</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>narrowed</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>unyielding</span> <span class='slop-word-item'>unsettling</span> <span class='slop-word-item'>darting</span> <span class='slop-word-item'>raced</span> <span class='slop-word-item'>grizzled</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>carvings</span> <span class='slop-word-item'>growl</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>gripped</span> <span class='slop-word-item'>dimly</span> <span class='slop-word-item'>darted</span> <span class='slop-word-item'>coursing</span> <span class='slop-word-item'>rustling</span> <span class='slop-word-item'>gnawing</span> <span class='slop-word-item'>wavered</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>widened</span> <span class='slop-word-item'>bounty</span> <span class='slop-word-item'>haze</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>trembling</span> <span class='slop-word-item'>smirk</span> <span class='slop-word-item'>clatter</span> <span class='slop-word-item'>grimy</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Claude 3 Haiku\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3 Haiku__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3 Haiku__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Claude 3 Haiku' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3 Haiku__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Claude 3 Haiku__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Claude 3 Haiku' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>openai/gpt-4-0314 (distance=0.730)</div>\n",
      "<div class='slop-similar'>mistralai/pixtral-large-2411 (distance=0.737)</div>\n",
      "<div class='slop-similar'>Gemma 2 9B (distance=0.750)</div>\n",
      "<div class='slop-similar'>Mistral Small 24B (distance=0.756)</div>\n",
      "<div class='slop-similar'>mistralai/mistral-large-2411 (distance=0.763)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>whirred</span> <span class='slop-word-item'>furrowing</span> <span class='slop-word-item'>furrowed</span> <span class='slop-word-item'>murmured</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>purred</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>placating</span> <span class='slop-word-item'>amara</span> <span class='slop-word-item'>transfixed</span> <span class='slop-word-item'>kiran</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>acrid</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>warily</span> <span class='slop-word-item'>darting</span> <span class='slop-word-item'>shivered</span> <span class='slop-word-item'>glanced</span> <span class='slop-word-item'>sheepish</span> <span class='slop-word-item'>stammer</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>bustling</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>murmurs</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>nods</span> <span class='slop-word-item'>trepidation</span> <span class='slop-word-item'>exhilaration</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>glancing</span> <span class='slop-word-item'>dimly</span> <span class='slop-word-item'>cavernous</span> <span class='slop-word-item'>scavengers</span> <span class='slop-word-item'>brow</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>murmur</span> <span class='slop-word-item'>redacted</span> <span class='slop-word-item'>intently</span> <span class='slop-word-item'>paused</span> <span class='slop-word-item'>gesturing</span> <span class='slop-word-item'>leaned</span> <span class='slop-word-item'>creaking</span> <span class='slop-word-item'>hurried</span> <span class='slop-word-item'>pounding</span> <span class='slop-word-item'>blinked</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Llama 3.2 3B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.2 3B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.2 3B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Llama 3.2 3B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.2 3B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.2 3B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Llama 3.2 3B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Llama 3.1 8B (distance=0.519)</div>\n",
      "<div class='slop-similar'>Llama 3.1 70B (distance=0.528)</div>\n",
      "<div class='slop-similar'>Llama 3.2 1B (distance=0.554)</div>\n",
      "<div class='slop-similar'>Llama 3.1 405B (distance=0.580)</div>\n",
      "<div class='slop-similar'>meta-llama/llama-4-maverick (distance=0.596)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>crinkling</span> <span class='slop-word-item'>sparkled</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>wafted</span> <span class='slop-word-item'>gleamed</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>wariness</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>trudged</span> <span class='slop-word-item'>trepidation</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>dimly</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>snorted</span> <span class='slop-word-item'>labyrinthine</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>faltered</span> <span class='slop-word-item'>wavered</span> <span class='slop-word-item'>reeled</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>pang</span> <span class='slop-word-item'>weaved</span> <span class='slop-word-item'>nonchalant</span> <span class='slop-word-item'>cacophony</span> <span class='slop-word-item'>lingered</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>redacted</span> <span class='slop-word-item'>creaking</span> <span class='slop-word-item'>husky</span> <span class='slop-word-item'>anomalous</span> <span class='slop-word-item'>akira</span> <span class='slop-word-item'>jumbled</span> <span class='slop-word-item'>muttered</span> <span class='slop-word-item'>glimmer</span> <span class='slop-word-item'>narrowed</span> <span class='slop-word-item'>addendum</span> <span class='slop-word-item'>groaned</span> <span class='slop-word-item'>gazed</span> <span class='slop-word-item'>otherworldly</span> <span class='slop-word-item'>shivers</span> <span class='slop-word-item'>piqued</span> <span class='slop-word-item'>gleaming</span> <span class='slop-word-item'>widened</span> <span class='slop-word-item'>dripping</span> <span class='slop-word-item'>jolt</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### openai/gpt-3.5-turbo-0613\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-3.5-turbo-0613__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-3.5-turbo-0613__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for openai/gpt-3.5-turbo-0613' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-3.5-turbo-0613__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/openai__gpt-3.5-turbo-0613__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for openai/gpt-3.5-turbo-0613' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>openai/gpt-4-0314 (distance=0.674)</div>\n",
      "<div class='slop-similar'>Llama 3.1 70B (distance=0.756)</div>\n",
      "<div class='slop-similar'>Llama 3.1 405B (distance=0.769)</div>\n",
      "<div class='slop-similar'>Llama 3.2 1B (distance=0.769)</div>\n",
      "<div class='slop-similar'>Llama 3.1 8B (distance=0.776)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>flickered</span> <span class='slop-word-item'>stammered</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>smirks</span> <span class='slop-word-item'>dimly</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>lurked</span> <span class='slop-word-item'>flickering</span> <span class='slop-word-item'>unfazed</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>foreboding</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>bustling</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>rustling</span> <span class='slop-word-item'>crackling</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>mingling</span> <span class='slop-word-item'>swirling</span> <span class='slop-word-item'>desolate</span> <span class='slop-word-item'>gleaming</span> <span class='slop-word-item'>smirk</span> <span class='slop-word-item'>nervously</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>eerie</span> <span class='slop-word-item'>containment</span> <span class='slop-word-item'>glances</span> <span class='slop-word-item'>glimmer</span> <span class='slop-word-item'>whispered</span> <span class='slop-word-item'>suffocating</span> <span class='slop-word-item'>echoing</span> <span class='slop-word-item'>unwavering</span> <span class='slop-word-item'>evelyn</span> <span class='slop-word-item'>solace</span> <span class='slop-word-item'>sighed</span> <span class='slop-word-item'>whirlwind</span> <span class='slop-word-item'>pounding</span> <span class='slop-word-item'>newfound</span> <span class='slop-word-item'>mischief</span> <span class='slop-word-item'>makeshift</span> <span class='slop-word-item'>crumbling</span> <span class='slop-word-item'>sleek</span> <span class='slop-word-item'>widened</span> <span class='slop-word-item'>shadows</span> <span class='slop-word-item'>intrigued</span> <span class='slop-word-item'>outpost</span> <span class='slop-word-item'>glanced</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### Llama 3.2 1B\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.2 1B__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.2 1B__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for Llama 3.2 1B' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.2 1B__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/Llama 3.2 1B__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for Llama 3.2 1B' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>Llama 3.1 8B (distance=0.545)</div>\n",
      "<div class='slop-similar'>Llama 3.2 3B (distance=0.554)</div>\n",
      "<div class='slop-similar'>Llama 3.1 70B (distance=0.571)</div>\n",
      "<div class='slop-similar'>Llama 3.1 405B (distance=0.629)</div>\n",
      "<div class='slop-similar'>meta-llama/llama-4-maverick (distance=0.629)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>elara</span> <span class='slop-word-item'>glinting</span> <span class='slop-word-item'>arachne</span> <span class='slop-word-item'>crinkling</span> <span class='slop-word-item'>kael</span> <span class='slop-word-item'>erebus</span> <span class='slop-word-item'>creaked</span> <span class='slop-word-item'>twinge</span> <span class='slop-word-item'>flickered</span> <span class='slop-word-item'>unease</span> <span class='slop-word-item'>wariness</span> <span class='slop-word-item'>sparkled</span> <span class='slop-word-item'>trepidation</span> <span class='slop-word-item'>defensiveness</span> <span class='slop-word-item'>faltered</span> <span class='slop-word-item'>writhe</span> <span class='slop-word-item'>containment</span> <span class='slop-word-item'>shiver</span> <span class='slop-word-item'>nodded</span> <span class='slop-word-item'>otherworldly</span> <span class='slop-word-item'>narrowed</span> <span class='slop-word-item'>flashed</span> <span class='slop-word-item'>chuckled</span> <span class='slop-word-item'>dimly</span> <span class='slop-word-item'>hesitated</span> <span class='slop-word-item'>trudged</span> <span class='slop-word-item'>gravelly</span> <span class='slop-word-item'>glint</span> <span class='slop-word-item'>widened</span> <span class='slop-word-item'>grinned</span> <span class='slop-word-item'>unreadable</span> <span class='slop-word-item'>jolt</span> <span class='slop-word-item'>agonizing</span> <span class='slop-word-item'>takashi</span> <span class='slop-word-item'>pang</span> <span class='slop-word-item'>akira</span> <span class='slop-word-item'>darting</span> <span class='slop-word-item'>growled</span> <span class='slop-word-item'>nonchalant</span> <span class='slop-word-item'>husky</span> <span class='slop-word-item'>creaking</span> <span class='slop-word-item'>illuminating</span> <span class='slop-word-item'>snorted</span> <span class='slop-word-item'>gestured</span> <span class='slop-word-item'>intricately</span> <span class='slop-word-item'>conspiratorial</span> <span class='slop-word-item'>eyebrow</span> <span class='slop-word-item'>navigated</span> <span class='slop-word-item'>darted</span> <span class='slop-word-item'>gaze</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "\n",
      "##### unsloth/gemma-3-12b-it\n",
      "<div class='dendrogram-thumbnails'>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/unsloth__gemma-3-12b-it__phylo_tree_parsimony_circular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/unsloth__gemma-3-12b-it__phylo_tree_parsimony_circular.png' alt='Circular dendrogram for unsloth/gemma-3-12b-it' class='dendrogram-thumb circular-thumb' />\n",
      "    <span class='dendrogram-caption'>Circular View</span>\n",
      "  </a>\n",
      "  <a href='results/creative-writing-v3/hybrid_parsimony/charts/unsloth__gemma-3-12b-it__phylo_tree_parsimony_rectangular.png' target='_blank' class='dendrogram-link'>\n",
      "    <img src='results/creative-writing-v3/hybrid_parsimony/charts/unsloth__gemma-3-12b-it__phylo_tree_parsimony_rectangular.png' alt='Rectangular dendrogram for unsloth/gemma-3-12b-it' class='dendrogram-thumb rect-thumb' />\n",
      "    <span class='dendrogram-caption'>Rectangular View</span>\n",
      "  </a>\n",
      "</div>\n",
      "\n",
      "<h4>Most Similar To:</h4>\n",
      "<div class='slop-similar-section'>\n",
      "<div class='slop-similar'>openai/gpt-3.5-turbo-0613 (distance=0.947)</div>\n",
      "<div class='slop-similar'>Claude 3.5 Sonnet (distance=0.961)</div>\n",
      "<div class='slop-similar'>Gemma 3 12B (distance=0.961)</div>\n",
      "<div class='slop-similar'>Gemma 3 Starshine 12B (distance=0.966)</div>\n",
      "<div class='slop-similar'>Claude 3 Haiku (distance=0.966)</div>\n",
      "</div>\n",
      "\n",
      "<h4>Top Repetitive Words</h4>\n",
      "<div class='slop-section-items'>\n",
      "<span class='slop-word-item'>squeak</span> <span class='slop-word-item'>unsettling</span> <span class='slop-word-item'>radiating</span> <span class='slop-word-item'>flicker</span> <span class='slop-word-item'>tremor</span> <span class='slop-word-item'>relentless</span> <span class='slop-word-item'>crumbling</span> <span class='slop-word-item'>paused</span> <span class='slop-word-item'>gaze</span> <span class='slop-word-item'>defiance</span> <span class='slop-word-item'>damp</span> <span class='slop-word-item'>adapting</span> <span class='slop-word-item'>scent</span> <span class='slop-word-item'>vulnerability</span> <span class='slop-word-item'>eleanor</span> <span class='slop-word-item'>smiled</span> <span class='slop-word-item'>brutal</span> <span class='slop-word-item'>shadows</span> <span class='slop-word-item'>aimed</span> <span class='slop-word-item'>entities</span> <span class='slop-word-item'>civilization</span> <span class='slop-word-item'>surprisingly</span> <span class='slop-word-item'>marcus</span> <span class='slop-word-item'>judging</span> <span class='slop-word-item'>barely</span> <span class='slop-word-item'>habit</span> <span class='slop-word-item'>sweat</span> <span class='slop-word-item'>subtle</span> <span class='slop-word-item'>desperate</span> <span class='slop-word-item'>hung</span> <span class='slop-word-item'>forcing</span> <span class='slop-word-item'>smile</span> <span class='slop-word-item'>recovered</span> <span class='slop-word-item'>designated</span> <span class='slop-word-item'>arena</span> <span class='slop-word-item'>movements</span> <span class='slop-word-item'>sharp</span> <span class='slop-word-item'>rapid</span> <span class='slop-word-item'>expression</span> <span class='slop-word-item'>silence</span> <span class='slop-word-item'>dust</span> <span class='slop-word-item'>familiar</span> <span class='slop-word-item'>lips</span> <span class='slop-word-item'>stomach</span> <span class='slop-word-item'>voice</span> <span class='slop-word-item'>strike</span> <span class='slop-word-item'>landscape</span> <span class='slop-word-item'>seed</span> <span class='slop-word-item'>silent</span> <span class='slop-word-item'>pattern</span>\n",
      "</div>\n",
      "<h4>Top Bigrams</h4>\n",
      "<p><i>No multi-prompt bigrams found.</i></p>\n",
      "<h4>Top Trigrams</h4>\n",
      "<p><i>No multi-prompt trigrams found.</i></p>\n",
      "----- END SLOP PROFILE STRING -----\n",
      "\n",
      "\n",
      "Generating and saving HTML reports for all models...\n",
      "Processing report for: o3\n",
      "Report saved to results/o3.html\n",
      "Processing report for: DeepSeek R1\n",
      "Report saved to results/DeepSeek R1.html\n",
      "Processing report for: DeepSeek Chat v3\n",
      "Report saved to results/DeepSeek Chat v3.html\n",
      "Processing report for: ChatGPT-4o Latest\n",
      "Report saved to results/ChatGPT-4o Latest.html\n",
      "Processing report for: openai/gpt-4.1\n",
      "Report saved to results/openai__gpt-4.1.html\n",
      "Processing report for: openrouter/optimus-alpha\n",
      "Report saved to results/openrouter__optimus-alpha.html\n",
      "Processing report for: Gemini 2.5 Pro Exp\n",
      "Report saved to results/Gemini 2.5 Pro Exp.html\n",
      "Processing report for: Claude 3.5 Sonnet\n",
      "Report saved to results/Claude 3.5 Sonnet.html\n",
      "Processing report for: ChatGPT-4o Latest\n",
      "Report saved to results/ChatGPT-4o Latest.html\n",
      "Processing report for: openrouter/quasar-alpha\n",
      "Report saved to results/openrouter__quasar-alpha.html\n",
      "Processing report for: Reka Flash 3 (Free)\n",
      "Report saved to results/Reka Flash 3 (Free).html\n",
      "Processing report for: QwQ 32B\n",
      "Report saved to results/QwQ 32B.html\n",
      "Processing report for: Claude 3.7 Sonnet\n",
      "Report saved to results/Claude 3.7 Sonnet.html\n",
      "Processing report for: Gemma 3 27B\n",
      "Report saved to results/Gemma 3 27B.html\n",
      "Processing report for: GPT-4.5 Preview\n",
      "Report saved to results/GPT-4.5 Preview.html\n",
      "Processing report for: Grok 3 Beta\n",
      "Report saved to results/Grok 3 Beta.html\n",
      "Processing report for: openai/gpt-4.1-mini\n",
      "Report saved to results/openai__gpt-4.1-mini.html\n",
      "Processing report for: Command A\n",
      "Report saved to results/Command A.html\n",
      "Processing report for: Claude 3.5 Haiku\n",
      "Report saved to results/Claude 3.5 Haiku.html\n",
      "Processing report for: Darkest Muse v1\n",
      "Report saved to results/Darkest Muse v1.html\n",
      "Processing report for: Gemma 3 12B\n",
      "Report saved to results/Gemma 3 12B.html\n",
      "Processing report for: Gemma 3 Glitter 12B\n",
      "Report saved to results/Gemma 3 Glitter 12B.html\n",
      "Processing report for: Gemini 2.0 Flash\n",
      "Report saved to results/Gemini 2.0 Flash.html\n",
      "Processing report for: Gemma 3 4B\n",
      "Report saved to results/Gemma 3 4B.html\n",
      "Processing report for: Gemma 2 Ifable 9B\n",
      "Report saved to results/Gemma 2 Ifable 9B.html\n",
      "Processing report for: accounts/fireworks/models/deepseek-v3\n",
      "Report saved to results/accounts__fireworks__models__deepseek-v3.html\n",
      "Processing report for: openai/gpt-4.1-nano\n",
      "Report saved to results/openai__gpt-4.1-nano.html\n",
      "Processing report for: mistralai/mistral-large-2411\n",
      "Report saved to results/mistralai__mistral-large-2411.html\n",
      "Processing report for: mistralai/pixtral-large-2411\n",
      "Report saved to results/mistralai__pixtral-large-2411.html\n",
      "Processing report for: Gemma 3 Starshine 12B\n",
      "Report saved to results/Gemma 3 Starshine 12B.html\n",
      "Processing report for: Mistral Nemo\n",
      "Report saved to results/Mistral Nemo.html\n",
      "Processing report for: GPT-4o Mini\n",
      "Report saved to results/GPT-4o Mini.html\n",
      "Processing report for: Llama 3.1 405B\n",
      "Report saved to results/Llama 3.1 405B.html\n",
      "Processing report for: meta-llama/llama-4-maverick\n",
      "Report saved to results/meta-llama__llama-4-maverick.html\n",
      "Processing report for: Gemma 2 9B\n",
      "Report saved to results/Gemma 2 9B.html\n",
      "Processing report for: LFM 7B\n",
      "Report saved to results/LFM 7B.html\n",
      "Processing report for: Llama 3.1 70B\n",
      "Report saved to results/Llama 3.1 70B.html\n",
      "Processing report for: meta-llama/llama-4-scout\n",
      "Report saved to results/meta-llama__llama-4-scout.html\n",
      "Processing report for: Mistral Small 3.1 24B\n",
      "Report saved to results/Mistral Small 3.1 24B.html\n",
      "Processing report for: openai/gpt-4-0314\n",
      "Report saved to results/openai__gpt-4-0314.html\n",
      "Processing report for: Llama 3.1 8B\n",
      "Report saved to results/Llama 3.1 8B.html\n",
      "Processing report for: Mistral Small 24B\n",
      "Report saved to results/Mistral Small 24B.html\n",
      "Processing report for: Claude 3 Haiku\n",
      "Report saved to results/Claude 3 Haiku.html\n",
      "Processing report for: Llama 3.2 3B\n",
      "Report saved to results/Llama 3.2 3B.html\n",
      "Processing report for: openai/gpt-3.5-turbo-0613\n",
      "Report saved to results/openai__gpt-3.5-turbo-0613.html\n",
      "Processing report for: Llama 3.2 1B\n",
      "Report saved to results/Llama 3.2 1B.html\n",
      "\n",
      "Finished saving reports.\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from core.metrics import calculate_repetition_metric, get_top_repetitive_words, get_multi_prompt_ngrams, calculate_slop_index_new\n",
    "\n",
    "# --- Add core directory to Python path ---\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath('./')) # Assumes running from parent dir of script\n",
    "CORE_DIR = os.path.join(SCRIPT_DIR, 'core')\n",
    "if CORE_DIR not in sys.path:\n",
    "    sys.path.insert(0, CORE_DIR)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Helper function to update model name if a substitution exists ---\n",
    "def get_updated_model_name(original: str) -> str:\n",
    "    return MODEL_NAME_SUBS.get(original, original)\n",
    "\n",
    "# --- Import metrics functions ---\n",
    "try:\n",
    "    from core.metrics import calculate_slop_index, calculate_complexity_index\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing metrics from core.metrics: {e}\", file=sys.stderr)\n",
    "    print(\"Please ensure core/metrics.py exists and is in the Python path.\", file=sys.stderr)\n",
    "    # Define dummy functions if import fails to avoid crashing later\n",
    "    def calculate_slop_index(text: str) -> float: return -1.0\n",
    "    def calculate_complexity_index(text: str) -> float: return -1.0\n",
    "\n",
    "# Config variables\n",
    "RUNS_FILE = \"creative_bench_runs.json\"\n",
    "#RUNS_FILE = \"repro_testing.json\"\n",
    "ELO_RESULTS_FILE = \"elo_results.json\"\n",
    "ELO_RESULTS_UPDATED_FILE = \"elo_results_with_metrics_repro.json\"\n",
    "\n",
    "PROMPTS_ORDER = [\n",
    "    \"25\", \"9\", \"8\", \"33\", \"31\", \"4\", \"3\", \"32\", \"20\", \"30\",\n",
    "    \"15\", \"19\", \"18\", \"7\", \"28\", \"6\", \"5\", \"16\", \"1\", \"2\",\n",
    "    \"10\", \"11\", \"12\", \"13\", \"14\", \"17\", \"21\", \"22\", \"23\",\n",
    "    \"24\", \"26\", \"29\"\n",
    "]\n",
    "\n",
    "# --- Existing Functions (load_json_file, sanitize_model_name, etc.) ---\n",
    "def load_json_file(file_path: str) -> Dict:\n",
    "    \"\"\"Load data from a JSON file.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            return json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON from {file_path}\")\n",
    "            return {}\n",
    "\n",
    "def sanitize_model_name(model_name: str) -> str:\n",
    "    \"\"\"Sanitize model name for use in filenames.\"\"\"\n",
    "    sanitized = model_name.replace(\"/\", \"__\")\n",
    "    unsafe_chars = r'<>:\"|?*\\\\'\n",
    "    for char in unsafe_chars:\n",
    "        sanitized = sanitized.replace(char, '-')\n",
    "    return sanitized\n",
    "\n",
    "def calculate_creative_writing_scores(runs_data: Dict, model_name: str) -> Tuple[float, Dict]:\n",
    "    \"\"\"\n",
    "    Calculate the creative writing scores for a model using the same methodology as generate_model_report.\n",
    "    \n",
    "    Args:\n",
    "        runs_data: The dictionary containing all run data\n",
    "        model_name: The name of the model to calculate the score for\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (overall_average_score, iterations_dict)\n",
    "        where iterations_dict maps iteration IDs to their score and prompts\n",
    "    \"\"\"\n",
    "    # Get negative criteria if available\n",
    "    neg_criteria = []\n",
    "    try:\n",
    "        neg_criteria_file = 'data/negative_criteria.txt'\n",
    "        if os.path.exists(neg_criteria_file):\n",
    "            with open(neg_criteria_file, 'r') as f:\n",
    "                neg_criteria = [line.strip().lower() for line in list(f.readlines())]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {neg_criteria_file} not found. Negative criteria scoring adjustment will not be applied.\")\n",
    "    \n",
    "    # Find matching runs for the model\n",
    "    matching_runs = [k for k, v in runs_data.items() if v.get(\"test_model\") == model_name]\n",
    "    if not matching_runs:\n",
    "        return 0.0, {}\n",
    "    \n",
    "    # Use the most recent run\n",
    "    run_key = matching_runs[-1]\n",
    "    run_data = runs_data[run_key]\n",
    "    \n",
    "    creative_tasks = run_data.get(\"creative_tasks\", {})\n",
    "    if not creative_tasks:\n",
    "        return 0.0, {}\n",
    "    \n",
    "    # Calculate scores by iteration\n",
    "    iterations = {}\n",
    "    total_score_sum = 0\n",
    "    total_score_count = 0\n",
    "    \n",
    "    for iter_idx, prompt_data in creative_tasks.items():\n",
    "        iter_score_sum = 0\n",
    "        iter_score_count = 0\n",
    "        \n",
    "        for prompt_id, task_data in prompt_data.items():\n",
    "            if task_data.get(\"status\") not in [\"completed\", \"judged\"]:\n",
    "                continue\n",
    "            \n",
    "            results_by_mod = task_data.get(\"results_by_modifier\", {})\n",
    "            for seed_mod, block in results_by_mod.items():\n",
    "                j_scores = block.get(\"judge_scores\", {})\n",
    "                for metric, val in j_scores.items():\n",
    "                    if isinstance(val, (int, float)) and val <= 20:\n",
    "                        score_val = (20 - val) if metric.lower() in neg_criteria else val\n",
    "                        iter_score_sum += score_val\n",
    "                        iter_score_count += 1\n",
    "                        total_score_sum += score_val\n",
    "                        total_score_count += 1\n",
    "        \n",
    "        iterations[iter_idx] = {\n",
    "            \"score\": round(iter_score_sum / iter_score_count, 2) if iter_score_count > 0 else 0,\n",
    "            \"prompts\": prompt_data\n",
    "        }\n",
    "    \n",
    "    overall_avg_score = round(total_score_sum / total_score_count, 2) if total_score_count > 0 else 0.0\n",
    "    return overall_avg_score, iterations\n",
    "\n",
    "def generate_model_report(model_name: str, run_key: Optional[str] = None, save_to_file: bool = False) -> HTML:\n",
    "    \"\"\"\n",
    "    Generate an HTML report for a specific model with theme and font selection,\n",
    "    including a back button and dark mode toggle.\n",
    "\n",
    "    Args:\n",
    "        model_name: The name of the model to generate the report for\n",
    "        run_key: Optional specific run key to use\n",
    "        save_to_file: Whether to save the report to an HTML file\n",
    "\n",
    "    Returns:\n",
    "        An HTML object containing the report\n",
    "    \"\"\"\n",
    "    # --- Data Loading and Processing (Identical to previous version) ---\n",
    "    runs_data = load_json_file(RUNS_FILE)\n",
    "    elo_data = load_json_file(ELO_RESULTS_FILE)\n",
    "\n",
    "    if run_key is None:\n",
    "        matching_runs = [k for k, v in runs_data.items() if v.get(\"test_model\") == model_name]\n",
    "        if not matching_runs:\n",
    "            return HTML(f\"<h2>No runs found for model: {model_name}</h2>\")\n",
    "        run_key = matching_runs[-1]\n",
    "\n",
    "    if run_key not in runs_data:\n",
    "        return HTML(f\"<h2>Run key not found: {run_key}</h2>\")\n",
    "\n",
    "    run_data = runs_data[run_key]\n",
    "    original_model_name = run_data.get(\"test_model\", model_name)\n",
    "    display_model_name = get_updated_model_name(original_model_name) # Use updated name for display\n",
    "\n",
    "    creative_tasks = run_data.get(\"creative_tasks\", {})\n",
    "    if not creative_tasks:\n",
    "        return HTML(f\"<h2>No creative tasks found for run: {run_key}</h2>\")\n",
    "\n",
    "    # --- Data Processing ---\n",
    "    creative_prompts = {}\n",
    "    try:\n",
    "        # Adjust path relative to SCRIPT_DIR if needed\n",
    "        creative_prompts_file = run_data.get(\"creative_prompts_file\", os.path.join(SCRIPT_DIR, \"data/creative_writing_prompts_v3.json\"))\n",
    "        if os.path.exists(creative_prompts_file):\n",
    "            creative_prompts = load_json_file(creative_prompts_file)\n",
    "        else:\n",
    "             print(f\"Warning: Creative prompts file not found at {creative_prompts_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load creative prompts: {str(e)}\")\n",
    "\n",
    "    # Use the new function to calculate overall score and iterations\n",
    "    overall_avg_score, iterations = calculate_creative_writing_scores(runs_data, model_name)\n",
    "    \n",
    "    # Sort iterations by score (descending)\n",
    "    sorted_iterations = sorted(iterations.items(), key=lambda x: x[1][\"score\"], reverse=True)\n",
    "    # --- End Data Processing ---\n",
    "\n",
    "    # --- HTML Generation with Themes, Fonts, Back Button, Dark Mode ---\n",
    "    html_output = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Model Outputs: {display_model_name}</title>\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "        <style>\n",
    "            /* ----------------------------------------------------\n",
    "            1) Font Imports & Face Definitions\n",
    "            ---------------------------------------------------- */\n",
    "            /* Lora (Used for Cozy Headers) */\n",
    "            @import url('https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400..700;1,400..700&display=swap');\n",
    "            /* Merriweather (Used for Modern Headers - fallback) */\n",
    "            @import url('https://fonts.googleapis.com/css2?family=Merriweather:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap');\n",
    "\n",
    "            /* Dynamic font loading will be handled with JavaScript */\n",
    "            /* We'll keep the font declarations in CSS for fallback purposes in case JS fails */\n",
    "\n",
    "            /* ----------------------------------------------------\n",
    "            2) Base Variables & Font Defaults\n",
    "            ---------------------------------------------------- */\n",
    "            :root {{\n",
    "                /* Default Theme: Cozy Light */\n",
    "                --theme-name: 'cozy'; /* JS uses this */\n",
    "\n",
    "                /* Fonts */\n",
    "                --font-body-cozy: 'Tiempos Text', Georgia, serif;\n",
    "                --font-heading-cozy: 'Lora', serif;\n",
    "                --font-body-modern: 'Inter', sans-serif; /* Changed modern default body */\n",
    "                --font-heading-modern: 'Besley', 'Merriweather', serif;\n",
    "                --font-ui: 'Lora', sans-serif; /* For controls */\n",
    "\n",
    "                /* Default to Cozy fonts */\n",
    "                --font-body: var(--font-body-cozy);\n",
    "                --font-heading: var(--font-heading-cozy);\n",
    "\n",
    "                /* Cozy Light Colors */\n",
    "                --bg-color: #fdfaf6;\n",
    "                --text-color: #3a3a3a;\n",
    "                --header-color: #5c4033;\n",
    "                --subheader-color: #7a6a60;\n",
    "                --border-color: #e0dcd1;\n",
    "                --accent-border-color: #d3c0a5;\n",
    "                --container-bg: #fffcf7;\n",
    "                --iter-header-bg: #f5f0e8;\n",
    "                --iter-header-hover-bg: #ede8de;\n",
    "                --prompt-header-bg: #faf5ef;\n",
    "                --prompt-header-hover-bg: #f5f0e8;\n",
    "                --judge-bg: #f3f6f9;\n",
    "                --judge-border: #c8d7e6;\n",
    "                --judge-text: #555;\n",
    "                --prompt-display-bg: #f9f6f0;\n",
    "                --toggle-icon-color: #8a7a70;\n",
    "                --shadow-color: rgba(0, 0, 0, 0.08);\n",
    "                --link-color: #7a6a60;\n",
    "                --link-hover-color: #5c4033;\n",
    "                --toggle-bg: #ccc; /* Not used visually now */\n",
    "                --toggle-checked-bg: #7a6a60; /* Not used visually now */\n",
    "                --toggle-knob-bg: white; /* Not used visually now */\n",
    "                --select-text-color: var(--subheader-color);\n",
    "                --select-chevron-color: var(--subheader-color);\n",
    "                --select-bg: transparent;\n",
    "                --select-border: none;\n",
    "            }}\n",
    "\n",
    "            /* ----------------------------------------------------\n",
    "            3) Cozy Dark Mode Variables\n",
    "            ---------------------------------------------------- */\n",
    "            body.theme-cozy.dark-mode {{\n",
    "                --bg-color: #2a2527;\n",
    "                --text-color: #fff9f2;\n",
    "                --header-color: #f7eee0;\n",
    "                --subheader-color: #e9dfd0;\n",
    "                --border-color: #3e3936;\n",
    "                --accent-border-color: #6a5349;\n",
    "                --container-bg: #312c2e;\n",
    "                --iter-header-bg: #342e2f;\n",
    "                --iter-header-hover-bg: #413935;\n",
    "                --prompt-header-bg: #312b2d;\n",
    "                --prompt-header-hover-bg: #3a3234;\n",
    "                --judge-bg: #2f3136;\n",
    "                --judge-border: #4e4944;\n",
    "                --judge-text: #fcf5eb;\n",
    "                --prompt-display-bg: #302a2c;\n",
    "                --toggle-icon-color: #c0b0a0;\n",
    "                --shadow-color: #0c0705;\n",
    "                --link-color: #d0bca8;\n",
    "                --link-hover-color: #ebdac5;\n",
    "                --toggle-bg: #524740; /* Not used visually now */\n",
    "                --toggle-checked-bg: #9a8778; /* Not used visually now */\n",
    "                --toggle-knob-bg: #ede6dc; /* Not used visually now */\n",
    "                --select-text-color: var(--subheader-color);\n",
    "                --select-chevron-color: var(--subheader-color);\n",
    "            }}\n",
    "\n",
    "            /* ----------------------------------------------------\n",
    "            4) Modern Theme Variables (Light & Dark)\n",
    "            ---------------------------------------------------- */\n",
    "            body.theme-modern {{\n",
    "                --theme-name: 'modern'; /* JS uses this */\n",
    "\n",
    "                /* Fonts */\n",
    "                --font-body: var(--font-body-modern);\n",
    "                --font-heading: var(--font-heading-modern);\n",
    "\n",
    "                /* Modern Light Colors */\n",
    "                --bg-color: #ffffff;\n",
    "                --text-color: #212529;\n",
    "                --header-color: #000000;\n",
    "                --subheader-color: #495057;\n",
    "                --border-color: #dee2e6;\n",
    "                --accent-border-color: #adb5bd;\n",
    "                --container-bg: #ffffff;\n",
    "                --iter-header-bg: #f8f9fa;\n",
    "                --iter-header-hover-bg: #e9ecef;\n",
    "                --prompt-header-bg: #ffffff;\n",
    "                --prompt-header-hover-bg: #f8f9fa;\n",
    "                --judge-bg: #f1f3f5;\n",
    "                --judge-border: #ced4da;\n",
    "                --judge-text: #343a40;\n",
    "                --prompt-display-bg: #f8f9fa;\n",
    "                --toggle-icon-color: #6c757d;\n",
    "                --shadow-color: rgba(0, 0, 0, 0.1);\n",
    "                --link-color: #007bff;\n",
    "                --link-hover-color: #0056b3;\n",
    "                --toggle-bg: #ced4da; /* Not used visually now */\n",
    "                --toggle-checked-bg: #007bff; /* Not used visually now */\n",
    "                --toggle-knob-bg: white; /* Not used visually now */\n",
    "                --select-text-color: var(--subheader-color);\n",
    "                --select-chevron-color: var(--subheader-color);\n",
    "            }}\n",
    "\n",
    "            body.theme-modern.dark-mode {{\n",
    "                /* Modern Dark Colors */\n",
    "                --bg-color: #1a1a1a;\n",
    "                --text-color: #e9ecef;\n",
    "                --header-color: #ffffff;\n",
    "                --subheader-color: #adb5bd;\n",
    "                --border-color: #495057;\n",
    "                --accent-border-color: #6c757d;\n",
    "                --container-bg: #212529;\n",
    "                --iter-header-bg: #343a40;\n",
    "                --iter-header-hover-bg: #495057;\n",
    "                --prompt-header-bg: #2c3034;\n",
    "                --prompt-header-hover-bg: #343a40;\n",
    "                --judge-bg: #343a40;\n",
    "                --judge-border: #495057;\n",
    "                --judge-text: #ced4da;\n",
    "                --prompt-display-bg: #343a40;\n",
    "                --toggle-icon-color: #adb5bd;\n",
    "                --shadow-color: rgba(0, 0, 0, 0.3);\n",
    "                --link-color: #69b1ff;\n",
    "                --link-hover-color: #a8d1ff;\n",
    "                --toggle-bg: #495057; /* Not used visually now */\n",
    "                --toggle-checked-bg: #0d6efd; /* Not used visually now */\n",
    "                --toggle-knob-bg: #dee2e6; /* Not used visually now */\n",
    "                --select-text-color: var(--subheader-color);\n",
    "                --select-chevron-color: var(--subheader-color);\n",
    "            }}\n",
    "\n",
    "\n",
    "            /* ----------------------------------------------------\n",
    "            5) Base Global Styles (Theme Independent)\n",
    "            ---------------------------------------------------- */\n",
    "            body {{\n",
    "                font-family: var(--font-body);\n",
    "                line-height: 1.7;\n",
    "                color: var(--text-color);\n",
    "                background-color: var(--bg-color);\n",
    "                max-width: 900px;\n",
    "                margin: 30px auto;\n",
    "                padding: 40px 50px;\n",
    "                border: 1px solid var(--border-color);\n",
    "                box-shadow: 0 5px 15px var(--shadow-color);\n",
    "                transition: background-color 0.3s, color 0.3s, border-color 0.3s;\n",
    "            }}\n",
    "            h1, h2, h3, h4 {{\n",
    "                font-family: var(--font-heading);\n",
    "                color: var(--header-color);\n",
    "                margin-top: 2em;\n",
    "                margin-bottom: 0.8em;\n",
    "                line-height: 1.3;\n",
    "                transition: color 0.3s;\n",
    "            }}\n",
    "            h1 {{\n",
    "                text-align: center;\n",
    "                font-size: 2.5em;\n",
    "                border-bottom: 2px solid var(--accent-border-color);\n",
    "                padding-bottom: 15px;\n",
    "                margin-bottom: 1.5em;\n",
    "                font-weight: 700;\n",
    "                transition: border-color 0.3s;\n",
    "                font-family: var(--font-ui) !important; /* Keep title in UI font */\n",
    "            }}\n",
    "            h2 {{\n",
    "                font-size: 1.8em;\n",
    "                font-weight: 700;\n",
    "            }}\n",
    "            h3 {{\n",
    "                font-size: 1.4em;\n",
    "                font-style: italic;\n",
    "                font-weight: 400;\n",
    "                color: var(--subheader-color);\n",
    "            }}\n",
    "            strong {{\n",
    "                font-weight: bold;\n",
    "                color: var(--header-color);\n",
    "                transition: color 0.3s;\n",
    "            }}\n",
    "            a {{\n",
    "                color: var(--link-color);\n",
    "                text-decoration: none;\n",
    "                transition: color 0.3s;\n",
    "            }}\n",
    "            a:hover {{\n",
    "                color: var(--link-hover-color);\n",
    "                text-decoration: underline;\n",
    "            }}\n",
    "            .top-controls {{\n",
    "                display: flex;\n",
    "                justify-content: space-between; /* Align items to opposite ends */\n",
    "                align-items: center;\n",
    "                margin-bottom: 20px;\n",
    "                padding-bottom: 10px;\n",
    "                border-bottom: 1px solid var(--border-color);\n",
    "                transition: border-color 0.3s;\n",
    "                font-family: var(--font-ui) !important; /* Keep controls in UI font */\n",
    "            }}\n",
    "            .back-button {{\n",
    "                font-family: var(--font-ui) !important;\n",
    "                font-size: 1em;\n",
    "                color: var(--select-text-color); /* Add this line to match other nav elements */\n",
    "                transition: color 0.3s; /* Add transition for smooth theme changes */\n",
    "            }}\n",
    "            \n",
    "            /* Controls right side container */\n",
    "            .controls-right {{\n",
    "                display: flex;\n",
    "                align-items: center;\n",
    "                gap: 15px; /* Space between controls */\n",
    "            }}\n",
    "\n",
    "            /* ----------------------------------------------------\n",
    "            6) Theme Specific Overrides & Effects\n",
    "            ---------------------------------------------------- */\n",
    "\n",
    "            /* Cozy Theme Specifics */\n",
    "            body.theme-cozy {{\n",
    "                /* Existing body styles are cozy defaults */\n",
    "            }}\n",
    "            body.theme-cozy.dark-mode {{\n",
    "                box-shadow: 0 5px 20px var(--shadow-color);\n",
    "                background-image: linear-gradient(to bottom, #211f21, #232022);\n",
    "            }}\n",
    "            body.theme-cozy.dark-mode .iteration-container {{\n",
    "                box-shadow: 0 2px 8px #000000;\n",
    "                border-color: var(--border-color);\n",
    "            }}\n",
    "            body.theme-cozy.dark-mode h1 {{\n",
    "                text-shadow: 0 1px 2px #000000;\n",
    "            }}\n",
    "            body.theme-cozy.dark-mode .content-block {{\n",
    "                border-color: var(--border-color);\n",
    "            }}\n",
    "            body.theme-cozy.dark-mode .prompt-text-display {{\n",
    "                border-left: 3px solid var(--accent-border-color);\n",
    "                background-color: #362e2b;\n",
    "            }}\n",
    "            body.theme-cozy.dark-mode .scores-container {{\n",
    "                color: #b0a598;\n",
    "            }}\n",
    "\n",
    "            /* Modern Theme Specifics */\n",
    "            body.theme-modern {{\n",
    "                padding: 35px 45px;\n",
    "            }}\n",
    "            body.theme-modern h1 {{\n",
    "                font-weight: 600;\n",
    "                border-bottom-width: 1px;\n",
    "            }}\n",
    "            body.theme-modern h2 {{\n",
    "                font-weight: 600;\n",
    "            }}\n",
    "            body.theme-modern h3 {{\n",
    "                font-weight: 500; /* Use Medium for Inter/Modern */\n",
    "                font-style: normal;\n",
    "            }}\n",
    "            body.theme-modern .iteration-header {{\n",
    "                font-weight: 600; /* Besley */\n",
    "            }}\n",
    "            body.theme-modern .prompt-header {{\n",
    "                font-weight: 500; /* Besley */\n",
    "                font-style: normal;\n",
    "            }}\n",
    "            body.theme-modern .prompt-text-display {{\n",
    "                border-left-width: 4px;\n",
    "                border-radius: 3px;\n",
    "                font-style: normal; /* Modern prompt less italic */\n",
    "            }}\n",
    "            body.theme-modern .judge-content {{\n",
    "                border-style: solid;\n",
    "                border-width: 1px;\n",
    "            }}\n",
    "            body.theme-modern strong {{\n",
    "                font-weight: 600; /* Use SemiBold for Inter/Modern */\n",
    "            }}\n",
    "\n",
    "\n",
    "            /* ----------------------------------------------------\n",
    "            7) Components / Containers (Theme Independent Styles)\n",
    "            ---------------------------------------------------- */\n",
    "\n",
    "            /* --- Selectors (Theme, Font) --- */\n",
    "            .control-select-wrapper {{\n",
    "                position: relative;\n",
    "                display: inline-block;\n",
    "            }}\n",
    "            .control-select {{\n",
    "                font-family: var(--font-ui) !important;\n",
    "                font-size: 0.9em;\n",
    "                color: var(--select-text-color);\n",
    "                background-color: var(--select-bg);\n",
    "                border: none;\n",
    "                padding: 2px 5px 2px 18px; /* top/bottom, right, left (space for chevron) */\n",
    "                margin: 0;\n",
    "                cursor: pointer;\n",
    "                appearance: none;\n",
    "                -webkit-appearance: none;\n",
    "                -moz-appearance: none;\n",
    "                transition: color 0.3s;\n",
    "                border-radius: 0; /* Ensure no default rounding */\n",
    "            }}\n",
    "            .control-select:focus {{\n",
    "                outline: none;\n",
    "            }}\n",
    "            /* Custom Chevron */\n",
    "            .control-select-wrapper::before {{ /* Changed from ::after */\n",
    "                content: '▼';\n",
    "                font-size: 0.6em;\n",
    "                color: var(--select-chevron-color);\n",
    "                position: absolute;\n",
    "                left: 5px; /* Position on the left */\n",
    "                top: 50%;\n",
    "                transform: translateY(-50%);\n",
    "                pointer-events: none;\n",
    "                transition: color 0.3s;\n",
    "            }}\n",
    "            .control-select option {{\n",
    "                background-color: var(--bg-color);\n",
    "                color: var(--text-color);\n",
    "                font-family: var(--font-ui); /* Ensure options use UI font */\n",
    "            }}\n",
    "\n",
    "            /* --- Dark Mode Toggle --- */\n",
    "            .mode-toggle {{\n",
    "                display: flex;\n",
    "                align-items: center;\n",
    "                font-family: var(--font-ui) !important;\n",
    "            }}\n",
    "            .mode-toggle .form-check-input {{ /* The hidden checkbox */\n",
    "                opacity: 0;\n",
    "                width: 0;\n",
    "                height: 0;\n",
    "                position: absolute;\n",
    "            }}\n",
    "            /* No visual switch span needed */\n",
    "            .mode-toggle .form-check-label {{ /* The clickable text */\n",
    "                font-family: var(--font-ui) !important;\n",
    "                font-size: 0.9em;\n",
    "                color: var(--subheader-color);\n",
    "                cursor: pointer;\n",
    "                transition: color 0.3s;\n",
    "                user-select: none; /* Prevent text selection on click */\n",
    "                padding: 2px 5px; /* Add some padding for easier clicking */\n",
    "            }}\n",
    "            .mode-toggle .form-check-label:hover {{\n",
    "                color: var(--link-hover-color); /* Use link hover color for feedback */\n",
    "            }}\n",
    "\n",
    "\n",
    "            /* --- Report Content Containers --- */\n",
    "            .iteration-container {{\n",
    "                margin: 30px 0;\n",
    "                border: 1px solid var(--border-color);\n",
    "                border-radius: 4px;\n",
    "                overflow: hidden;\n",
    "                background-color: var(--container-bg);\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
    "                transition: background-color 0.3s, border-color 0.3s, box-shadow 0.3s;\n",
    "            }}\n",
    "            .iteration-header {{\n",
    "                background: var(--iter-header-bg);\n",
    "                padding: 12px 20px;\n",
    "                cursor: pointer;\n",
    "                position: relative;\n",
    "                border-bottom: 1px solid var(--border-color);                \n",
    "                font-size: 1.2em;\n",
    "                font-weight: 700;\n",
    "                color: var(--header-color);\n",
    "                transition: background-color 0.3s, border-color 0.3s, color 0.3s;\n",
    "            }}\n",
    "            .iteration-header:hover {{\n",
    "                background: var(--iter-header-hover-bg);\n",
    "            }}\n",
    "            .prompt-container {{\n",
    "                border-top: 1px dashed var(--accent-border-color);\n",
    "                transition: border-color 0.3s;\n",
    "            }}\n",
    "            .prompt-container:first-child {{\n",
    "                border-top: none;\n",
    "            }}\n",
    "            .prompt-header {{\n",
    "                background: var(--prompt-header-bg);\n",
    "                padding: 10px 20px;\n",
    "                cursor: pointer;\n",
    "                font-size: 1.1em;\n",
    "                font-weight: 400;\n",
    "                color: var(--subheader-color);\n",
    "                transition: background-color 0.3s, color 0.3s;\n",
    "            }}\n",
    "            .prompt-header:hover {{\n",
    "                background: var(--prompt-header-hover-bg);\n",
    "            }}\n",
    "            .content-block {{\n",
    "                padding: 15px 25px;\n",
    "                border-top: 1px solid var(--border-color);\n",
    "                background-color: var(--container-bg);\n",
    "                transition: background-color 0.3s, border-color 0.3s;\n",
    "            }}\n",
    "            .response-content {{\n",
    "                white-space: pre-wrap;\n",
    "                font-family: var(--font-body);\n",
    "                font-size: 1.05em;\n",
    "                line-height: 1.7;\n",
    "                margin-bottom: 15px;\n",
    "                color: var(--text-color);\n",
    "                transition: color 0.3s;\n",
    "            }}\n",
    "            .judge-content {{\n",
    "                white-space: pre-wrap;\n",
    "                font-family: var(--font-body);\n",
    "                font-size: 1.0em;\n",
    "                line-height: 1.6;\n",
    "                background: var(--judge-bg);\n",
    "                border: 1px dashed var(--judge-border);\n",
    "                padding: 10px 15px;\n",
    "                margin-top: 10px;\n",
    "                border-radius: 3px;\n",
    "                color: var(--judge-text);\n",
    "                transition: background-color 0.3s, border-color 0.3s, color 0.3s;\n",
    "            }}\n",
    "            .prompt-text-display {{\n",
    "                font-style: italic; /* Default italic */\n",
    "                color: var(--subheader-color);\n",
    "                margin-bottom: 1em;\n",
    "                padding: 10px 15px;\n",
    "                background-color: var(--prompt-display-bg);\n",
    "                border-left: 3px solid var(--accent-border-color);\n",
    "                white-space: pre-wrap;\n",
    "                font-family: var(--font-body);\n",
    "                transition: background-color 0.3s, border-color 0.3s, color 0.3s, font-style 0.3s;\n",
    "            }}\n",
    "            .collapsible-content {{\n",
    "                display: none;\n",
    "                padding: 0;\n",
    "                background-color: var(--container-bg);\n",
    "                transition: background-color 0.3s;\n",
    "            }}\n",
    "            .expanded {{\n",
    "                display: block;\n",
    "            }}\n",
    "            .toggle-icon {{\n",
    "                display: inline-block;\n",
    "                width: 20px;\n",
    "                text-align: center;\n",
    "                font-weight: bold;\n",
    "                margin-right: 8px;\n",
    "                color: var(--toggle-icon-color);\n",
    "                transition: color 0.3s;\n",
    "            }}\n",
    "            .scores-container {{\n",
    "                margin-left: 20px;\n",
    "                font-style: italic;\n",
    "                color: #888;\n",
    "                font-size: 0.9em;\n",
    "            }}\n",
    "\n",
    "            /* Make certain elements always use the UI font */\n",
    "            h1, \n",
    "            .back-button,\n",
    "            .control-select,\n",
    "            .form-check-label,\n",
    "            .top-controls {{\n",
    "                font-family: var(--font-ui) !important; /* Override with UI font */\n",
    "            }}\n",
    "\n",
    "            h1.main-title, /* Add a class to the main title */\n",
    "            .back-button,\n",
    "            .control-select,\n",
    "            .form-check-label,\n",
    "            .top-controls {{\n",
    "                font-family: var(--font-ui) !important; /* Override with UI font */\n",
    "            }}\n",
    "\n",
    "            /* Allow iteration and prompt headers to use selected font */\n",
    "            .iteration-header,\n",
    "            .prompt-header {{\n",
    "                font-family: var(--font-body) !important;\n",
    "            }}\n",
    "\n",
    "            /* Mobile Responsiveness Adjustments */\n",
    "            @media screen and (max-width: 768px) {{\n",
    "    /* Body / Layout */\n",
    "    body.theme-cozy,\n",
    "    body.theme-modern {{\n",
    "        max-width: 100%;\n",
    "        margin: 10px 5px;\n",
    "        padding: 15px 10px;\n",
    "    }}\n",
    "\n",
    "    /* Headings */\n",
    "    body.theme-cozy h1,\n",
    "    body.theme-modern h1 {{\n",
    "        font-size: 1.8em;\n",
    "        padding-bottom: 10px;\n",
    "        margin-bottom: 1em;\n",
    "    }}\n",
    "\n",
    "    body.theme-cozy h2,\n",
    "    body.theme-modern h2 {{\n",
    "        font-size: 1.5em;\n",
    "    }}\n",
    "\n",
    "    body.theme-cozy h3,\n",
    "    body.theme-modern h3 {{\n",
    "        font-size: 1.2em;\n",
    "    }}\n",
    "\n",
    "    /* Iteration / Prompt headers */\n",
    "    body.theme-cozy .iteration-header,\n",
    "    body.theme-modern .iteration-header {{\n",
    "        padding: 10px 12px;\n",
    "    }}\n",
    "\n",
    "    body.theme-cozy .prompt-header,\n",
    "    body.theme-modern .prompt-header {{\n",
    "        padding: 8px 12px;\n",
    "    }}\n",
    "\n",
    "    /* Content blocks */\n",
    "    body.theme-cozy .content-block,\n",
    "    body.theme-modern .content-block {{\n",
    "        padding: 10px 12px;\n",
    "    }}\n",
    "\n",
    "    /* Top controls layout */\n",
    "    body.theme-cozy .top-controls,\n",
    "    body.theme-modern .top-controls {{\n",
    "        flex-direction: column;\n",
    "        align-items: flex-start;\n",
    "        gap: 10px;\n",
    "    }}\n",
    "\n",
    "    body.theme-cozy .controls-right,\n",
    "    body.theme-modern .controls-right {{\n",
    "        width: 100%;\n",
    "        justify-content: space-between;\n",
    "    }}\n",
    "}}\n",
    "\n",
    "\n",
    "\n",
    "        </style>\n",
    "    </head>\n",
    "    <body class=\"theme-cozy\">\n",
    "        <div class=\"top-controls\">\n",
    "            <div class=\"nav-left\">\n",
    "                <a href=\"javascript:history.back()\" class=\"back-button\">← Back</a>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"controls-right\">\n",
    "                <div class=\"control-select-wrapper\">\n",
    "                    <select id=\"themeSelector\" class=\"control-select\" aria-label=\"Select Theme\">\n",
    "                        <option value=\"cozy\">Cozy</option>\n",
    "                        <option value=\"modern\">Modern</option>\n",
    "                    </select>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"control-select-wrapper\">\n",
    "                    <select id=\"fontSelector\" class=\"control-select\" aria-label=\"Select Font\">\n",
    "                        <option value=\"tiempos\">Tiempos Text</option>\n",
    "                        <option value=\"bookerly\">Bookerly</option>\n",
    "                        <option value=\"bitter\">Bitter Pro</option>\n",
    "                        <option value=\"roboto\">Roboto</option>\n",
    "                        <option value=\"inter\">Inter</option>\n",
    "                        <option value=\"source_sans\">Source Sans 3</option>\n",
    "                        <option value=\"open_sans\">Open Sans</option>\n",
    "                        <option value=\"fira_sans\">Fira Sans</option>\n",
    "                        <option value=\"besley\">Besley</option>\n",
    "                    </select>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"mode-toggle\">\n",
    "                    <input class=\"form-check-input\" type=\"checkbox\" id=\"darkModeToggle\">\n",
    "                    <label class=\"form-check-label\" for=\"darkModeToggle\" id=\"toggleLabel\">Light</label>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <h1 class=\"main-title\">Sample Outputs: {display_model_name}</h1>\n",
    "    \"\"\"\n",
    "    neg_criteria = []\n",
    "    try:\n",
    "        neg_criteria_file = 'data/negative_criteria.txt'\n",
    "        if os.path.exists(neg_criteria_file):\n",
    "            with open(neg_criteria_file, 'r') as f:\n",
    "                neg_criteria = [line.strip().lower() for line in list(f.readlines())]\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading negative criteria: {e}\")\n",
    "        neg_criteria = []\n",
    "    for display_idx, (iter_idx, iter_data) in enumerate(sorted_iterations):\n",
    "        is_first = display_idx == 0\n",
    "        html_output += f\"\"\"\n",
    "        <div class=\"iteration-container\">\n",
    "            <div class=\"iteration-header\" onclick=\"toggleContent('iteration-{iter_idx}')\">\n",
    "                <span class=\"toggle-icon\">{'−' if is_first else '+'}</span>\n",
    "                Iteration {display_idx + 1} — Avg Score: {round(iter_data['score']*5, 1)}\n",
    "            </div>\n",
    "            <div id=\"iteration-{iter_idx}\" class=\"collapsible-content {'expanded' if is_first else ''}\">\n",
    "        \"\"\"\n",
    "        prompt_data = iter_data[\"prompts\"]\n",
    "        prompt_items = []\n",
    "        for prompt_id, task_data in prompt_data.items():\n",
    "            if task_data.get(\"status\") not in [\"completed\", \"judged\"]: continue\n",
    "            prompt_text = task_data.get(\"base_prompt\", \"\")\n",
    "            if not prompt_text: continue\n",
    "\n",
    "            prompt_category = \"Unknown Category\"\n",
    "            prompt_title = f\"Prompt {prompt_id}\"\n",
    "            if prompt_id in creative_prompts:\n",
    "                prompt_info = creative_prompts[prompt_id]\n",
    "                prompt_category = prompt_info.get(\"category\", prompt_category)\n",
    "                prompt_title = prompt_info.get(\"title\", prompt_title)\n",
    "\n",
    "            all_responses = []\n",
    "            total_score = 0\n",
    "            score_count = 0\n",
    "            results_by_mod = task_data.get(\"results_by_modifier\", {})\n",
    "            for seed_mod, block in results_by_mod.items():\n",
    "                response_text = block.get(\"model_response\", \"\")\n",
    "                raw_judge_text = block.get(\"raw_judge_text\", \"\")\n",
    "                j_scores = block.get(\"judge_scores\", {})\n",
    "                response_scores_list = []\n",
    "                for metric, val in j_scores.items():\n",
    "                    if isinstance(val, (int, float)):\n",
    "                        score_val = (20 - val) if metric.lower() in neg_criteria else val\n",
    "                        total_score += score_val\n",
    "                        score_count += 1\n",
    "                        response_scores_list.append(f\"{metric}: {val}\")\n",
    "                all_responses.append({\n",
    "                    \"text\": response_text, \"judge_text\": raw_judge_text, \"scores\": \", \".join(response_scores_list)\n",
    "                })\n",
    "            avg_score = round(total_score / score_count, 2) if score_count > 0 else 0\n",
    "            prompt_items.append({\n",
    "                \"id\": prompt_id, \"prompt\": prompt_text, \"category\": prompt_category,\n",
    "                \"title\": prompt_title, \"responses\": all_responses, \"avg_score\": avg_score\n",
    "            })\n",
    "\n",
    "        def get_prompt_order(prompt_item):\n",
    "            try: return PROMPTS_ORDER.index(prompt_item[\"id\"])\n",
    "            except ValueError: return len(PROMPTS_ORDER)\n",
    "        prompt_items.sort(key=get_prompt_order)\n",
    "\n",
    "        for pidx, item in enumerate(prompt_items):\n",
    "            prompt_html_id = f\"prompt-{iter_idx}-{item['id']}\"\n",
    "            html_output += f\"\"\"\n",
    "            <div class=\"prompt-container\">\n",
    "                <div class=\"prompt-header\" onclick=\"toggleContent('{prompt_html_id}')\">\n",
    "                    <span class=\"toggle-icon\">+</span>\n",
    "                    {item['category'].capitalize()}: {item['title']} — Score: {round(item['avg_score']*5, 1)}\n",
    "                </div>\n",
    "                <div id=\"{prompt_html_id}\" class=\"collapsible-content\">\n",
    "                    <div class=\"content-block\">\n",
    "                        <div class=\"prompt-text-display\">\n",
    "<strong>Prompt:</strong><br>{item['prompt']}\n",
    "                        </div>\"\"\"\n",
    "            for ridx, response in enumerate(item[\"responses\"]):\n",
    "                html_output += f\"\"\"\n",
    "                        <div class=\"response-content\">\n",
    "<strong>Model Output:</strong><br>{response['text']}\n",
    "                        </div>\"\"\"\n",
    "                if response[\"judge_text\"]:\n",
    "                    scores_display = f\"<br><i>Scores: {response['scores']}</i>\" if response['scores'] else \"\"\n",
    "                    html_output += f\"\"\"\n",
    "                        <div class=\"judge-content\">\n",
    "<strong>Judge Evaluation:</strong><br>{response['judge_text']} {scores_display}\n",
    "                        </div>\"\"\"\n",
    "                if ridx < len(item[\"responses\"]) - 1:\n",
    "                    html_output += \"<hr style='border: none; border-top: 1px dotted var(--border-color); margin: 15px 0; transition: border-color 0.3s;'>\"\n",
    "            html_output += \"\"\"\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\"\"\"\n",
    "        html_output += \"\"\"\n",
    "            </div>\n",
    "        </div>\"\"\"\n",
    "    # --- End Iteration Loop ---\n",
    "\n",
    "    # --- JavaScript for Toggling, Dark Mode, Themes, Fonts with Dynamic Font Loading ---\n",
    "    html_output += \"\"\"\n",
    "        <script>\n",
    "            // --- DOM Elements ---\n",
    "            const body = document.body;\n",
    "            const themeSelector = document.getElementById('themeSelector');\n",
    "            const fontSelector = document.getElementById('fontSelector');\n",
    "            const darkModeToggle = document.getElementById('darkModeToggle');\n",
    "            const toggleLabel = document.getElementById('toggleLabel');\n",
    "\n",
    "            // --- Constants ---\n",
    "            const FONT_MAP = {\n",
    "                'tiempos': \"'Tiempos Text', Georgia, serif\",\n",
    "                'bookerly': \"'Bookerly', Georgia, serif\",\n",
    "                'bitter': \"'Bitter Pro', Georgia, serif\",\n",
    "                'roboto': \"'Roboto', sans-serif\",\n",
    "                'inter': \"'Inter', sans-serif\",\n",
    "                'source_sans': \"'Source Sans 3', sans-serif\",\n",
    "                'open_sans': \"'Open Sans', sans-serif\",\n",
    "                'fira_sans': \"'Fira Sans', sans-serif\",\n",
    "                'besley': \"'Besley', 'Merriweather', serif\"\n",
    "            };\n",
    "            \n",
    "            // Font definitions with URLs for dynamic loading\n",
    "            const FONT_DEFINITIONS = {\n",
    "                'tiempos': {\n",
    "                    family: 'Tiempos Text',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/tiempos_text/TiemposText-Regular.woff2' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/tiempos_text/TiemposText-RegularItalic.woff2' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/tiempos_text/TiemposText-Bold.woff2' }\n",
    "                    ],\n",
    "                    fallback: 'Georgia, serif'\n",
    "                },\n",
    "                'bookerly': {\n",
    "                    family: 'Bookerly',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/bookerly/Bookerly.woff' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/bookerly/Bookerly Italic.woff' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/bookerly/Bookerly Bold.woff' }\n",
    "                    ],\n",
    "                    fallback: 'Georgia, serif'\n",
    "                },\n",
    "                'bitter': {\n",
    "                    family: 'Bitter Pro',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/bitter_pro/BitterPro-Regular.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/bitter_pro/BitterPro-Italic.ttf' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/bitter_pro/BitterPro-Bold.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'Georgia, serif'\n",
    "                },\n",
    "                'roboto': {\n",
    "                    family: 'Roboto',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/roboto/static/Roboto-Regular.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/roboto/static/Roboto-Italic.ttf' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/roboto/static/Roboto-Bold.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'sans-serif'\n",
    "                },\n",
    "                'inter': {\n",
    "                    family: 'Inter',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/inter/static/Inter-Regular.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/inter/static/Inter-Italic.ttf' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/inter/static/Inter-Bold.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'sans-serif'\n",
    "                },\n",
    "                'source_sans': {\n",
    "                    family: 'Source Sans 3',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/source_sans_3/static/SourceSans3-Regular.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/source_sans_3/static/SourceSans3-Italic.ttf' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/source_sans_3/static/SourceSans3-Bold.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'sans-serif'\n",
    "                },\n",
    "                'open_sans': {\n",
    "                    family: 'Open Sans',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/open_sans/static/OpenSans-Regular.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/open_sans/static/OpenSans-Italic.ttf' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/open_sans/static/OpenSans-Bold.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'sans-serif'\n",
    "                },\n",
    "                'fira_sans': {\n",
    "                    family: 'Fira Sans',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/fira_sans/FiraSans-Regular.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/fira_sans/FiraSans-Italic.ttf' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/fira_sans/FiraSans-Bold.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'sans-serif'\n",
    "                },\n",
    "                'besley': {\n",
    "                    family: 'Besley',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/besley/Besley-VariableFont_wght.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/besley/Besley-Italic-VariableFont_wght.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'serif'\n",
    "                }\n",
    "            };\n",
    "            \n",
    "            // Define which fonts are generally sans-serif for logic purposes\n",
    "            const SANS_FONTS = ['roboto', 'inter', 'source_sans', 'open_sans', 'fira_sans'];\n",
    "\n",
    "            const THEME_DEFAULT_FONTS = {\n",
    "                'cozy': 'tiempos',\n",
    "                'modern': 'inter'\n",
    "            };\n",
    "            const THEME_DEFAULT_HEAD_FONTS = {\n",
    "                 'cozy': \"'Lora', serif\",\n",
    "                 'modern': \"'Besley', 'Merriweather', serif\"\n",
    "            };\n",
    "            \n",
    "            // Keep track of loaded fonts to avoid loading the same font multiple times\n",
    "            const loadedFonts = new Set();\n",
    "\n",
    "            // --- Dynamic Font Loading ---\n",
    "            async function loadFontFace(fontKey) {\n",
    "                if (loadedFonts.has(fontKey)) return; // Skip if already loaded\n",
    "                \n",
    "                const fontDef = FONT_DEFINITIONS[fontKey];\n",
    "                if (!fontDef) {\n",
    "                    console.warn(`Font definition not found for: ${fontKey}`);\n",
    "                    return;\n",
    "                }\n",
    "                \n",
    "                try {\n",
    "                    const fontLoadPromises = fontDef.variants.map(variant => {\n",
    "                        const fontFace = new FontFace(\n",
    "                            fontDef.family,\n",
    "                            `url(${variant.url})`,\n",
    "                            {\n",
    "                                weight: variant.weight,\n",
    "                                style: variant.style\n",
    "                            }\n",
    "                        );\n",
    "                        \n",
    "                        return fontFace.load().then(loadedFont => {\n",
    "                            document.fonts.add(loadedFont);\n",
    "                            return loadedFont;\n",
    "                        });\n",
    "                    });\n",
    "                    \n",
    "                    await Promise.all(fontLoadPromises);\n",
    "                    loadedFonts.add(fontKey);\n",
    "                    console.log(`Loaded font: ${fontDef.family}`);\n",
    "                } catch (err) {\n",
    "                    console.error(`Error loading font ${fontDef.family}:`, err);\n",
    "                    // Fall back silently - CSS will use fallback fonts\n",
    "                }\n",
    "            }\n",
    "\n",
    "            // --- Content Toggling ---\n",
    "            function toggleContent(id) {\n",
    "                const element = document.getElementById(id);\n",
    "                if (!element) return;\n",
    "                const isExpanded = element.classList.contains('expanded');\n",
    "                const header = element.previousElementSibling;\n",
    "                const toggleIcon = header ? header.querySelector('.toggle-icon') : null;\n",
    "\n",
    "                if (isExpanded) {\n",
    "                    element.classList.remove('expanded');\n",
    "                    if (toggleIcon) toggleIcon.textContent = '+';\n",
    "                } else {\n",
    "                    element.classList.add('expanded');\n",
    "                    if (toggleIcon) toggleIcon.textContent = '−';\n",
    "                }\n",
    "            }\n",
    "\n",
    "            // --- Shared settings with consistent keys ---\n",
    "            const STORAGE_PREFIX = 'model_viewer_';\n",
    "            const KEYS = {\n",
    "                THEME: `${STORAGE_PREFIX}theme`,\n",
    "                FONT: `${STORAGE_PREFIX}font`,\n",
    "                DARK_MODE: `modelViewerDarkModeEnabled`\n",
    "            };\n",
    "\n",
    "            // Save settings with consistent keys\n",
    "            function saveSettings(type, value) {\n",
    "                localStorage.setItem(KEYS[type], value);\n",
    "            }\n",
    "\n",
    "            // --- Dark Mode ---\n",
    "            function setDarkMode(isDark) {\n",
    "                body.classList.toggle('dark-mode', isDark);\n",
    "                toggleLabel.textContent = isDark ? 'Dark' : 'Light';\n",
    "                if (darkModeToggle.checked !== isDark) {\n",
    "                    darkModeToggle.checked = isDark;\n",
    "                }\n",
    "                saveSettings('DARK_MODE', isDark);\n",
    "            }\n",
    "\n",
    "\n",
    "            // --- Theme Selection ---\n",
    "            function applyTheme(themeName) {\n",
    "                body.classList.remove('theme-cozy', 'theme-modern');\n",
    "                body.classList.add(`theme-${themeName}`);\n",
    "                if (themeSelector.value !== themeName) {\n",
    "                    themeSelector.value = themeName;\n",
    "                }\n",
    "                saveSettings('THEME', themeName);\n",
    "                \n",
    "                // Re-apply font based on theme's default or user's saved preference\n",
    "                const savedFont = localStorage.getItem(KEYS.FONT);\n",
    "                const defaultFont = THEME_DEFAULT_FONTS[themeName] || 'tiempos';\n",
    "                applyFont(savedFont || defaultFont);\n",
    "            }\n",
    "\n",
    "            // --- Font Selection ---\n",
    "            async function applyFont(fontValue) {\n",
    "                // First, load the font faces dynamically\n",
    "                await loadFontFace(fontValue);\n",
    "                \n",
    "                const fontFamily = FONT_MAP[fontValue];\n",
    "                const currentTheme = localStorage.getItem(KEYS.THEME) || 'cozy';\n",
    "                let headingFontFamily = THEME_DEFAULT_HEAD_FONTS[currentTheme]; // Default heading for theme\n",
    "\n",
    "                if (fontFamily) {\n",
    "                    // Set body font - content text only, not UI elements\n",
    "                    body.style.setProperty('--font-body', fontFamily);\n",
    "\n",
    "                    // Determine appropriate heading font based on selected body font and theme\n",
    "                    if (currentTheme === 'modern') {\n",
    "                        headingFontFamily = THEME_DEFAULT_HEAD_FONTS['modern'];\n",
    "                    } else { \n",
    "                        headingFontFamily = THEME_DEFAULT_HEAD_FONTS['cozy'];\n",
    "                    }\n",
    "                    \n",
    "                    // Special case: If Besley is explicitly selected, use it for heading regardless of theme\n",
    "                    if (fontValue === 'besley') {\n",
    "                        headingFontFamily = FONT_MAP['besley'];\n",
    "                    }\n",
    "\n",
    "                    // Set the content heading font - not UI elements\n",
    "                    body.style.setProperty('--font-heading', headingFontFamily);\n",
    "\n",
    "                    // Update the selector value if needed\n",
    "                    if (fontSelector.value !== fontValue) {\n",
    "                        fontSelector.value = fontValue;\n",
    "                    }\n",
    "                    \n",
    "                    saveSettings('FONT', fontValue);\n",
    "                } else {\n",
    "                    console.warn(\"Font value not found in FONT_MAP:\", fontValue);\n",
    "                    // Fallback to theme default\n",
    "                    const theme = localStorage.getItem(KEYS.THEME) || 'cozy';\n",
    "                    applyFont(THEME_DEFAULT_FONTS[theme]);\n",
    "                }\n",
    "            }\n",
    "\n",
    "            // --- Event Listeners ---\n",
    "            darkModeToggle.addEventListener('change', function() {\n",
    "                setDarkMode(this.checked);\n",
    "            });\n",
    "\n",
    "            themeSelector.addEventListener('change', function() {\n",
    "                applyTheme(this.value);\n",
    "            });\n",
    "\n",
    "            fontSelector.addEventListener('change', function() {\n",
    "                applyFont(this.value);\n",
    "            });\n",
    "\n",
    "            // --- Initial Settings Application ---\n",
    "            async function applyInitialSettings() {\n",
    "                const savedDarkMode = localStorage.getItem(KEYS.DARK_MODE);\n",
    "                const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
    "                setDarkMode(savedDarkMode !== null ? (savedDarkMode === 'true') : prefersDark);\n",
    "\n",
    "                const savedTheme = localStorage.getItem(KEYS.THEME) || 'cozy';\n",
    "                applyTheme(savedTheme);\n",
    "\n",
    "                const savedFont = localStorage.getItem(KEYS.FONT) || THEME_DEFAULT_FONTS[savedTheme];\n",
    "                await applyFont(savedFont);\n",
    "                \n",
    "                fontSelector.value = savedFont || THEME_DEFAULT_FONTS[savedTheme];\n",
    "            }\n",
    "\n",
    "            applyInitialSettings();\n",
    "\n",
    "            // Optional: Listen for system theme changes ONLY if no preference is saved\n",
    "            window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {\n",
    "                if (localStorage.getItem('darkModeEnabled') === null) {\n",
    "                    setDarkMode(event.matches);\n",
    "                }\n",
    "            });\n",
    "\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    if save_to_file:\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        sanitized_name = sanitize_model_name(get_updated_model_name(original_model_name))\n",
    "        filename = f\"results/{sanitized_name}.html\"\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(html_output)\n",
    "            print(f\"Report saved to {filename}\")\n",
    "        except IOError as e:\n",
    "            print(f\"Error saving report to {filename}: {e}\")\n",
    "\n",
    "    return HTML(html_output)\n",
    "\n",
    "\n",
    "# --- Helper Functions (Identical to original) ---\n",
    "def view_model_report(model_name, run_key=None, save_to_file=False):\n",
    "    \"\"\"Display the HTML report for a given model and optionally save it.\"\"\"\n",
    "    report = generate_model_report(model_name, run_key, save_to_file)\n",
    "    display(report)\n",
    "\n",
    "def save_model_report(model_name, run_key=None):\n",
    "    \"\"\"Generate and save the HTML report for a given model.\"\"\"\n",
    "    generate_model_report(model_name, run_key, save_to_file=True)\n",
    "\n",
    "def list_available_models():\n",
    "    \"\"\"List all models available in the ELO results file.\"\"\"\n",
    "    elo_data = load_json_file(ELO_RESULTS_FILE)\n",
    "    if not elo_data:\n",
    "        print(\"No ELO data found.\")\n",
    "        return []\n",
    "    models = []\n",
    "    print(\"Available models (sorted by ELO):\")\n",
    "    for model_name, model_data in elo_data.items():\n",
    "        elo_score = model_data.get(\"elo\", -float('inf'))\n",
    "        models.append((model_name, elo_score))\n",
    "    models.sort(key=lambda x: x[1] if isinstance(x[1], (int, float)) else -float('inf'), reverse=True)\n",
    "    for rank, (name, elo) in enumerate(models, 1):\n",
    "        elo_display = f\"{elo:.0f}\" if isinstance(elo, (int, float)) else \"N/A\"\n",
    "        print(f\"{rank}. {get_updated_model_name(name)} (ELO: {elo_display})\") # Use updated name\n",
    "    return [name for name, _ in models]\n",
    "\n",
    "def list_model_runs(model_name):\n",
    "    \"\"\"List all runs available for a specific model.\"\"\"\n",
    "    runs_data = load_json_file(RUNS_FILE)\n",
    "    if not runs_data:\n",
    "        print(\"No runs data found.\")\n",
    "        return []\n",
    "    matching_runs = []\n",
    "    for key, data in runs_data.items():\n",
    "        if data.get(\"test_model\") == model_name:\n",
    "            start_time = data.get(\"start_time\", \"Unknown Time\")\n",
    "            status = data.get(\"status\", \"Unknown Status\")\n",
    "            matching_runs.append((key, start_time, status))\n",
    "    if not matching_runs:\n",
    "        print(f\"No runs found for model: {model_name}\")\n",
    "        return []\n",
    "    print(f\"\\nAvailable runs for {get_updated_model_name(model_name)}:\") # Use updated name\n",
    "    matching_runs.sort(key=lambda x: x[0])\n",
    "    for idx, (key, time, status) in enumerate(matching_runs, 1):\n",
    "        print(f\"{idx}. {key} (Started: {time}, Status: {status})\")\n",
    "    return [key for key, _, _ in matching_runs]\n",
    "\n",
    "\n",
    "import html # Import the html module for escaping\n",
    "\n",
    "# Assume MODELS_TO_IGNORE and get_updated_model_name are defined elsewhere\n",
    "\n",
    "def format_slop_profile_string(elo_data_with_metrics: Dict[str, Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Formats repetitive word and n-gram data into a single multi-line string\n",
    "    with HTML formatting, including clickable dendrogram thumbnails.\n",
    "    \n",
    "    Args:\n",
    "        elo_data_with_metrics: The dictionary containing model data\n",
    "        \n",
    "    Returns:\n",
    "        A multi-line string containing the formatted slop profiles with thumbnails\n",
    "    \"\"\"\n",
    "    output_string = \"\"\n",
    "\n",
    "    # Sort models by normalized ELO descending\n",
    "    sorted_models = sorted(\n",
    "        elo_data_with_metrics.items(),\n",
    "        key=lambda item: (\n",
    "            item[1].get(\"normalized_elo\", -float('inf'))\n",
    "            if isinstance(item[1].get(\"normalized_elo\"), (int, float))\n",
    "            else (\n",
    "                item[1].get(\"elo\", -float('inf'))\n",
    "                if isinstance(item[1].get(\"elo\"), (int, float))\n",
    "                else -float('inf')\n",
    "            )\n",
    "        ),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    for model_name, data in sorted_models:\n",
    "        if model_name in MODELS_TO_IGNORE:\n",
    "            continue\n",
    "\n",
    "        updated_name = get_updated_model_name(model_name)\n",
    "        sanitized_name = sanitize_model_name(updated_name)\n",
    "        \n",
    "        output_string += f\"##### {updated_name}\\n\"\n",
    "        \n",
    "        # Add dendrogram thumbnails with links to full-size images\n",
    "        output_string += \"<div class='dendrogram-thumbnails'>\\n\"\n",
    "        \n",
    "        # Circular dendrogram thumbnail\n",
    "        circular_path = f\"results/creative-writing-v3/hybrid_parsimony/charts/{sanitized_name}__phylo_tree_parsimony_circular.png\"\n",
    "        output_string += f\"  <a href='{circular_path}' target='_blank' class='dendrogram-link'>\\n\"\n",
    "        output_string += f\"    <img src='{circular_path}' alt='Circular dendrogram for {html.escape(updated_name)}' class='dendrogram-thumb circular-thumb' />\\n\"\n",
    "        output_string += f\"    <span class='dendrogram-caption'>Circular View</span>\\n\"\n",
    "        output_string += f\"  </a>\\n\"\n",
    "        \n",
    "        # Rectangular dendrogram thumbnail\n",
    "        rectangular_path = f\"results/creative-writing-v3/hybrid_parsimony/charts/{sanitized_name}__phylo_tree_parsimony_rectangular.png\"\n",
    "        output_string += f\"  <a href='{rectangular_path}' target='_blank' class='dendrogram-link'>\\n\"\n",
    "        output_string += f\"    <img src='{rectangular_path}' alt='Rectangular dendrogram for {html.escape(updated_name)}' class='dendrogram-thumb rect-thumb' />\\n\"\n",
    "        output_string += f\"    <span class='dendrogram-caption'>Rectangular View</span>\\n\"\n",
    "        output_string += f\"  </a>\\n\"\n",
    "        output_string += \"</div>\\n\\n\"\n",
    "        \n",
    "        # Continue with existing similar models section\n",
    "        top_5 = data.get(\"top_5_similar\", [])\n",
    "        if top_5:\n",
    "            output_string += \"<h4>Most Similar To:</h4>\\n\"\n",
    "            output_string += \"<div class='slop-similar-section'>\\n\"\n",
    "            for item in top_5:\n",
    "                dist_str = f\"{item['distance']:.3f}\"\n",
    "                output_string += f\"<div class='slop-similar'>{html.escape(item['model'])} (distance={dist_str})</div>\\n\"\n",
    "            output_string += \"</div>\\n\"\n",
    "            output_string += \"\\n\"\n",
    "\n",
    "        # Continue with the rest of the existing code for repetitive words, bigrams, trigrams\n",
    "        rep_words = data.get('top_repetitive_words', [])\n",
    "        output_string += \"<h4>Top Repetitive Words</h4>\\n\"\n",
    "        if rep_words:\n",
    "            output_string += \"<div class='slop-section-items'>\\n\"\n",
    "            items_html = []\n",
    "            for item in rep_words[:50]:\n",
    "                word = item.get('word', 'N/A')\n",
    "                safe_word = html.escape(word)\n",
    "                items_html.append(f\"<span class='slop-word-item'>{safe_word}</span>\")\n",
    "            output_string += \" \".join(items_html)\n",
    "            output_string += \"\\n</div>\\n\"\n",
    "        else:\n",
    "            output_string += \"<p><i>No multi-prompt repetitive words found.</i></p>\\n\"\n",
    "\n",
    "        # Bigrams section (unchanged)\n",
    "        bigrams = data.get('top_multi_prompt_bigrams', [])\n",
    "        output_string += \"<h4>Top Bigrams</h4>\\n\"\n",
    "        if bigrams:\n",
    "            output_string += \"<div class='slop-section-items'>\\n\"\n",
    "            items_html = []\n",
    "            for item in bigrams[:30]:\n",
    "                ngram = item.get('ngram', 'N/A')\n",
    "                freq = item.get('frequency', 0)\n",
    "                safe_ngram = html.escape(ngram)\n",
    "                items_html.append(f\"<span class='slop-ngram-item'>{safe_ngram} ({freq})</span>\")\n",
    "            output_string += \" \".join(items_html)\n",
    "            output_string += \"\\n</div>\\n\"\n",
    "        else:\n",
    "            output_string += \"<p><i>No multi-prompt bigrams found.</i></p>\\n\"\n",
    "\n",
    "        # Trigrams section (unchanged)\n",
    "        trigrams = data.get('top_multi_prompt_trigrams', [])\n",
    "        output_string += \"<h4>Top Trigrams</h4>\\n\"\n",
    "        if trigrams:\n",
    "            output_string += \"<div class='slop-section-items'>\\n\"\n",
    "            items_html = []\n",
    "            for item in trigrams[:30]:\n",
    "                ngram = item.get('ngram', 'N/A')\n",
    "                freq = item.get('frequency', 0)\n",
    "                safe_ngram = html.escape(ngram)\n",
    "                items_html.append(f\"<span class='slop-ngram-item'>{safe_ngram} ({freq})</span>\")\n",
    "            output_string += \" \".join(items_html)\n",
    "            output_string += \"\\n</div>\\n\"\n",
    "        else:\n",
    "            output_string += \"<p><i>No multi-prompt trigrams found.</i></p>\\n\"\n",
    "\n",
    "        output_string += \"\\n\"\n",
    "\n",
    "    return output_string.strip()\n",
    "\n",
    "\n",
    "# --- ADDED: import for distance computation\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# --- ADDED: compute top-5 nearest models (via combined Jaccard features)\n",
    "def calculate_combined_jaccard_similarities(elo_data_with_metrics: Dict[str, Dict], top_n: int = 1500):\n",
    "    \"\"\"\n",
    "    Builds a presence/absence matrix of \"combined\" features (top_repetitive_words,\n",
    "    bigrams, trigrams) for each model, computes pairwise Jaccard distances,\n",
    "    and stores each model’s top 5 neighbors under 'top_5_similar'.\n",
    "    \"\"\"\n",
    "    model_names = list(elo_data_with_metrics.keys())\n",
    "    model_to_features = {}\n",
    "\n",
    "    for m in model_names:\n",
    "        info = elo_data_with_metrics[m]\n",
    "        words = info.get(\"top_repetitive_words\", [])\n",
    "        bigrams = info.get(\"top_multi_prompt_bigrams\", [])\n",
    "        trigrams = info.get(\"top_multi_prompt_trigrams\", [])\n",
    "\n",
    "        w_count = 120 #top_n // 3\n",
    "        b_count = 40 #top_n // 3\n",
    "        t_count = 40 #top_n // 3\n",
    "\n",
    "        words_sorted = sorted(words, key=lambda x: x.get(\"score\", 0), reverse=True)[:w_count]\n",
    "        bigrams_sorted = sorted(bigrams, key=lambda x: x.get(\"frequency\", 0), reverse=True)[:b_count]\n",
    "        trigrams_sorted = sorted(trigrams, key=lambda x: x.get(\"frequency\", 0), reverse=True)[:t_count]\n",
    "\n",
    "        word_set = set(x[\"word\"] for x in words_sorted)\n",
    "        bigram_set = set(x[\"ngram\"] for x in bigrams_sorted)\n",
    "        trigram_set = set(x[\"ngram\"] for x in trigrams_sorted)\n",
    "\n",
    "        combined_set = word_set.union(bigram_set).union(trigram_set)\n",
    "        model_to_features[m] = combined_set\n",
    "\n",
    "    all_models = sorted(model_names)\n",
    "    global_vocab = set()\n",
    "    for feats in model_to_features.values():\n",
    "        global_vocab.update(feats)\n",
    "    if len(all_models) < 2 or not global_vocab:\n",
    "        return\n",
    "\n",
    "    global_vocab = sorted(global_vocab)\n",
    "    df = pd.DataFrame(0, index=all_models, columns=global_vocab, dtype=int)\n",
    "    for m in all_models:\n",
    "        for ft in model_to_features[m]:\n",
    "            if ft in df.columns:\n",
    "                df.loc[m, ft] = 1\n",
    "\n",
    "    dist_array = pdist(df.values, metric=\"jaccard\")\n",
    "    dist_matrix = squareform(dist_array)\n",
    "\n",
    "    for i, m in enumerate(all_models):\n",
    "        row_dist = dist_matrix[i, :]\n",
    "        pair_list = [(all_models[j], row_dist[j]) for j in range(len(all_models)) if j != i]\n",
    "        pair_list.sort(key=lambda x: x[1])  # ascending\n",
    "        top_5 = pair_list[:5]\n",
    "        elo_data_with_metrics[m][\"top_5_similar\"] = [\n",
    "            {\"model\": get_updated_model_name(t[0]), \"distance\": t[1]} for t in top_5\n",
    "        ]\n",
    "\n",
    "\n",
    "def calculate_and_print_metrics(save_updated_elo: bool = True, print_slop_profile: bool = True): # Added print_slop_profile flag\n",
    "    \"\"\"\n",
    "    Calculates aggregated metrics (length, vocab, slop, repetition) AND\n",
    "    extracts top multi-prompt N-grams for all models found in the runs file.\n",
    "    Repetition metrics & N-grams only consider words/sequences appearing in multiple prompts.\n",
    "    Merges metrics with ELO data, prints results, optionally saves the updated ELO data,\n",
    "    and optionally prints the formatted slop profile string.\n",
    "    \"\"\"\n",
    "    print(\"\\nCalculating aggregated metrics and N-grams...\")\n",
    "    runs_data = load_json_file(RUNS_FILE)\n",
    "    elo_data = load_json_file(ELO_RESULTS_FILE)\n",
    "\n",
    "    if not runs_data:\n",
    "        print(f\"Runs data file ('{RUNS_FILE}') is empty or not found. Cannot calculate metrics.\")\n",
    "        return\n",
    "\n",
    "    # Structure: { model_name: { prompt_id: [text1, text2, ...], ... }, ... }\n",
    "    model_texts_by_prompt = defaultdict(lambda: defaultdict(list))\n",
    "    print(\"Extracting text from runs (grouped by prompt)...\")\n",
    "    processed_runs = 0\n",
    "    # ... (rest of text extraction logic remains the same) ...\n",
    "    for run_key, run_data in runs_data.items():\n",
    "        model_name = run_data.get(\"test_model\")\n",
    "        if model_name in MODELS_TO_IGNORE:\n",
    "            continue\n",
    "        if not model_name: continue\n",
    "        creative_tasks = run_data.get(\"creative_tasks\", {})\n",
    "        if not creative_tasks: continue\n",
    "\n",
    "        run_has_text = False\n",
    "        for iter_idx, prompt_data in creative_tasks.items():\n",
    "            for prompt_id, task_data in prompt_data.items():\n",
    "                if task_data.get(\"status\") not in [\"completed\", \"judged\"]: continue\n",
    "                results_by_mod = task_data.get(\"results_by_modifier\", {})\n",
    "                for seed_mod, block in results_by_mod.items():\n",
    "                    response_text = block.get(\"model_response\")\n",
    "                    if isinstance(response_text, str) and response_text.strip():\n",
    "                        model_texts_by_prompt[model_name][prompt_id].append(response_text)\n",
    "                        run_has_text = True\n",
    "        if run_has_text: processed_runs += 1\n",
    "\n",
    "    print(f\"Extracted text for {len(model_texts_by_prompt)} models from {processed_runs} runs.\")\n",
    "    if not model_texts_by_prompt:\n",
    "        print(\"No model text found in any run. Cannot calculate metrics.\")\n",
    "        return\n",
    "\n",
    "    print(\"Calculating metrics and extracting N-grams per model...\")\n",
    "    model_metrics = {}\n",
    "    model_repetitive_words = {}\n",
    "    model_top_bigrams = {}\n",
    "    model_top_trigrams = {}\n",
    "\n",
    "    # --- Iterate through models ---\n",
    "    for model_name, prompts_data in model_texts_by_prompt.items():\n",
    "        all_responses_flat = [] # For slop, complexity, avg_length\n",
    "        texts_with_ids_list = [] # For repetition metrics\n",
    "        repetition_score = 0.0  # Default score\n",
    "        top_repetitive_words = [] # Default list\n",
    "        top_bigrams = []        # Default list\n",
    "        top_trigrams = []       # Default list\n",
    "\n",
    "        # Basic check: Does the model have *any* data?\n",
    "        if not prompts_data:\n",
    "            print(f\"Skipping {model_name}: No prompt data found.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n  Processing {model_name} (Responses from {len(prompts_data)} prompts)...\")\n",
    "\n",
    "        # Check for multi-prompt data BEFORE calculating repetition/n-grams\n",
    "        has_multi_prompt_data = len(prompts_data) >= 2\n",
    "\n",
    "        # Populate lists needed for different metrics\n",
    "        for prompt_id, texts in prompts_data.items():\n",
    "            all_responses_flat.extend(texts)\n",
    "            # Only add to list for repetition if multi-prompt data exists\n",
    "            if has_multi_prompt_data:\n",
    "                for text in texts:\n",
    "                    if isinstance(text, str) and text.strip(): # Ensure only valid text is added\n",
    "                        texts_with_ids_list.append((text, prompt_id))\n",
    "\n",
    "        # --- Calculate N-grams, etc. (only if multi-prompt data) ---\n",
    "        if has_multi_prompt_data and texts_with_ids_list:\n",
    "            ngram_calculation_error = False\n",
    "            word_extraction_error = False\n",
    "            \n",
    "            # Calculate total text length for normalization\n",
    "            total_text_length = sum(len(text.split()) for text, _ in texts_with_ids_list)\n",
    "            \n",
    "            print(\"      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\")\n",
    "            try:\n",
    "                top_bigram_count = 0\n",
    "                top_trigram_count = 0\n",
    "                \n",
    "                top_bigrams = get_multi_prompt_ngrams(prompts_data, n=2, top_k=200, min_prompt_ids=2)\n",
    "                if top_bigrams:\n",
    "                    model_top_bigrams[model_name] = top_bigrams\n",
    "                    top_bigram_count = sum(freq for ngram, freq in top_bigrams[:40])\n",
    "                    print(f\"        Found {len(top_bigrams)} top bigrams meeting criteria.\")\n",
    "                else:\n",
    "                    print(\"        No bigrams met the multi-prompt criteria.\")\n",
    "\n",
    "                top_trigrams = get_multi_prompt_ngrams(prompts_data, n=3, top_k=200, min_prompt_ids=2)\n",
    "                if top_trigrams:\n",
    "                    model_top_trigrams[model_name] = top_trigrams\n",
    "                    top_trigram_count = sum(freq for ngram, freq in top_trigrams[:40])\n",
    "                    print(f\"        Found {len(top_trigrams)} top trigrams meeting criteria.\")\n",
    "                else:\n",
    "                    print(\"        No trigrams met the multi-prompt criteria.\")\n",
    "                    \n",
    "                # Calculate normalized repetition score\n",
    "                if total_text_length > 0:\n",
    "                    repetition_score = (top_bigram_count + top_trigram_count) / total_text_length * 1000\n",
    "                else:\n",
    "                    repetition_score = 0\n",
    "\n",
    "            except NameError:\n",
    "                print(\"      ERROR: `get_multi_prompt_ngrams` function not found. Skipping N-gram calculation and score.\")\n",
    "                ngram_calculation_error = True\n",
    "                repetition_score = 'Error'\n",
    "            except Exception as e:\n",
    "                print(f\"      ERROR calculating N-grams for {model_name}: {e}\")\n",
    "                ngram_calculation_error = True\n",
    "                repetition_score = 'Error'\n",
    "\n",
    "            if not ngram_calculation_error:\n",
    "                print(f\"        Calculated N-gram repetition score (normalized by text length * 1000): {repetition_score:.4f}\")\n",
    "\n",
    "            # --- Extract Top Repetitive Words ---\n",
    "            print(\"      Extracting top repetitive words (multi-prompt)...\")\n",
    "            try:\n",
    "                top_repetitive_words = get_top_repetitive_words(texts_with_ids_list, top_n=1000, min_prompt_ids=2) # Get more initially\n",
    "                if top_repetitive_words:\n",
    "                    model_repetitive_words[model_name] = top_repetitive_words # Store all found\n",
    "                    print(f\"        Found {len(top_repetitive_words)} repetitive words meeting criteria.\")\n",
    "                else:\n",
    "                    print(\"        No words met the multi-prompt repetitive word criteria.\")\n",
    "            except NameError:\n",
    "                print(\"      ERROR: `get_top_repetitive_words` function not found. Skipping word extraction.\")\n",
    "                word_extraction_error = True\n",
    "            except Exception as e:\n",
    "                print(f\"      ERROR extracting repetitive words for {model_name}: {e}\")\n",
    "                word_extraction_error = True\n",
    "\n",
    "        elif not has_multi_prompt_data:\n",
    "            print(f\"      Skipping N-grams, Repetition Score, and Repetitive Words: Only 1 prompt ID found.\")\n",
    "        elif not texts_with_ids_list:\n",
    "            print(\"      Skipping N-grams, Repetition Score, and Repetitive Words: No valid text entries found after filtering.\")\n",
    "\n",
    "        # --- Calculate Other Metrics ---\n",
    "        print(\"      Calculating other metrics (length, vocab, slop)...\")\n",
    "        num_responses = len(all_responses_flat)\n",
    "        if num_responses == 0:\n",
    "            print(f\"      Skipping length/vocab/slop metrics: No text after flattening.\")\n",
    "            avg_length = 0.0\n",
    "            vocab_complexity = 0.0\n",
    "            slop_score = 0.0\n",
    "        else:\n",
    "            total_chars = sum(len(r) for r in all_responses_flat if isinstance(r, str))\n",
    "            avg_length = round(total_chars / num_responses, 2)\n",
    "            all_text_combined = \"\\n\\n\".join(r for r in all_responses_flat if isinstance(r, str))\n",
    "            if not all_text_combined.strip():\n",
    "                 print(\"      Warning: Combined text is empty after joining, cannot calculate vocab/slop.\")\n",
    "                 vocab_complexity = 0.0\n",
    "                 slop_score = 0.0\n",
    "            else:\n",
    "                try:\n",
    "                    vocab_complexity = calculate_complexity_index(all_text_combined)\n",
    "                except Exception as e:\n",
    "                    print(f\"      ERROR calculating vocab complexity for {model_name}: {e}\")\n",
    "                    vocab_complexity = 'Error'\n",
    "                try:\n",
    "                    slop_score = calculate_slop_index_new(all_text_combined)\n",
    "                except Exception as e:\n",
    "                    print(f\"      ERROR calculating slop score for {model_name}: {e}\")\n",
    "                    slop_score = 'Error'\n",
    "\n",
    "        model_metrics[model_name] = {\n",
    "            'avg_length': avg_length,\n",
    "            'vocab_complexity': round(vocab_complexity, 4) if isinstance(vocab_complexity, (int, float)) and vocab_complexity != float('inf') else str(vocab_complexity),\n",
    "            'slop_score': round(slop_score, 4) if isinstance(slop_score, (int, float)) else str(slop_score),\n",
    "            'repetition_score': round(repetition_score, 4) if isinstance(repetition_score, (int, float)) else str(repetition_score) # Store potentially updated score\n",
    "        }\n",
    "\n",
    "        # --- Print Summary for Model ---\n",
    "        print(f\"    Metrics - Avg Len: {avg_length:.0f}, Vocab K: {model_metrics[model_name]['vocab_complexity']}, \"\n",
    "              f\"Slop: {model_metrics[model_name]['slop_score']}, Repetition (multi-prompt): {model_metrics[model_name]['repetition_score']}\")\n",
    "\n",
    "        if top_repetitive_words:\n",
    "            filtered_top_words = top_repetitive_words[:10] # Limit printout in console\n",
    "            print(f\"    Top multi-prompt repetitive words: \" + \", \".join([f\"{word} ({score:.1f}x)\" for word, score in filtered_top_words]))\n",
    "        elif has_multi_prompt_data:\n",
    "             print(\"    No words met the multi-prompt repetition criteria.\")\n",
    "\n",
    "        if top_bigrams:\n",
    "            print(\"    Top multi-prompt Bigrams:\")\n",
    "            for bg, freq in top_bigrams[:5]: # Limit printout\n",
    "                print(f\"      - {' '.join(bg)} ({freq})\")\n",
    "        elif has_multi_prompt_data:\n",
    "            print(\"    No bigrams met the multi-prompt criteria.\")\n",
    "\n",
    "        if top_trigrams:\n",
    "            print(\"    Top multi-prompt Trigrams:\")\n",
    "            for tg, freq in top_trigrams[:5]: # Limit printout\n",
    "                print(f\"      - {' '.join(tg)} ({freq})\")\n",
    "        elif has_multi_prompt_data:\n",
    "            print(\"    No trigrams met the multi-prompt criteria.\")\n",
    "\n",
    "\n",
    "    # --- Merging metrics with ELO data ---\n",
    "    print(\"\\nMerging metrics with ELO data...\")\n",
    "    updated_elo_data = elo_data.copy() if isinstance(elo_data, dict) else {}\n",
    "\n",
    "    # Add calculated metrics\n",
    "    for model_name, metrics in model_metrics.items():\n",
    "        if model_name not in updated_elo_data:\n",
    "            updated_elo_data[model_name] = {}\n",
    "            print(f\"  Note: Model '{model_name}' found in runs but not in ELO data. Added entry.\")\n",
    "        updated_elo_data[model_name].update(metrics)\n",
    "\n",
    "    # Add repetitive words if found\n",
    "    for model_name, words_list in model_repetitive_words.items():\n",
    "        if model_name in updated_elo_data:\n",
    "             updated_elo_data[model_name]['top_repetitive_words'] = [\n",
    "                 {\"word\": word, \"score\": float(score)}\n",
    "                 for word, score in words_list\n",
    "             ]\n",
    "\n",
    "    # Add N-grams if found\n",
    "    for model_name, ngrams_list in model_top_bigrams.items():\n",
    "         if model_name in updated_elo_data:\n",
    "             updated_elo_data[model_name]['top_multi_prompt_bigrams'] = [\n",
    "                 {\"ngram\": ' '.join(ngram), \"frequency\": int(freq)}\n",
    "                 for ngram, freq in ngrams_list\n",
    "             ]\n",
    "    for model_name, ngrams_list in model_top_trigrams.items():\n",
    "         if model_name in updated_elo_data:\n",
    "             updated_elo_data[model_name]['top_multi_prompt_trigrams'] = [\n",
    "                 {\"ngram\": ' '.join(ngram), \"frequency\": int(freq)}\n",
    "                 for ngram, freq in ngrams_list\n",
    "             ]\n",
    "\n",
    "    # --- Set default values for models present in ELO but potentially missing metrics ---\n",
    "    default_metrics = {\n",
    "        'avg_length': 0.0, 'vocab_complexity': 'N/A', 'slop_score': 'N/A',\n",
    "        'repetition_score': 0.0, 'top_repetitive_words': [],\n",
    "        'top_multi_prompt_bigrams': [], 'top_multi_prompt_trigrams': []\n",
    "    }\n",
    "    all_model_names = set(updated_elo_data.keys())\n",
    "    for model_name in all_model_names:\n",
    "        if model_name not in updated_elo_data: continue\n",
    "        for key, default_value in default_metrics.items():\n",
    "            updated_elo_data[model_name].setdefault(key, default_value)\n",
    "\n",
    "\n",
    "    # --- Normalize ELO scores ---\n",
    "    print(\"\\nNormalizing ELO scores...\")\n",
    "    raw_elo_scores = {}\n",
    "    for model_name, data in updated_elo_data.items():\n",
    "        elo = data.get('elo')\n",
    "        if isinstance(elo, (int, float)):\n",
    "            raw_elo_scores[model_name] = elo\n",
    "\n",
    "    anchor_models = {\n",
    "        'deepseek/deepseek-r1': 1500,\n",
    "        'meta-llama/llama-3.2-1b-instruct': 200\n",
    "    }\n",
    "\n",
    "    normalized_scores = normalize_elo_scores(raw_elo_scores, anchor_models)\n",
    "\n",
    "    normalized_count = 0\n",
    "    for model_name, normalized_elo in normalized_scores.items():\n",
    "        if model_name in updated_elo_data:\n",
    "            updated_elo_data[model_name]['normalized_elo'] = round(normalized_elo, 1)\n",
    "            normalized_count += 1\n",
    "\n",
    "    print(f\"  Normalized ELO scores for {normalized_count} models using anchor models.\")\n",
    "\n",
    "\n",
    "    # --- Print CSV Results ---\n",
    "    print(\"\\n--- Aggregated Metrics Results (CSV Format) ---\")\n",
    "    print(\"model_name,elo_score,creative_writing_score,avg_length,vocab_complexity,slop_score,repetition_score\")\n",
    "    sorted_models = sorted(\n",
    "        updated_elo_data.items(),\n",
    "        key=lambda item: (\n",
    "            item[1].get(\"normalized_elo\", -float('inf'))\n",
    "            if isinstance(item[1].get(\"normalized_elo\"), (int, float))\n",
    "            else (\n",
    "                item[1].get(\"elo\", -float('inf'))\n",
    "                if isinstance(item[1].get(\"elo\"), (int, float))\n",
    "                else -float('inf')\n",
    "            )\n",
    "        ),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    for model_name, data in sorted_models:\n",
    "        if model_name in MODELS_TO_IGNORE:\n",
    "            continue\n",
    "        updated_name = get_updated_model_name(model_name)\n",
    "        elo = data.get('elo', 'N/A')\n",
    "        elo_display = f\"{elo:.1f}\" if isinstance(elo, (int, float)) else 'N/A'\n",
    "\n",
    "        norm_elo = data.get('normalized_elo', 'N/A')\n",
    "        norm_elo_display = f\"{norm_elo:.1f}\" if isinstance(norm_elo, (int, float)) else 'N/A'\n",
    "\n",
    "        # Calculate creative writing score from scratch\n",
    "        creative_score, iterations = calculate_creative_writing_scores(runs_data, model_name)\n",
    "        if iterations:  # If we got valid iterations data\n",
    "            creative_score_display = f\"{creative_score:.2f}\"\n",
    "            \n",
    "            # Optionally, update the elo_data with our calculated score for consistency\n",
    "            updated_elo_data[model_name]['calculated_creative_score'] = creative_score\n",
    "        else:\n",
    "            # Fall back to existing score if no scores were found\n",
    "            creative_score = data.get('creative_writing_rubric_score_agg', 'N/A')\n",
    "            creative_score_display = f\"{creative_score:.2f}\" if isinstance(creative_score, (int, float)) else 'N/A'\n",
    "\n",
    "        avg_len = data.get('avg_length', 'N/A')\n",
    "        avg_len_display = f\"{avg_len:.0f}\" if isinstance(avg_len, (int, float)) else 'N/A'\n",
    "\n",
    "        vocab = data.get('vocab_complexity', 'N/A')\n",
    "        vocab_display = f\"{float(vocab):.2f}\" if isinstance(vocab, (int, float)) else str(vocab)\n",
    "\n",
    "        slop = data.get('slop_score', 'N/A')\n",
    "        slop_display = f\"{float(slop):.2f}\" if isinstance(slop, (int, float)) else str(slop)\n",
    "\n",
    "        repetition = data.get('repetition_score', 'N/A')\n",
    "        repetition_display = f\"{float(repetition):.2f}\" if isinstance(repetition, (int, float)) else str(repetition)\n",
    "\n",
    "        safe_model_name = f'\"{updated_name}\"' if ',' in updated_name else updated_name\n",
    "        print(f\"{safe_model_name},{norm_elo_display},{creative_score_display},{avg_len_display},{vocab_display},{slop_display},{repetition_display}\")\n",
    "\n",
    "    # --- ADDED: call our new combined Jaccard similarity function\n",
    "    calculate_combined_jaccard_similarities(updated_elo_data, top_n=1500)\n",
    "\n",
    "    # --- Save Updated ELO Data ---\n",
    "    if save_updated_elo:\n",
    "        print(f\"\\nSaving updated ELO data with metrics (and N-grams) to {ELO_RESULTS_UPDATED_FILE}...\")\n",
    "        try:\n",
    "            with open(ELO_RESULTS_UPDATED_FILE, 'w', encoding='utf-8') as f:\n",
    "                json.dump(updated_elo_data, f, indent=2, ensure_ascii=False)\n",
    "            print(\"Save successful.\")\n",
    "        except IOError as e:\n",
    "            print(f\"Error saving updated ELO data to {ELO_RESULTS_UPDATED_FILE}: {e}\")\n",
    "        except TypeError as e:\n",
    "             print(f\"Error serializing updated ELO data to JSON: {e}. Check for non-serializable types.\")\n",
    "\n",
    "\n",
    "    # --- Generate and Print Slop Profile String ---\n",
    "    if print_slop_profile:\n",
    "        print(\"\\n--- Generating Slop Profile String for JS ---\")\n",
    "        slop_profile_output = format_slop_profile_string(updated_elo_data)\n",
    "        print(\"\\n----- BEGIN SLOP PROFILE STRING -----\")\n",
    "        print(slop_profile_output)\n",
    "        print(\"----- END SLOP PROFILE STRING -----\\n\")\n",
    "\n",
    "\n",
    "def normalize_elo_scores(raw_scores, anchor_models=None):\n",
    "    \"\"\"\n",
    "    Normalize ELO scores by anchoring specific models to predefined values.\n",
    "    \n",
    "    Args:\n",
    "        raw_scores (dict): Dictionary of model names to raw ELO scores\n",
    "        anchor_models (dict, optional): Dictionary mapping model names to their anchor values.\n",
    "            Default: {'deepseek/deepseek-r1': 1500, 'mistralai/ministral-3b': 200}\n",
    "            \n",
    "    Returns:\n",
    "        dict: Dictionary of model names to normalized ELO scores\n",
    "    \"\"\"\n",
    "    if anchor_models is None:\n",
    "        anchor_models = {\n",
    "            'deepseek/deepseek-r1': 1500,\n",
    "            'meta-llama/llama-3.2-1b-instruct': 200\n",
    "        }\n",
    "    \n",
    "    # First check if we have at least two anchor models in our raw scores\n",
    "    valid_anchors = {k: v for k, v in anchor_models.items() if k in raw_scores}\n",
    "    \n",
    "    if len(valid_anchors) < 2:\n",
    "        print(f\"Warning: Not enough anchor models found in scores. \"\n",
    "              f\"Found {len(valid_anchors)} of {len(anchor_models)}. \"\n",
    "              f\"Returning raw scores.\")\n",
    "        return {k: v for k, v in raw_scores.items()}\n",
    "    \n",
    "    # Get first two valid anchors to calculate normalization\n",
    "    anchor_items = list(valid_anchors.items())\n",
    "    model_a, target_a = anchor_items[0]\n",
    "    model_b, target_b = anchor_items[1]\n",
    "    \n",
    "    raw_a = raw_scores[model_a]\n",
    "    raw_b = raw_scores[model_b]\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if raw_a == raw_b:\n",
    "        scale = 1.0\n",
    "    else:\n",
    "        scale = (target_a - target_b) / (raw_a - raw_b)\n",
    "    \n",
    "    shift = target_a - (scale * raw_a)\n",
    "    \n",
    "    # Apply the transformation to all scores\n",
    "    normalized_scores = {model: (score * scale + shift) for model, score in raw_scores.items()}\n",
    "    \n",
    "    return normalized_scores\n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure the results directory exists for saving reports\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "    # 1. List available models (optional, uses updated names)\n",
    "    print(\"--- Available Models ---\")\n",
    "    models = list_available_models()\n",
    "    print(\"-\" * 24)\n",
    "\n",
    "    # 2. Calculate and print the aggregated metrics\n",
    "    #    Set save_updated_elo=True to save to ELO_RESULTS_UPDATED_FILE\n",
    "    calculate_and_print_metrics(save_updated_elo=True) # Set to True to save the file\n",
    "    # print(\"-\" * 24)\n",
    "\n",
    "    # 3. Example: Generate and save reports for *all* models\n",
    "    #    (using the updated generate_model_report function)\n",
    "    \n",
    "    print(\"\\nGenerating and saving HTML reports for all models...\")\n",
    "    if models and True:\n",
    "        for model in models:\n",
    "            if model in MODELS_TO_IGNORE:\n",
    "                continue\n",
    "            print(f\"Processing report for: {get_updated_model_name(model)}\")\n",
    "            try:\n",
    "                save_model_report(model) # This now generates the report with themes/fonts\n",
    "            except Exception as e:\n",
    "                print(f\"  ERROR generating report for {model}: {e}\")\n",
    "        print(\"\\nFinished saving reports.\")\n",
    "    else:\n",
    "        print(\"\\nNo models found in ELO data to generate reports for.\")\n",
    "\n",
    "    # 4. Example: View a report directly in IPython/Jupyter (if available)\n",
    "    # if models and 'IPython' in sys.modules:\n",
    "    #     print(f\"\\nDisplaying report for {get_updated_model_name(models[0])} in IPython...\")\n",
    "    #     view_model_report(models[0]) # Display the first model's report\n",
    "    # else:\n",
    "    #      print(\"\\nSkipping direct display (not in IPython or no models found).\")\n",
    "\n",
    "    print(\"\\nScript finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ete3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtempfile\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mete3\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tree, TreeStyle, NodeStyle, TextFace, faces\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Force Qt to run in 'offscreen' mode so ETE won't crash in headless environments\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ete3'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import tempfile\n",
    "import shutil\n",
    "from ete3 import Tree, TreeStyle, NodeStyle, TextFace, faces\n",
    "\n",
    "import os\n",
    "# Force Qt to run in 'offscreen' mode so ETE won't crash in headless environments\n",
    "os.environ[\"QT_QPA_PLATFORM\"] = \"offscreen\"\n",
    "\n",
    "# -----------------------------\n",
    "# GLOBAL FLAG: RUN CONSENSE?\n",
    "# -----------------------------\n",
    "RUN_CONSENSE = True  # set to True to produce a single consensus from multiple best trees\n",
    "\n",
    "MODELS_TO_IGNORE = [\n",
    "    'mistralai/ministral-3b',\n",
    "    'ministral-3b',\n",
    "    'google/gemma-3-4b-it:free',\n",
    "    'unsloth/gemma-2-9b-it'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# --- Helper functions ---\n",
    "def get_updated_model_name(original):\n",
    "    \"\"\"Get the updated model name if a substitution exists.\"\"\"\n",
    "    return MODEL_NAME_SUBS.get(original, original)\n",
    "\n",
    "def sanitize_model_name(model_name):\n",
    "    \"\"\"Sanitize model name for use in filenames.\"\"\"\n",
    "    sanitized = model_name.replace(\"/\", \"__\")\n",
    "    unsafe_chars = r'<>:\"|?*\\\\'\n",
    "    for char in unsafe_chars:\n",
    "        sanitized = sanitized.replace(char, '-')\n",
    "    return sanitized\n",
    "\n",
    "def layout_fn_with_highlight(node, focus_model_name=None, highlight_color=\"#FF0000\"):\n",
    "    \"\"\"\n",
    "    Colors nodes by model family and highlights the focal model.\n",
    "    - Internal nodes: standard style\n",
    "    - Leaf nodes: colored by family, with optional highlighting\n",
    "    \"\"\"\n",
    "    if not node.is_leaf():\n",
    "        # Internal node style\n",
    "        style = NodeStyle()\n",
    "        style[\"size\"] = 0\n",
    "        style[\"hz_line_width\"] = 2\n",
    "        style[\"vt_line_width\"] = 2\n",
    "        node.set_style(style)\n",
    "        return\n",
    "\n",
    "    # Leaf node: figure out color and label\n",
    "    leaf_label = node.name\n",
    "\n",
    "    # If the node has an 'original_name' (PHYLIP code), use that\n",
    "    if hasattr(node, 'original_name'):\n",
    "        leaf_label = node.original_name\n",
    "\n",
    "    # Access family information\n",
    "    family = model_to_family.get(leaf_label, \"Other\")\n",
    "    circle_color = family_colors.get(family, \"#cccccc\")\n",
    "\n",
    "    # Highlight this model if it's the focus\n",
    "    if leaf_label == focus_model_name:\n",
    "        circle_color = highlight_color\n",
    "        text_face = TextFace(get_updated_model_name(leaf_label), fsize=10, fgcolor=highlight_color)\n",
    "    else:\n",
    "        text_face = TextFace(get_updated_model_name(leaf_label), fsize=10, fgcolor=\"black\")\n",
    "\n",
    "    # Attach label face to the branch\n",
    "    faces.add_face_to_node(text_face, node, column=0, position=\"branch-right\")\n",
    "\n",
    "    # Circle style\n",
    "    style = NodeStyle()\n",
    "    style[\"size\"] = 8\n",
    "    style[\"fgcolor\"] = circle_color\n",
    "    style[\"shape\"] = \"circle\"\n",
    "    style[\"hz_line_width\"] = 2\n",
    "    style[\"vt_line_width\"] = 2\n",
    "    node.set_style(style)\n",
    "\n",
    "def render_ete_tree_focus(ete_tree, focus_model_name, output_image, layout=\"c\"):\n",
    "    \"\"\"\n",
    "    Renders an ETE3 tree, highlighting one particular leaf.\n",
    "    layout=\"c\" => circular, layout=\"r\" => rectangular\n",
    "    \"\"\"\n",
    "    ts = TreeStyle()\n",
    "    ts.mode = layout\n",
    "    ts.show_leaf_name = False\n",
    "    ts.show_branch_length = False\n",
    "    ts.show_scale = False\n",
    "    if layout == 'r':\n",
    "        ts.branch_vertical_margin = 10\n",
    "    \n",
    "    # Set width based on layout type\n",
    "    width = 1200 if layout == 'c' else 500\n",
    "\n",
    "    def custom_layout(node):\n",
    "        layout_fn_with_highlight(node, focus_model_name)\n",
    "\n",
    "    ts.layout_fn = custom_layout\n",
    "    ete_tree.render(output_image, w=width, units=\"px\", tree_style=ts)\n",
    "    print(f\"Saved {layout.upper()} tree with highlight on '{get_updated_model_name(focus_model_name)}' => {output_image} (width: {width}px)\")\n",
    "\n",
    "def run_pars_command(env=None, timeout=300):\n",
    "    \"\"\"\n",
    "    Executes PHYLIP 'pars' with minimal interactive input (i.e., 'Y' for defaults).\n",
    "    If you want multiple jumbles, modify 'pars_input' below accordingly.\n",
    "    \"\"\"\n",
    "    # Currently, 'pars_input = \"Y\\n\"' just accepts all defaults.\n",
    "    # If you want to enable jumbles (for multiple equally parsimonious trees), you could do:\n",
    "    #   pars_input = \"J\\n5\\n1\\nY\\nY\\n\"\n",
    "    # and so on, adjusting each question asked by 'pars'.\n",
    "    pars_input = \"Y\\n\"\n",
    "\n",
    "    result = subprocess.run(\n",
    "        [\"pars\"],\n",
    "        input=pars_input,\n",
    "        text=True,\n",
    "        capture_output=True,\n",
    "        env=env,\n",
    "        timeout=timeout\n",
    "    )\n",
    "    return result\n",
    "\n",
    "def run_consense_command(env=None, timeout=300):\n",
    "    \"\"\"\n",
    "    Executes PHYLIP 'consense' with defaults.\n",
    "    \"\"\"\n",
    "    if os.path.exists(\"outfile\"):\n",
    "        os.remove(\"outfile\")\n",
    "    if os.path.exists(\"outtree\"):\n",
    "        os.remove(\"outtree\")\n",
    "\n",
    "    cons_input = \"Y\\n\"\n",
    "    result = subprocess.run(\n",
    "        [\"consense\"],\n",
    "        input=cons_input,\n",
    "        text=True,\n",
    "        capture_output=True,\n",
    "        env=env,\n",
    "        timeout=timeout\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def build_hybrid_parsimony_trees(\n",
    "    elo_file=\"elo_results_with_metrics.json\",\n",
    "    top_n=1500,\n",
    "    output_dir=\"results/hybrid_parsimony\",\n",
    "    phylip_path=\"/usr/local/bin\"\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Extract feature matrices from ELO data\n",
    "    2) Create PHYLIP input with a translation table for model names\n",
    "    3) Run parsimony analysis (pars)\n",
    "    4) Optionally run consense if RUN_CONSENSE = True\n",
    "    5) Load final tree into ETE3 with mapped model names\n",
    "    6) Render multiple views (circular/rectangular) with highlighting\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    charts_dir = os.path.join(output_dir, \"charts\")\n",
    "    if not os.path.exists(charts_dir):\n",
    "        os.makedirs(charts_dir, exist_ok=True)\n",
    "\n",
    "    # --- 1. Load and process ELO data ---\n",
    "    print(\"Loading and processing feature data...\")\n",
    "    with open(elo_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        elo_data = json.load(f)\n",
    "\n",
    "    # Collect features for each model\n",
    "    model_to_feats = {}\n",
    "    for raw_name, info in elo_data.items():\n",
    "        if raw_name in MODELS_TO_IGNORE:\n",
    "            continue\n",
    "\n",
    "        # Just an example with fewer features:\n",
    "        w_count = 1000#100 #200\n",
    "        b_count = 200#20\n",
    "        t_count = 200#20\n",
    "        #w_count = top_n // 3\n",
    "        #b_count = top_n // 3\n",
    "        #t_count = top_n // 3\n",
    "\n",
    "        words = info.get(\"top_repetitive_words\", [])\n",
    "        bigrams = info.get(\"top_multi_prompt_bigrams\", [])\n",
    "        trigrams = info.get(\"top_multi_prompt_trigrams\", [])\n",
    "\n",
    "        sorted_w = sorted(words, key=lambda x: x.get('score', 0), reverse=True)[:w_count]\n",
    "        sorted_b = sorted(bigrams, key=lambda x: x.get('frequency', 0), reverse=True)[:b_count]\n",
    "        sorted_t = sorted(trigrams, key=lambda x: x.get('frequency', 0), reverse=True)[:t_count]\n",
    "\n",
    "        top_words = [x[\"word\"] for x in sorted_w]\n",
    "        top_bigs = [x[\"ngram\"] for x in sorted_b]\n",
    "        top_tris = [x[\"ngram\"] for x in sorted_t]\n",
    "\n",
    "        combined_feats = set(top_words + top_bigs + top_tris)\n",
    "        if combined_feats:\n",
    "            model_to_feats[raw_name] = combined_feats\n",
    "\n",
    "    all_models = sorted(model_to_feats.keys())\n",
    "    if len(all_models) < 2:\n",
    "        print(\"Not enough models with features to build a parsimony tree.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(all_models)} models with feature data.\")\n",
    "\n",
    "    # Build global vocabulary\n",
    "    global_vocab = set()\n",
    "    for feats in model_to_feats.values():\n",
    "        global_vocab.update(feats)\n",
    "    global_vocab = sorted(global_vocab)\n",
    "    print(f\"Total feature space size: {len(global_vocab)} features\")\n",
    "\n",
    "    # --- 2. Create PHYLIP input file ---\n",
    "    print(\"Creating PHYLIP input files...\")\n",
    "    temp_dir = tempfile.mkdtemp(prefix=\"phylip_\")\n",
    "    try:\n",
    "        code_to_model = {}\n",
    "        model_to_code = {}\n",
    "        for i, model in enumerate(all_models):\n",
    "            code = f\"M{i+1:04d}\"  # M0001, M0002, ...\n",
    "            code_to_model[code] = model\n",
    "            model_to_code[model] = code\n",
    "\n",
    "        translation_file = os.path.join(output_dir, \"model_codes.json\")\n",
    "        with open(translation_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({\"code_to_model\": code_to_model, \"model_to_code\": model_to_code},\n",
    "                      f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        phylip_file = os.path.join(temp_dir, \"infile\")\n",
    "        with open(phylip_file, \"w\") as f:\n",
    "            n_taxa = len(all_models)\n",
    "            n_chars = len(global_vocab)\n",
    "            f.write(f\"{n_taxa} {n_chars}\\n\")\n",
    "            for model in all_models:\n",
    "                code = model_to_code[model]\n",
    "                feats = model_to_feats[model]\n",
    "                bits = [\"1\" if feat in feats else \"0\" for feat in global_vocab]\n",
    "                bitstring = \"\".join(bits)\n",
    "                f.write(f\"{code.ljust(10)} {bitstring}\\n\")\n",
    "\n",
    "        # --- 3. Run PHYLIP parsimony analysis ---\n",
    "        print(\"Running PHYLIP parsimony analysis...\")\n",
    "        current_dir = os.getcwd()\n",
    "        output_dir_abs = os.path.abspath(output_dir)\n",
    "        charts_dir_abs = os.path.join(output_dir_abs, \"charts\")\n",
    "        os.makedirs(output_dir_abs, exist_ok=True)\n",
    "        os.makedirs(charts_dir_abs, exist_ok=True)\n",
    "\n",
    "        os.chdir(temp_dir)\n",
    "        try:\n",
    "            env = os.environ.copy()\n",
    "            if phylip_path and os.path.exists(phylip_path):\n",
    "                env[\"PATH\"] = f\"{phylip_path}:{env.get('PATH', '')}\"\n",
    "                print(f\"Added {phylip_path} to PATH\")\n",
    "\n",
    "            # Also try the original location\n",
    "            original_phylip_path = \"/usr/lib/phylip/bin\"\n",
    "            if os.path.exists(original_phylip_path):\n",
    "                env[\"PATH\"] = f\"{original_phylip_path}:{env.get('PATH', '')}\"\n",
    "                print(f\"Added {original_phylip_path} to PATH\")\n",
    "\n",
    "            # Check if 'pars' is in PATH\n",
    "            which_result = subprocess.run([\"which\", \"pars\"],\n",
    "                                          capture_output=True,\n",
    "                                          text=True,\n",
    "                                          env=env)\n",
    "            pars_path = which_result.stdout.strip()\n",
    "            if not pars_path:\n",
    "                print(\"ERROR: Could not find 'pars' executable in the PATH.\")\n",
    "                print(\"Falling back to hierarchical clustering.\")\n",
    "                return\n",
    "\n",
    "            print(f\"Using pars from: {pars_path}\")\n",
    "\n",
    "            # Actually run pars\n",
    "            result = run_pars_command(env=env, timeout=300)\n",
    "            print(f\"PARS STDOUT (first 500 chars):\\n{result.stdout[:500]}...\")\n",
    "            if result.stderr:\n",
    "                print(f\"PARS STDERR:\\n{result.stderr}\")\n",
    "\n",
    "            if result.returncode != 0:\n",
    "                print(f\"PHYLIP Error: pars returned code {result.returncode}\")\n",
    "                print(\"Falling back to hierarchical clustering approach.\")\n",
    "                return\n",
    "\n",
    "            # See if outfile/outtree exist\n",
    "            print(\"Files after running pars:\")\n",
    "            for file in os.listdir('.'):\n",
    "                print(f\" - {file} ({os.path.getsize(file)} bytes)\")\n",
    "\n",
    "            # Copy output files to final location\n",
    "            output_files_found = False\n",
    "            for file in [\"outfile\", \"outtree\"]:\n",
    "                if os.path.exists(file):\n",
    "                    output_files_found = True\n",
    "                    dest_file = os.path.join(output_dir_abs, file)\n",
    "                    shutil.copy(file, dest_file)\n",
    "                    print(f\"Copied {file} to {dest_file}\")\n",
    "\n",
    "            # Save a copy of infile\n",
    "            shutil.copy(\"infile\", os.path.join(output_dir_abs, \"infile\"))\n",
    "\n",
    "            if not output_files_found:\n",
    "                print(\"ERROR: No output files created by PHYLIP 'pars'.\")\n",
    "                print(\"Falling back to hierarchical clustering.\")\n",
    "                return\n",
    "\n",
    "            print(\"PHYLIP parsimony finished successfully.\")\n",
    "\n",
    "            # ------------------------------\n",
    "            # Optional: run consense\n",
    "            # ------------------------------\n",
    "            final_tree_path = os.path.join(output_dir_abs, \"outtree\")  # default\n",
    "            if RUN_CONSENSE:\n",
    "                print(\"RUN_CONSENSE = True, so we'll run 'consense' to build a consensus tree.\")\n",
    "\n",
    "                # Move 'outtree' → 'intree' for consense\n",
    "                intree_path = os.path.join(output_dir_abs, \"intree\")\n",
    "                if os.path.exists(intree_path):\n",
    "                    os.remove(intree_path)\n",
    "                shutil.copy(final_tree_path, intree_path)\n",
    "\n",
    "                # Run 'consense' in the same temp_dir context\n",
    "                # Because consense also expects an \"intree\" in the working directory\n",
    "                # We'll rename in the temp_dir, run consense, then copy results out\n",
    "                # So copy \"intree\" from output_dir_abs → temp_dir\n",
    "                intree_local = os.path.join(temp_dir, \"intree\")\n",
    "                if os.path.exists(intree_local):\n",
    "                    os.remove(intree_local)\n",
    "                shutil.copy(intree_path, intree_local)\n",
    "\n",
    "                which_cons = subprocess.run([\"which\", \"consense\"], capture_output=True, text=True, env=env)\n",
    "                cons_path = which_cons.stdout.strip()\n",
    "                if not cons_path:\n",
    "                    print(\"ERROR: 'consense' not found in PATH. Skipping consensus.\")\n",
    "                else:\n",
    "                    print(f\"Running consense from: {cons_path}\")                    \n",
    "                    res_cons = run_consense_command(env=env, timeout=300)\n",
    "                    print(f\"CONSENSE STDOUT (first 500 chars):\\n{res_cons.stdout[:500]}...\")\n",
    "                    if res_cons.stderr:\n",
    "                        print(f\"CONSENSE STDERR:\\n{res_cons.stderr}\")\n",
    "\n",
    "                    if res_cons.returncode != 0:\n",
    "                        print(f\"ERROR: consense returned code {res_cons.returncode}\")\n",
    "                    else:\n",
    "                        # consense writes 'outfile' and 'outtree'\n",
    "                        # We'll rename 'outtree' → 'outtree_consensus'\n",
    "                        outtree_cons_path = os.path.join(temp_dir, \"outtree\")\n",
    "                        if os.path.exists(outtree_cons_path):\n",
    "                            consensus_dest = os.path.join(output_dir_abs, \"outtree_consensus\")\n",
    "                            shutil.copy(outtree_cons_path, consensus_dest)\n",
    "                            print(f\"Consensus tree => {consensus_dest}\")\n",
    "                            final_tree_path = consensus_dest  # the final we parse\n",
    "\n",
    "        finally:\n",
    "            os.chdir(current_dir)\n",
    "\n",
    "        # --- 4. Load final tree into ETE3 ---\n",
    "        if not os.path.exists(final_tree_path):\n",
    "            print(f\"Error: final tree not found: {final_tree_path}\")\n",
    "            return\n",
    "\n",
    "        # PHYLIP format=1 typically means branch lengths + supports are recognized\n",
    "        tree = Tree(final_tree_path, format=1)\n",
    "\n",
    "        # Map short codes back to original names\n",
    "        for leaf in tree.get_leaves():\n",
    "            original_code = leaf.name.strip()\n",
    "            if original_code in code_to_model:\n",
    "                leaf.original_name = code_to_model[original_code]\n",
    "                leaf.name = code_to_model[original_code]\n",
    "            else:\n",
    "                # Might be an already-correct name or something else\n",
    "                pass\n",
    "\n",
    "        # Basic tree\n",
    "        basic_tree_path = os.path.join(output_dir, \"parsimony_tree_basic.png\")\n",
    "        ts = TreeStyle()\n",
    "        ts.show_leaf_name = False\n",
    "        ts.mode = \"r\"\n",
    "\n",
    "        def basic_layout(node):\n",
    "            layout_fn_with_highlight(node)\n",
    "\n",
    "        ts.layout_fn = basic_layout\n",
    "        tree.render(basic_tree_path, w=800, units=\"px\", tree_style=ts)\n",
    "        print(f\"Saved basic tree: {basic_tree_path}\")\n",
    "\n",
    "        # --- 5. Per-model visualizations\n",
    "        print(\"Generating per-model visualizations...\")\n",
    "        for model_name in all_models:\n",
    "            updated_model = get_updated_model_name(model_name)\n",
    "            sanitized = sanitize_model_name(updated_model)\n",
    "\n",
    "            # Circular layout\n",
    "            circ_png = os.path.join(charts_dir, f\"{sanitized}__phylo_tree_parsimony_circular.png\")\n",
    "            render_ete_tree_focus(tree, model_name, circ_png, layout=\"c\")\n",
    "\n",
    "            # Rectangular layout\n",
    "            rect_png = os.path.join(charts_dir, f\"{sanitized}__phylo_tree_parsimony_rectangular.png\")\n",
    "            render_ete_tree_focus(tree, model_name, rect_png, layout=\"r\")\n",
    "\n",
    "        # Also save as Nexus\n",
    "        nexus_path = os.path.join(output_dir, \"parsimony_tree.nex\")\n",
    "        with open(nexus_path, \"w\") as f:\n",
    "            f.write(\"#NEXUS\\nBEGIN TREES;\\n\")\n",
    "            f.write(f\"  TREE parsimony = {tree.write(format=8)};\\n\")\n",
    "            f.write(\"END;\\n\")\n",
    "\n",
    "        print(f\"Success! Generated circular & rectangular phylogenetic trees for {len(all_models)} models.\")\n",
    "        if RUN_CONSENSE:\n",
    "            print(f\"(Used CONSENSE for a final consensus tree.)\")\n",
    "        print(f\"Reference files in: {output_dir}\")\n",
    "        print(f\"Per-model visualizations in: {charts_dir}\")\n",
    "\n",
    "    finally:\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "\n",
    "def build_fallback_hierarchical_trees(\n",
    "    elo_file=\"elo_results_with_metrics.json\",\n",
    "    top_n=1500,\n",
    "    output_dir=\"results/hierarchical_clustering\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Fallback method that uses scipy for hierarchical clustering.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from scipy.spatial.distance import pdist\n",
    "    from scipy.cluster.hierarchy import linkage, to_tree\n",
    "\n",
    "    print(\"Using fallback hierarchical clustering method...\")\n",
    "\n",
    "    output_dir_abs = os.path.abspath(output_dir)\n",
    "    if not os.path.exists(output_dir_abs):\n",
    "        os.makedirs(output_dir_abs, exist_ok=True)\n",
    "\n",
    "    charts_dir_abs = os.path.join(output_dir_abs, \"charts\")\n",
    "    if not os.path.exists(charts_dir_abs):\n",
    "        os.makedirs(charts_dir_abs, exist_ok=True)\n",
    "\n",
    "    print(\"Loading and processing feature data...\")\n",
    "    with open(elo_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        elo_data = json.load(f)\n",
    "\n",
    "    model_to_feats = {}\n",
    "    for raw_name, info in elo_data.items():\n",
    "        if raw_name in MODELS_TO_IGNORE:\n",
    "            continue\n",
    "\n",
    "        w_count = top_n // 3\n",
    "        b_count = top_n // 3\n",
    "        t_count = top_n // 3\n",
    "\n",
    "        words = info.get(\"top_repetitive_words\", [])\n",
    "        bigrams = info.get(\"top_multi_prompt_bigrams\", [])\n",
    "        trigrams = info.get(\"top_multi_prompt_trigrams\", [])\n",
    "\n",
    "        sorted_w = sorted(words, key=lambda x: x.get('score', 0), reverse=True)[:w_count]\n",
    "        sorted_b = sorted(bigrams, key=lambda x: x.get('frequency', 0), reverse=True)[:b_count]\n",
    "        sorted_t = sorted(trigrams, key=lambda x: x.get('frequency', 0), reverse=True)[:t_count]\n",
    "\n",
    "        top_words = [x[\"word\"] for x in sorted_w]\n",
    "        top_bigs = [x[\"ngram\"] for x in sorted_b]\n",
    "        top_tris = [x[\"ngram\"] for x in sorted_t]\n",
    "\n",
    "        combined_feats = set(top_words + top_bigs + top_tris)\n",
    "        if combined_feats:\n",
    "            model_to_feats[raw_name] = combined_feats\n",
    "\n",
    "    all_models = sorted(model_to_feats.keys())\n",
    "    if len(all_models) < 2:\n",
    "        print(\"Not enough models with features to build a tree.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(all_models)} models with feature data.\")\n",
    "\n",
    "    global_vocab = set()\n",
    "    for feats in model_to_feats.values():\n",
    "        global_vocab.update(feats)\n",
    "    global_vocab = sorted(global_vocab)\n",
    "    print(f\"Total feature space size: {len(global_vocab)} features\")\n",
    "\n",
    "    print(\"Building feature matrix...\")\n",
    "    df = pd.DataFrame(0, index=all_models, columns=global_vocab, dtype=int)\n",
    "    for m in all_models:\n",
    "        for ft in model_to_feats[m]:\n",
    "            if ft in df.columns:\n",
    "                df.loc[m, ft] = 1\n",
    "\n",
    "    print(\"Performing hierarchical clustering...\")\n",
    "    dist_matrix = pdist(df.values, metric='jaccard')\n",
    "    linked = linkage(dist_matrix, method='complete')\n",
    "\n",
    "    root_node = to_tree(linked, rd=False)\n",
    "    ete_tree = Tree()\n",
    "\n",
    "    def scipy_cluster_to_ete(scipy_node, ete_parent, id_to_label):\n",
    "        if scipy_node.is_leaf():\n",
    "            leaf_name = id_to_label[scipy_node.id]\n",
    "            ete_parent.name = leaf_name\n",
    "        else:\n",
    "            left_child = ete_parent.add_child()\n",
    "            scipy_cluster_to_ete(scipy_node.left, left_child, id_to_label)\n",
    "            right_child = ete_parent.add_child()\n",
    "            scipy_cluster_to_ete(scipy_node.right, right_child, id_to_label)\n",
    "\n",
    "    id_to_label = dict(enumerate(df.index))\n",
    "    scipy_cluster_to_ete(root_node, ete_tree, id_to_label)\n",
    "\n",
    "    basic_tree_path = os.path.join(output_dir_abs, \"hierarchical_tree_basic.png\")\n",
    "    ts = TreeStyle()\n",
    "    ts.show_leaf_name = False\n",
    "    ts.mode = \"r\"\n",
    "\n",
    "    def basic_layout(node):\n",
    "        layout_fn_with_highlight(node)\n",
    "\n",
    "    ts.layout_fn = basic_layout\n",
    "    ete_tree.render(basic_tree_path, w=800, units=\"px\", tree_style=ts)\n",
    "    print(f\"Saved basic tree: {basic_tree_path}\")\n",
    "\n",
    "    print(\"Generating per-model visualizations...\")\n",
    "    for model_name in all_models:\n",
    "        updated_model = get_updated_model_name(model_name)\n",
    "        sanitized = sanitize_model_name(updated_model)\n",
    "\n",
    "        circ_png = os.path.join(charts_dir_abs, f\"{sanitized}__hierarchical_circular.png\")\n",
    "        render_ete_tree_focus(ete_tree, model_name, circ_png, layout=\"c\")\n",
    "\n",
    "        rect_png = os.path.join(charts_dir_abs, f\"{sanitized}__hierarchical_rectangular.png\")\n",
    "        render_ete_tree_focus(ete_tree, model_name, rect_png, layout=\"r\")\n",
    "\n",
    "    print(f\"Success! Generated circular & rectangular hierarchical trees for {len(all_models)} models.\")\n",
    "    print(f\"Reference files in: {output_dir_abs}\")\n",
    "    print(f\"Per-model visualizations in: {charts_dir_abs}\")\n",
    "    return ete_tree\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Try to find phylip installation automatically\n",
    "    possible_phylip_paths = [\n",
    "        \"/usr/lib/phylip/bin\",\n",
    "        \"/usr/local/bin\",\n",
    "        \"/opt/homebrew/bin\",\n",
    "        \"/usr/local/phylip\",\n",
    "        os.path.expanduser(\"~/phylip\")\n",
    "    ]\n",
    "    existing_paths = [p for p in possible_phylip_paths if os.path.exists(p)]\n",
    "    phylip_path = None\n",
    "    for path in existing_paths:\n",
    "        if os.path.exists(os.path.join(path, \"pars\")):\n",
    "            phylip_path = path\n",
    "            print(f\"Found PHYLIP at: {phylip_path}\")\n",
    "            break\n",
    "\n",
    "    if phylip_path:\n",
    "        print(f\"Attempting parsimony trees using PHYLIP from {phylip_path}...\")\n",
    "        build_hybrid_parsimony_trees(\n",
    "            elo_file=\"elo_results_with_metrics.json\",\n",
    "            top_n=1500,\n",
    "            output_dir=\"results/hybrid_parsimony\",\n",
    "            phylip_path=phylip_path\n",
    "        )\n",
    "    else:\n",
    "        print(\"Could not locate PHYLIP installation. Searched:\")\n",
    "        for p in possible_phylip_paths:\n",
    "            print(f\" - {p}\")\n",
    "\n",
    "    #print(\"\\nAttempting fallback hierarchical clustering method...\")\n",
    "    #build_fallback_hierarchical_trees(\n",
    "    #    elo_file=\"elo_results_with_metrics.json\",\n",
    "    #    top_n=1500,\n",
    "    #    output_dir=\"results/hierarchical_clustering\"\n",
    "    #)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const chartData = {\n",
      "  \"o3\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        17.75,\n",
      "        18.73,\n",
      "        17.95,\n",
      "        18.49,\n",
      "        19.09,\n",
      "        17.69,\n",
      "        17.12,\n",
      "        17.11,\n",
      "        17.0,\n",
      "        15.95,\n",
      "        16.87,\n",
      "        16.81,\n",
      "        18.04,\n",
      "        16.57,\n",
      "        17.58\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.19,\n",
      "        0.18,\n",
      "        0.3,\n",
      "        0.23,\n",
      "        0.19,\n",
      "        0.3,\n",
      "        0.29,\n",
      "        0.36,\n",
      "        0.18,\n",
      "        0.41,\n",
      "        0.32,\n",
      "        0.26,\n",
      "        0.21,\n",
      "        0.12,\n",
      "        0.27\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.66\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 0.38\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.25\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": 0.22\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.63\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -0.6\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -0.54\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.52\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Gemini 2.5 Pro Exp\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        17.39,\n",
      "        18.6,\n",
      "        17.45,\n",
      "        18.08,\n",
      "        18.71,\n",
      "        17.25,\n",
      "        16.47,\n",
      "        16.29,\n",
      "        16.78,\n",
      "        15.05,\n",
      "        16.48,\n",
      "        16.51,\n",
      "        18.07,\n",
      "        16.27,\n",
      "        17.28\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.07,\n",
      "        0.15,\n",
      "        0.19,\n",
      "        0.1,\n",
      "        0.07,\n",
      "        0.19,\n",
      "        0.11,\n",
      "        0.16,\n",
      "        0.11,\n",
      "        0.22,\n",
      "        0.24,\n",
      "        0.2,\n",
      "        0.23,\n",
      "        -0.03,\n",
      "        0.2\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.83\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": 0.73\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": 0.5\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.42\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.54\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -0.51\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.36\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.34\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"DeepSeek R1\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        17.58,\n",
      "        18.34,\n",
      "        17.39,\n",
      "        18.08,\n",
      "        18.48,\n",
      "        17.1,\n",
      "        16.82,\n",
      "        16.47,\n",
      "        16.79,\n",
      "        14.92,\n",
      "        16.06,\n",
      "        16.29,\n",
      "        17.61,\n",
      "        16.65,\n",
      "        16.95\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.14,\n",
      "        0.06,\n",
      "        0.19,\n",
      "        0.11,\n",
      "        0.02,\n",
      "        0.16,\n",
      "        0.23,\n",
      "        0.23,\n",
      "        0.11,\n",
      "        0.2,\n",
      "        0.12,\n",
      "        0.15,\n",
      "        0.08,\n",
      "        0.11,\n",
      "        0.12\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.96\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": 0.7\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.59\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": 0.28\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -0.7\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.47\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.13\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.11\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"ChatGPT-4o Latest\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        17.03,\n",
      "        18.0,\n",
      "        16.09,\n",
      "        17.53,\n",
      "        17.86,\n",
      "        16.21,\n",
      "        15.83,\n",
      "        15.43,\n",
      "        16.33,\n",
      "        13.54,\n",
      "        15.21,\n",
      "        15.19,\n",
      "        17.16,\n",
      "        16.74,\n",
      "        16.05\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.02,\n",
      "        0.01,\n",
      "        -0.2,\n",
      "        -0.02,\n",
      "        -0.13,\n",
      "        -0.0,\n",
      "        -0.0,\n",
      "        0.07,\n",
      "        0.11,\n",
      "        -0.13,\n",
      "        0.07,\n",
      "        -0.16,\n",
      "        0.07,\n",
      "        0.27,\n",
      "        -0.12\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.33\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.2\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 0.2\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.2\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.8\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -0.63\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.63\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": -0.53\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"openrouter/optimus-alpha\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        17.24,\n",
      "        18.21,\n",
      "        16.81,\n",
      "        17.83,\n",
      "        18.51,\n",
      "        16.7,\n",
      "        16.16,\n",
      "        15.84,\n",
      "        16.45,\n",
      "        14.22,\n",
      "        15.88,\n",
      "        15.81,\n",
      "        17.37,\n",
      "        16.49,\n",
      "        16.67\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.03,\n",
      "        0.01,\n",
      "        0.0,\n",
      "        0.04,\n",
      "        0.04,\n",
      "        0.04,\n",
      "        0.03,\n",
      "        0.05,\n",
      "        -0.01,\n",
      "        -0.02,\n",
      "        0.1,\n",
      "        -0.01,\n",
      "        0.0,\n",
      "        0.09,\n",
      "        0.03\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.76\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.19\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.15\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": 0.05\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.83\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.8\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.59\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -0.54\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"openai/gpt-4.1\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        17.26,\n",
      "        18.23,\n",
      "        17.04,\n",
      "        17.83,\n",
      "        18.65,\n",
      "        16.77,\n",
      "        16.17,\n",
      "        15.98,\n",
      "        16.5,\n",
      "        14.32,\n",
      "        15.97,\n",
      "        15.87,\n",
      "        17.38,\n",
      "        16.5,\n",
      "        16.66\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.07,\n",
      "        0.05,\n",
      "        0.09,\n",
      "        0.05,\n",
      "        0.12,\n",
      "        0.08,\n",
      "        0.06,\n",
      "        0.1,\n",
      "        0.05,\n",
      "        0.02,\n",
      "        0.15,\n",
      "        0.02,\n",
      "        0.01,\n",
      "        0.14,\n",
      "        0.05\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.88\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.74\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.49\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.38\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.8\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.79\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.27\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": -0.26\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"openrouter/quasar-alpha\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        17.07,\n",
      "        18.27,\n",
      "        16.81,\n",
      "        17.73,\n",
      "        18.64,\n",
      "        16.61,\n",
      "        16.01,\n",
      "        15.76,\n",
      "        16.45,\n",
      "        14.16,\n",
      "        15.97,\n",
      "        16.05,\n",
      "        17.22,\n",
      "        16.06,\n",
      "        16.65\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.0,\n",
      "        0.08,\n",
      "        0.0,\n",
      "        0.01,\n",
      "        0.13,\n",
      "        0.03,\n",
      "        -0.0,\n",
      "        0.02,\n",
      "        0.04,\n",
      "        -0.05,\n",
      "        0.17,\n",
      "        0.11,\n",
      "        -0.03,\n",
      "        -0.02,\n",
      "        0.06\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.75\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.55\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.39\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": 0.22\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.75\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -0.67\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.37\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": -0.34\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Grok 3 Beta\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.88,\n",
      "        18.22,\n",
      "        16.85,\n",
      "        17.61,\n",
      "        18.56,\n",
      "        16.5,\n",
      "        15.74,\n",
      "        15.48,\n",
      "        16.29,\n",
      "        14.07,\n",
      "        15.74,\n",
      "        15.99,\n",
      "        17.69,\n",
      "        15.62,\n",
      "        16.73\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.07,\n",
      "        0.07,\n",
      "        0.04,\n",
      "        -0.02,\n",
      "        0.11,\n",
      "        -0.0,\n",
      "        -0.09,\n",
      "        -0.07,\n",
      "        -0.02,\n",
      "        -0.06,\n",
      "        0.11,\n",
      "        0.1,\n",
      "        0.16,\n",
      "        -0.18,\n",
      "        0.1\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.66\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 0.65\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": 0.6\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.57\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": -0.47\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.35\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.33\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.31\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Claude 3.7 Sonnet\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        17.23,\n",
      "        18.24,\n",
      "        16.39,\n",
      "        17.7,\n",
      "        18.43,\n",
      "        16.58,\n",
      "        16.04,\n",
      "        15.41,\n",
      "        16.49,\n",
      "        14.16,\n",
      "        15.39,\n",
      "        15.63,\n",
      "        17.06,\n",
      "        16.86,\n",
      "        16.45\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.09,\n",
      "        0.09,\n",
      "        -0.14,\n",
      "        0.03,\n",
      "        0.08,\n",
      "        0.04,\n",
      "        0.04,\n",
      "        -0.08,\n",
      "        0.08,\n",
      "        -0.02,\n",
      "        -0.0,\n",
      "        -0.04,\n",
      "        -0.07,\n",
      "        0.27,\n",
      "        0.0\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.22\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.2\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.18\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.16\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.59\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.54\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.35\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.24\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"QwQ 32B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.93,\n",
      "        17.72,\n",
      "        16.89,\n",
      "        17.65,\n",
      "        18.48,\n",
      "        16.33,\n",
      "        15.94,\n",
      "        15.52,\n",
      "        16.32,\n",
      "        14.35,\n",
      "        15.07,\n",
      "        15.74,\n",
      "        17.0,\n",
      "        15.83,\n",
      "        16.45\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.07,\n",
      "        -0.13,\n",
      "        0.04,\n",
      "        -0.02,\n",
      "        0.07,\n",
      "        -0.01,\n",
      "        -0.03,\n",
      "        0.03,\n",
      "        0.07,\n",
      "        0.12,\n",
      "        -0.07,\n",
      "        -0.01,\n",
      "        -0.04,\n",
      "        -0.06,\n",
      "        -0.01\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.65\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.63\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.36\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.31\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.44\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.42\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -0.36\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.2\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Gemma 3 27B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.85,\n",
      "        17.87,\n",
      "        16.56,\n",
      "        17.52,\n",
      "        18.33,\n",
      "        16.31,\n",
      "        15.77,\n",
      "        15.04,\n",
      "        16.19,\n",
      "        13.96,\n",
      "        14.85,\n",
      "        15.78,\n",
      "        17.16,\n",
      "        15.73,\n",
      "        16.46\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.08,\n",
      "        -0.07,\n",
      "        -0.08,\n",
      "        -0.06,\n",
      "        0.02,\n",
      "        -0.01,\n",
      "        -0.07,\n",
      "        -0.14,\n",
      "        0.03,\n",
      "        -0.03,\n",
      "        -0.13,\n",
      "        0.03,\n",
      "        0.04,\n",
      "        -0.09,\n",
      "        0.01\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.87\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.85\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.8\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": 0.69\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.9\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -0.39\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.28\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -0.25\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"DeepSeek Chat v3\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        17.18,\n",
      "        17.98,\n",
      "        16.08,\n",
      "        17.49,\n",
      "        17.11,\n",
      "        16.16,\n",
      "        15.89,\n",
      "        15.43,\n",
      "        16.46,\n",
      "        13.58,\n",
      "        15.13,\n",
      "        15.03,\n",
      "        17.25,\n",
      "        16.88,\n",
      "        15.9\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.09,\n",
      "        0.03,\n",
      "        -0.17,\n",
      "        -0.01,\n",
      "        -0.31,\n",
      "        0.01,\n",
      "        0.05,\n",
      "        0.1,\n",
      "        0.16,\n",
      "        -0.08,\n",
      "        0.07,\n",
      "        -0.18,\n",
      "        0.13,\n",
      "        0.3,\n",
      "        -0.13\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.41\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.31\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.19\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.18\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.52\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -0.48\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": -0.38\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.25\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"GPT-4.5 Preview\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.86,\n",
      "        18.08,\n",
      "        16.23,\n",
      "        17.4,\n",
      "        18.39,\n",
      "        16.14,\n",
      "        15.57,\n",
      "        15.16,\n",
      "        16.31,\n",
      "        13.53,\n",
      "        15.07,\n",
      "        15.39,\n",
      "        17.19,\n",
      "        15.86,\n",
      "        16.21\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.01,\n",
      "        0.09,\n",
      "        -0.08,\n",
      "        -0.02,\n",
      "        0.13,\n",
      "        0.04,\n",
      "        -0.04,\n",
      "        0.03,\n",
      "        0.14,\n",
      "        -0.06,\n",
      "        0.09,\n",
      "        -0.01,\n",
      "        0.14,\n",
      "        -0.01,\n",
      "        0.02\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.91\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 0.59\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.56\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.79\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": -0.56\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.41\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.29\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Command A\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.72,\n",
      "        17.81,\n",
      "        16.32,\n",
      "        17.38,\n",
      "        18.21,\n",
      "        15.88,\n",
      "        15.35,\n",
      "        14.96,\n",
      "        16.0,\n",
      "        13.53,\n",
      "        14.58,\n",
      "        15.27,\n",
      "        16.79,\n",
      "        15.64,\n",
      "        15.97\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.02,\n",
      "        0.01,\n",
      "        -0.04,\n",
      "        0.01,\n",
      "        0.09,\n",
      "        -0.03,\n",
      "        -0.09,\n",
      "        -0.03,\n",
      "        0.05,\n",
      "        -0.05,\n",
      "        -0.06,\n",
      "        -0.04,\n",
      "        -0.0,\n",
      "        -0.02,\n",
      "        -0.05\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.66\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.32\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": 0.26\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.19\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.55\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.43\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": -0.36\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -0.23\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Darkest Muse v1\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.28,\n",
      "        17.1,\n",
      "        17.06,\n",
      "        17.39,\n",
      "        17.22,\n",
      "        16.08,\n",
      "        15.31,\n",
      "        15.64,\n",
      "        15.1,\n",
      "        14.34,\n",
      "        14.99,\n",
      "        15.58,\n",
      "        17.14,\n",
      "        14.18,\n",
      "        16.09\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.15,\n",
      "        -0.21,\n",
      "        0.25,\n",
      "        0.05,\n",
      "        -0.23,\n",
      "        0.1,\n",
      "        -0.06,\n",
      "        0.26,\n",
      "        -0.23,\n",
      "        0.26,\n",
      "        0.17,\n",
      "        0.14,\n",
      "        0.16,\n",
      "        -0.4,\n",
      "        0.05\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.95\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.94\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 0.48\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.44\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.51\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -0.5\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -0.47\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.33\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Reka Flash 3 (Free)\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.57,\n",
      "        17.33,\n",
      "        16.53,\n",
      "        17.27,\n",
      "        17.62,\n",
      "        16.0,\n",
      "        15.58,\n",
      "        15.3,\n",
      "        15.98,\n",
      "        14.17,\n",
      "        14.58,\n",
      "        15.18,\n",
      "        16.3,\n",
      "        15.52,\n",
      "        15.8\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.0,\n",
      "        -0.12,\n",
      "        0.14,\n",
      "        0.05,\n",
      "        -0.05,\n",
      "        0.12,\n",
      "        0.11,\n",
      "        0.21,\n",
      "        0.12,\n",
      "        0.25,\n",
      "        0.1,\n",
      "        0.04,\n",
      "        -0.12,\n",
      "        0.01,\n",
      "        -0.01\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.73\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.39\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": 0.31\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.3\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -0.98\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -0.56\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": -0.34\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.28\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Gemma 3 12B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.49,\n",
      "        17.66,\n",
      "        15.93,\n",
      "        17.1,\n",
      "        18.11,\n",
      "        15.83,\n",
      "        15.17,\n",
      "        14.51,\n",
      "        15.77,\n",
      "        13.55,\n",
      "        14.28,\n",
      "        15.21,\n",
      "        16.85,\n",
      "        15.73,\n",
      "        15.85\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.01,\n",
      "        0.06,\n",
      "        -0.03,\n",
      "        0.03,\n",
      "        0.18,\n",
      "        0.12,\n",
      "        0.0,\n",
      "        -0.01,\n",
      "        0.09,\n",
      "        0.12,\n",
      "        0.07,\n",
      "        0.12,\n",
      "        0.16,\n",
      "        0.12,\n",
      "        0.08\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.75\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.41\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": 0.41\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.4\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.79\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": -0.7\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.66\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.45\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Gemma 3 4B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.62,\n",
      "        17.5,\n",
      "        16.62,\n",
      "        17.08,\n",
      "        17.55,\n",
      "        16.0,\n",
      "        15.53,\n",
      "        14.79,\n",
      "        15.67,\n",
      "        13.71,\n",
      "        14.18,\n",
      "        15.19,\n",
      "        16.58,\n",
      "        15.18,\n",
      "        15.87\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.1,\n",
      "        0.04,\n",
      "        0.27,\n",
      "        0.08,\n",
      "        0.03,\n",
      "        0.22,\n",
      "        0.19,\n",
      "        0.16,\n",
      "        0.09,\n",
      "        0.21,\n",
      "        0.11,\n",
      "        0.18,\n",
      "        0.13,\n",
      "        -0.09,\n",
      "        0.15\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": 0.66\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": 0.57\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": 0.39\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.32\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -0.48\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -0.47\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.29\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.2\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"accounts/fireworks/models/deepseek-v3\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        18.34,\n",
      "        18.91,\n",
      "        17.79,\n",
      "        18.58,\n",
      "        19.35,\n",
      "        14.14,\n",
      "        17.03,\n",
      "        12.74,\n",
      "        13.39,\n",
      "        11.53,\n",
      "        12.18,\n",
      "        16.69,\n",
      "        14.59,\n",
      "        14.52,\n",
      "        17.05\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.51,\n",
      "        0.43,\n",
      "        0.51,\n",
      "        0.47,\n",
      "        0.52,\n",
      "        -0.32,\n",
      "        0.52,\n",
      "        -0.39,\n",
      "        -0.48,\n",
      "        -0.39,\n",
      "        -0.4,\n",
      "        0.52,\n",
      "        -0.41,\n",
      "        -0.25,\n",
      "        0.46\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.95\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": 0.93\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.88\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.78\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.87\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.86\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.85\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.84\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Gemma 3 Glitter 12B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.26,\n",
      "        17.4,\n",
      "        15.76,\n",
      "        16.94,\n",
      "        17.9,\n",
      "        15.64,\n",
      "        14.91,\n",
      "        14.37,\n",
      "        15.66,\n",
      "        13.24,\n",
      "        14.23,\n",
      "        14.9,\n",
      "        16.47,\n",
      "        15.5,\n",
      "        15.67\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.06,\n",
      "        0.1,\n",
      "        0.13,\n",
      "        0.13,\n",
      "        0.3,\n",
      "        0.24,\n",
      "        0.1,\n",
      "        0.18,\n",
      "        0.18,\n",
      "        0.19,\n",
      "        0.28,\n",
      "        0.22,\n",
      "        0.22,\n",
      "        0.12,\n",
      "        0.22\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 0.77\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": 0.44\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.34\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.3\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -0.68\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": -0.67\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -0.54\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -0.46\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Gemini 2.0 Flash\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.47,\n",
      "        17.5,\n",
      "        15.61,\n",
      "        16.94,\n",
      "        17.53,\n",
      "        15.36,\n",
      "        14.86,\n",
      "        14.32,\n",
      "        15.66,\n",
      "        12.98,\n",
      "        14.04,\n",
      "        14.76,\n",
      "        16.54,\n",
      "        15.72,\n",
      "        15.48\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.17,\n",
      "        0.18,\n",
      "        0.14,\n",
      "        0.18,\n",
      "        0.26,\n",
      "        0.22,\n",
      "        0.15,\n",
      "        0.22,\n",
      "        0.23,\n",
      "        0.16,\n",
      "        0.29,\n",
      "        0.24,\n",
      "        0.3,\n",
      "        0.22,\n",
      "        0.22\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 0.84\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.53\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.24\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.08\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": -0.88\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.69\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.58\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -0.52\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Claude 3.5 Sonnet\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.54,\n",
      "        17.34,\n",
      "        15.15,\n",
      "        16.78,\n",
      "        16.98,\n",
      "        15.43,\n",
      "        14.89,\n",
      "        14.69,\n",
      "        16.1,\n",
      "        12.94,\n",
      "        14.64,\n",
      "        14.17,\n",
      "        16.38,\n",
      "        16.62,\n",
      "        15.26\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.24,\n",
      "        0.17,\n",
      "        0.04,\n",
      "        0.19,\n",
      "        0.16,\n",
      "        0.29,\n",
      "        0.22,\n",
      "        0.37,\n",
      "        0.37,\n",
      "        0.21,\n",
      "        0.45,\n",
      "        0.14,\n",
      "        0.31,\n",
      "        0.44,\n",
      "        0.22\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.91\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.58\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.56\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.32\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.49\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -0.34\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -0.3\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.21\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"openai/gpt-4.1-mini\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        16.23,\n",
      "        17.3,\n",
      "        15.4,\n",
      "        16.65,\n",
      "        17.21,\n",
      "        15.1,\n",
      "        14.75,\n",
      "        14.16,\n",
      "        15.4,\n",
      "        12.8,\n",
      "        13.49,\n",
      "        14.03,\n",
      "        16.08,\n",
      "        15.65,\n",
      "        15.11\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.19,\n",
      "        0.2,\n",
      "        0.2,\n",
      "        0.19,\n",
      "        0.27,\n",
      "        0.26,\n",
      "        0.24,\n",
      "        0.31,\n",
      "        0.24,\n",
      "        0.23,\n",
      "        0.29,\n",
      "        0.17,\n",
      "        0.29,\n",
      "        0.27,\n",
      "        0.23\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.75\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 0.71\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.53\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.42\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.67\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.61\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -0.58\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -0.54\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Gemma 2 Ifable 9B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        14.71,\n",
      "        16.67,\n",
      "        16.71,\n",
      "        16.23,\n",
      "        17.05,\n",
      "        15.23,\n",
      "        14.32,\n",
      "        14.82,\n",
      "        14.81,\n",
      "        14.01,\n",
      "        13.85,\n",
      "        15.01,\n",
      "        16.43,\n",
      "        12.47,\n",
      "        15.51\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.28,\n",
      "        0.03,\n",
      "        0.49,\n",
      "        0.12,\n",
      "        0.29,\n",
      "        0.34,\n",
      "        0.17,\n",
      "        0.47,\n",
      "        0.13,\n",
      "        0.5,\n",
      "        0.41,\n",
      "        0.43,\n",
      "        0.41,\n",
      "        -0.52,\n",
      "        0.37\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.83\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.56\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 0.43\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.6\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -0.32\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.25\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.24\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"openai/gpt-4.1-nano\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        15.61,\n",
      "        16.76,\n",
      "        14.62,\n",
      "        15.94,\n",
      "        16.1,\n",
      "        14.3,\n",
      "        13.91,\n",
      "        12.87,\n",
      "        14.34,\n",
      "        11.98,\n",
      "        12.0,\n",
      "        13.07,\n",
      "        15.82,\n",
      "        14.8,\n",
      "        14.18\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.09,\n",
      "        0.13,\n",
      "        0.09,\n",
      "        0.08,\n",
      "        0.11,\n",
      "        0.17,\n",
      "        0.1,\n",
      "        0.08,\n",
      "        0.0,\n",
      "        0.1,\n",
      "        -0.02,\n",
      "        -0.01,\n",
      "        0.33,\n",
      "        0.09,\n",
      "        0.09\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": 0.28\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.12\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.06\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": 0.04\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.91\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.83\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.09\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.07\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"GPT-4o Mini\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        15.19,\n",
      "        16.42,\n",
      "        14.11,\n",
      "        15.46,\n",
      "        15.99,\n",
      "        13.69,\n",
      "        13.33,\n",
      "        12.67,\n",
      "        14.43,\n",
      "        11.51,\n",
      "        11.81,\n",
      "        12.86,\n",
      "        14.82,\n",
      "        14.42,\n",
      "        13.6\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.04,\n",
      "        0.05,\n",
      "        0.01,\n",
      "        -0.04,\n",
      "        0.16,\n",
      "        0.05,\n",
      "        -0.05,\n",
      "        0.12,\n",
      "        0.07,\n",
      "        0.02,\n",
      "        0.03,\n",
      "        0.03,\n",
      "        0.12,\n",
      "        -0.07,\n",
      "        -0.04\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.68\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.66\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.29\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.12\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": -0.75\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": -0.71\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.66\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.63\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"mistralai/pixtral-large-2411\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        15.02,\n",
      "        16.11,\n",
      "        13.36,\n",
      "        15.14,\n",
      "        16.08,\n",
      "        13.07,\n",
      "        12.73,\n",
      "        11.86,\n",
      "        13.68,\n",
      "        10.84,\n",
      "        10.95,\n",
      "        12.26,\n",
      "        13.84,\n",
      "        14.46,\n",
      "        13.23\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.04,\n",
      "        -0.01,\n",
      "        -0.18,\n",
      "        -0.09,\n",
      "        0.27,\n",
      "        -0.1,\n",
      "        -0.18,\n",
      "        -0.09,\n",
      "        -0.16,\n",
      "        -0.14,\n",
      "        -0.18,\n",
      "        -0.1,\n",
      "        -0.17,\n",
      "        0.0,\n",
      "        -0.09\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.22\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.2\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.12\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": 0.02\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.96\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.87\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.69\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"mistralai/mistral-large-2411\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        14.85,\n",
      "        16.06,\n",
      "        13.04,\n",
      "        14.83,\n",
      "        15.56,\n",
      "        12.99,\n",
      "        12.56,\n",
      "        11.71,\n",
      "        14.15,\n",
      "        10.94,\n",
      "        11.22,\n",
      "        11.93,\n",
      "        13.67,\n",
      "        14.77,\n",
      "        12.82\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.04,\n",
      "        0.05,\n",
      "        -0.21,\n",
      "        -0.13,\n",
      "        0.19,\n",
      "        -0.02,\n",
      "        -0.16,\n",
      "        -0.04,\n",
      "        0.13,\n",
      "        -0.01,\n",
      "        0.04,\n",
      "        -0.12,\n",
      "        -0.14,\n",
      "        0.18,\n",
      "        -0.15\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.92\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.69\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.33\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 0.29\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": -0.69\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": -0.61\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.54\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.46\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Claude 3.5 Haiku\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        14.44,\n",
      "        15.15,\n",
      "        12.52,\n",
      "        14.56,\n",
      "        11.64,\n",
      "        12.3,\n",
      "        12.56,\n",
      "        10.56,\n",
      "        14.16,\n",
      "        10.53,\n",
      "        9.63,\n",
      "        10.55,\n",
      "        13.66,\n",
      "        14.67,\n",
      "        11.99\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.13,\n",
      "        -0.22,\n",
      "        -0.26,\n",
      "        -0.15,\n",
      "        -0.63,\n",
      "        -0.16,\n",
      "        -0.08,\n",
      "        -0.3,\n",
      "        0.19,\n",
      "        -0.06,\n",
      "        -0.35,\n",
      "        -0.39,\n",
      "        -0.06,\n",
      "        0.16,\n",
      "        -0.3\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.91\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": 0.3\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.3\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": 0.26\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.35\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.29\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": -0.2\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.19\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Gemma 3 Starshine 12B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        14.3,\n",
      "        15.12,\n",
      "        12.64,\n",
      "        14.28,\n",
      "        13.97,\n",
      "        12.02,\n",
      "        11.92,\n",
      "        10.64,\n",
      "        13.02,\n",
      "        9.98,\n",
      "        10.21,\n",
      "        11.34,\n",
      "        12.1,\n",
      "        14.19,\n",
      "        11.93\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.09,\n",
      "        -0.15,\n",
      "        -0.12,\n",
      "        -0.15,\n",
      "        -0.14,\n",
      "        -0.18,\n",
      "        -0.18,\n",
      "        -0.22,\n",
      "        -0.19,\n",
      "        -0.19,\n",
      "        -0.15,\n",
      "        -0.09,\n",
      "        -0.42,\n",
      "        0.01,\n",
      "        -0.23\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.47\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.44\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.27\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.08\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": -0.24\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.2\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.11\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.09\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Mistral Nemo\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        14.24,\n",
      "        15.1,\n",
      "        12.92,\n",
      "        14.32,\n",
      "        14.01,\n",
      "        12.02,\n",
      "        12.07,\n",
      "        10.76,\n",
      "        12.61,\n",
      "        10.12,\n",
      "        9.81,\n",
      "        11.45,\n",
      "        11.93,\n",
      "        13.05,\n",
      "        12.23\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.04,\n",
      "        -0.08,\n",
      "        0.1,\n",
      "        -0.06,\n",
      "        -0.03,\n",
      "        -0.07,\n",
      "        -0.04,\n",
      "        -0.09,\n",
      "        -0.22,\n",
      "        -0.05,\n",
      "        -0.18,\n",
      "        0.08,\n",
      "        -0.4,\n",
      "        -0.3,\n",
      "        -0.05\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.9\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.19\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.11\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": 0.11\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -0.63\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.37\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.27\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.06\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"meta-llama/llama-4-maverick\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        13.98,\n",
      "        15.32,\n",
      "        11.89,\n",
      "        14.02,\n",
      "        13.81,\n",
      "        11.55,\n",
      "        11.52,\n",
      "        10.25,\n",
      "        12.56,\n",
      "        9.52,\n",
      "        9.58,\n",
      "        10.23,\n",
      "        12.95,\n",
      "        14.24,\n",
      "        11.69\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.06,\n",
      "        0.12,\n",
      "        -0.2,\n",
      "        -0.08,\n",
      "        0.0,\n",
      "        -0.13,\n",
      "        -0.15,\n",
      "        -0.16,\n",
      "        -0.15,\n",
      "        -0.18,\n",
      "        -0.15,\n",
      "        -0.24,\n",
      "        -0.05,\n",
      "        0.15,\n",
      "        -0.15\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.9\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.5\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.33\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.33\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -0.47\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.28\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.13\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.08\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"openai/gpt-4-0314\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        14.06,\n",
      "        15.24,\n",
      "        11.45,\n",
      "        13.98,\n",
      "        13.48,\n",
      "        11.6,\n",
      "        11.51,\n",
      "        9.97,\n",
      "        13.51,\n",
      "        9.39,\n",
      "        9.18,\n",
      "        10.23,\n",
      "        12.49,\n",
      "        14.51,\n",
      "        11.44\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.08,\n",
      "        0.17,\n",
      "        -0.23,\n",
      "        0.01,\n",
      "        0.02,\n",
      "        0.03,\n",
      "        -0.05,\n",
      "        -0.13,\n",
      "        0.28,\n",
      "        -0.13,\n",
      "        -0.16,\n",
      "        -0.16,\n",
      "        -0.11,\n",
      "        0.28,\n",
      "        -0.13\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.59\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.31\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": 0.18\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.54\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.52\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.39\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": -0.36\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"LFM 7B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        13.66,\n",
      "        14.76,\n",
      "        12.96,\n",
      "        13.74,\n",
      "        13.48,\n",
      "        11.78,\n",
      "        11.61,\n",
      "        10.35,\n",
      "        12.23,\n",
      "        10.07,\n",
      "        9.48,\n",
      "        10.84,\n",
      "        12.08,\n",
      "        11.72,\n",
      "        11.62\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.0,\n",
      "        0.1,\n",
      "        0.35,\n",
      "        0.02,\n",
      "        0.19,\n",
      "        0.21,\n",
      "        0.12,\n",
      "        0.16,\n",
      "        -0.1,\n",
      "        0.24,\n",
      "        0.1,\n",
      "        0.2,\n",
      "        -0.12,\n",
      "        -0.46,\n",
      "        0.08\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": 0.47\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": 0.38\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.33\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 0.28\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.27\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.24\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.12\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.09\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Llama 3.1 405B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        13.64,\n",
      "        14.48,\n",
      "        10.65,\n",
      "        13.38,\n",
      "        11.73,\n",
      "        10.51,\n",
      "        10.88,\n",
      "        9.12,\n",
      "        12.85,\n",
      "        8.46,\n",
      "        8.45,\n",
      "        9.28,\n",
      "        12.73,\n",
      "        14.35,\n",
      "        10.88\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.1,\n",
      "        0.15,\n",
      "        -0.23,\n",
      "        0.01,\n",
      "        -0.24,\n",
      "        -0.11,\n",
      "        -0.04,\n",
      "        -0.15,\n",
      "        0.25,\n",
      "        -0.2,\n",
      "        -0.15,\n",
      "        -0.2,\n",
      "        0.25,\n",
      "        0.29,\n",
      "        -0.05\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.83\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.81\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.5\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.35\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -0.92\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.73\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.72\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.46\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Claude 3 Haiku\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        13.59,\n",
      "        14.25,\n",
      "        10.39,\n",
      "        13.15,\n",
      "        11.9,\n",
      "        10.57,\n",
      "        10.68,\n",
      "        9.45,\n",
      "        13.41,\n",
      "        8.43,\n",
      "        8.68,\n",
      "        9.25,\n",
      "        12.51,\n",
      "        14.26,\n",
      "        10.52\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.12,\n",
      "        0.12,\n",
      "        -0.26,\n",
      "        -0.03,\n",
      "        -0.14,\n",
      "        -0.01,\n",
      "        -0.06,\n",
      "        0.05,\n",
      "        0.4,\n",
      "        -0.16,\n",
      "        -0.0,\n",
      "        -0.16,\n",
      "        0.24,\n",
      "        0.29,\n",
      "        -0.13\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.64\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.5\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.24\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.23\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.55\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.54\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -0.46\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": -0.4\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Gemma 2 9B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        13.33,\n",
      "        13.91,\n",
      "        11.4,\n",
      "        13.26,\n",
      "        10.98,\n",
      "        10.3,\n",
      "        10.85,\n",
      "        9.05,\n",
      "        12.46,\n",
      "        8.64,\n",
      "        8.19,\n",
      "        9.47,\n",
      "        11.8,\n",
      "        12.86,\n",
      "        10.57\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.07,\n",
      "        0.04,\n",
      "        0.15,\n",
      "        0.07,\n",
      "        -0.33,\n",
      "        -0.06,\n",
      "        0.07,\n",
      "        -0.05,\n",
      "        0.21,\n",
      "        -0.04,\n",
      "        -0.13,\n",
      "        -0.02,\n",
      "        0.06,\n",
      "        -0.17,\n",
      "        -0.05\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.7\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": 0.33\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": 0.32\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.31\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -0.38\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.28\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": -0.09\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": -0.08\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"meta-llama/llama-4-scout\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        12.96,\n",
      "        13.69,\n",
      "        11.23,\n",
      "        13.06,\n",
      "        13.39,\n",
      "        9.98,\n",
      "        10.5,\n",
      "        8.8,\n",
      "        9.96,\n",
      "        8.53,\n",
      "        8.21,\n",
      "        9.56,\n",
      "        11.31,\n",
      "        12.19,\n",
      "        10.87\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.05,\n",
      "        0.0,\n",
      "        0.14,\n",
      "        0.03,\n",
      "        0.42,\n",
      "        -0.12,\n",
      "        -0.03,\n",
      "        -0.09,\n",
      "        -0.46,\n",
      "        -0.03,\n",
      "        -0.08,\n",
      "        0.08,\n",
      "        -0.09,\n",
      "        -0.32,\n",
      "        0.13\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.27\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": 0.24\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.17\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": 0.09\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -0.56\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": -0.14\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.09\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.08\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Llama 3.1 70B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        13.07,\n",
      "        14.02,\n",
      "        9.9,\n",
      "        12.8,\n",
      "        11.46,\n",
      "        9.68,\n",
      "        10.2,\n",
      "        8.14,\n",
      "        12.19,\n",
      "        7.96,\n",
      "        7.65,\n",
      "        8.63,\n",
      "        11.75,\n",
      "        14.04,\n",
      "        10.18\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        0.05,\n",
      "        0.18,\n",
      "        -0.28,\n",
      "        -0.03,\n",
      "        -0.07,\n",
      "        -0.17,\n",
      "        -0.1,\n",
      "        -0.25,\n",
      "        0.2,\n",
      "        -0.19,\n",
      "        -0.21,\n",
      "        -0.21,\n",
      "        0.13,\n",
      "        0.29,\n",
      "        -0.1\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 0.71\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.64\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.51\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.3\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.8\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": -0.56\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.56\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.45\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Llama 3.1 8B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        12.85,\n",
      "        13.57,\n",
      "        9.81,\n",
      "        12.58,\n",
      "        10.99,\n",
      "        9.5,\n",
      "        10.07,\n",
      "        8.17,\n",
      "        10.99,\n",
      "        7.9,\n",
      "        7.53,\n",
      "        8.65,\n",
      "        11.39,\n",
      "        13.1,\n",
      "        9.99\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.01,\n",
      "        0.06,\n",
      "        -0.27,\n",
      "        -0.08,\n",
      "        -0.23,\n",
      "        -0.18,\n",
      "        -0.1,\n",
      "        -0.21,\n",
      "        -0.18,\n",
      "        -0.17,\n",
      "        -0.22,\n",
      "        -0.18,\n",
      "        0.05,\n",
      "        0.02,\n",
      "        -0.13\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": 0.96\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.85\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.73\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": 0.44\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -0.53\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": -0.44\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.37\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": -0.16\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Mistral Small 3.1 24B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        12.21,\n",
      "        12.25,\n",
      "        10.56,\n",
      "        12.48,\n",
      "        12.21,\n",
      "        8.99,\n",
      "        9.74,\n",
      "        7.99,\n",
      "        9.31,\n",
      "        7.53,\n",
      "        7.53,\n",
      "        8.75,\n",
      "        10.46,\n",
      "        11.98,\n",
      "        10.03\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.21,\n",
      "        -0.33,\n",
      "        0.03,\n",
      "        -0.08,\n",
      "        0.25,\n",
      "        -0.29,\n",
      "        -0.18,\n",
      "        -0.22,\n",
      "        -0.51,\n",
      "        -0.24,\n",
      "        -0.17,\n",
      "        -0.09,\n",
      "        -0.26,\n",
      "        -0.32,\n",
      "        -0.08\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.49\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": 0.3\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": 0.29\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Emotional Depth\",\n",
      "        \"relativeScore\": 0.27\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -0.34\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": -0.29\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": -0.2\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.13\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Mistral Small 24B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        11.83,\n",
      "        11.81,\n",
      "        10.26,\n",
      "        12.02,\n",
      "        12.01,\n",
      "        8.9,\n",
      "        9.53,\n",
      "        8.14,\n",
      "        9.68,\n",
      "        7.84,\n",
      "        7.65,\n",
      "        8.48,\n",
      "        10.43,\n",
      "        12.65,\n",
      "        9.85\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.28,\n",
      "        -0.4,\n",
      "        -0.03,\n",
      "        -0.2,\n",
      "        0.25,\n",
      "        -0.27,\n",
      "        -0.2,\n",
      "        -0.13,\n",
      "        -0.43,\n",
      "        -0.1,\n",
      "        -0.09,\n",
      "        -0.12,\n",
      "        -0.25,\n",
      "        -0.13,\n",
      "        -0.09\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.26\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 0.11\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Believable Characters\",\n",
      "        \"relativeScore\": 0.11\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": 0.08\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -0.83\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.4\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": -0.38\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.32\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Llama 3.2 3B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        11.68,\n",
      "        12.18,\n",
      "        8.97,\n",
      "        11.41,\n",
      "        9.32,\n",
      "        8.25,\n",
      "        8.9,\n",
      "        6.92,\n",
      "        9.44,\n",
      "        6.9,\n",
      "        6.65,\n",
      "        7.52,\n",
      "        9.81,\n",
      "        11.81,\n",
      "        8.82\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.29,\n",
      "        -0.29,\n",
      "        -0.37,\n",
      "        -0.33,\n",
      "        -0.47,\n",
      "        -0.38,\n",
      "        -0.34,\n",
      "        -0.4,\n",
      "        -0.46,\n",
      "        -0.34,\n",
      "        -0.34,\n",
      "        -0.35,\n",
      "        -0.37,\n",
      "        -0.33,\n",
      "        -0.34\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.85\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": 0.34\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.21\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Elegant Prose\",\n",
      "        \"relativeScore\": 0.17\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.95\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.45\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Amateurish Prose\",\n",
      "        \"relativeScore\": -0.3\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -0.17\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"openai/gpt-3.5-turbo-0613\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        11.62,\n",
      "        12.11,\n",
      "        7.48,\n",
      "        10.91,\n",
      "        7.26,\n",
      "        7.56,\n",
      "        8.22,\n",
      "        6.16,\n",
      "        12.47,\n",
      "        5.87,\n",
      "        5.81,\n",
      "        6.62,\n",
      "        8.24,\n",
      "        13.48,\n",
      "        7.86\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.28,\n",
      "        -0.26,\n",
      "        -0.59,\n",
      "        -0.4,\n",
      "        -0.7,\n",
      "        -0.48,\n",
      "        -0.44,\n",
      "        -0.51,\n",
      "        0.42,\n",
      "        -0.5,\n",
      "        -0.47,\n",
      "        -0.49,\n",
      "        -0.59,\n",
      "        0.26,\n",
      "        -0.5\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.78\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": 0.33\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": 0.3\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": 0.13\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Positivity Bias\",\n",
      "        \"relativeScore\": -0.46\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": -0.43\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": -0.11\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": -0.09\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Llama 3.2 1B\": {\n",
      "    \"absoluteRadar\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        8.97,\n",
      "        7.19,\n",
      "        7.49,\n",
      "        8.92,\n",
      "        6.03,\n",
      "        6.75,\n",
      "        6.93,\n",
      "        6.05,\n",
      "        6.8,\n",
      "        6.24,\n",
      "        5.48,\n",
      "        5.58,\n",
      "        8.38,\n",
      "        10.43,\n",
      "        6.59\n",
      "      ]\n",
      "    },\n",
      "    \"relativeRadarLog\": {\n",
      "      \"labels\": [\n",
      "        \"Sentence Flow\",\n",
      "        \"Coherent\",\n",
      "        \"Descriptive Imagery\",\n",
      "        \"Consistent Voice & Tone\",\n",
      "        \"Instruction Following\",\n",
      "        \"Avoids Amateurish Prose\",\n",
      "        \"Elegant Prose\",\n",
      "        \"Show-Don't-Tell\",\n",
      "        \"Pacing\",\n",
      "        \"Creativity\",\n",
      "        \"Strong Dialogue\",\n",
      "        \"Emotional Depth\",\n",
      "        \"Avoids Positivity Bias\",\n",
      "        \"Avoids Purple Prose\",\n",
      "        \"Believable Characters\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        -0.67,\n",
      "        -0.85,\n",
      "        -0.55,\n",
      "        -0.66,\n",
      "        -0.78,\n",
      "        -0.57,\n",
      "        -0.61,\n",
      "        -0.5,\n",
      "        -0.74,\n",
      "        -0.41,\n",
      "        -0.5,\n",
      "        -0.61,\n",
      "        -0.56,\n",
      "        -0.56,\n",
      "        -0.64\n",
      "      ]\n",
      "    },\n",
      "    \"strengths\": [\n",
      "      {\n",
      "        \"criterion\": \"Creativity\",\n",
      "        \"relativeScore\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Show-Don't-Tell\",\n",
      "        \"relativeScore\": 0.61\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Strong Dialogue\",\n",
      "        \"relativeScore\": 0.6\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Descriptive Imagery\",\n",
      "        \"relativeScore\": 0.31\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Avoids Purple Prose\",\n",
      "        \"relativeScore\": 0.26\n",
      "      }\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      {\n",
      "        \"criterion\": \"Coherent\",\n",
      "        \"relativeScore\": -1.0\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Instruction Following\",\n",
      "        \"relativeScore\": -0.69\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Pacing\",\n",
      "        \"relativeScore\": -0.48\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Sentence Flow\",\n",
      "        \"relativeScore\": -0.23\n",
      "      },\n",
      "      {\n",
      "        \"criterion\": \"Consistent Voice & Tone\",\n",
      "        \"relativeScore\": -0.19\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "};\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_chart_data_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 494\u001b[0m\n\u001b[0;32m    492\u001b[0m chart_data_str \u001b[38;5;241m=\u001b[39m format_model_charts_js_object(df, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28mprint\u001b[39m(chart_data_str)\n\u001b[1;32m--> 494\u001b[0m \u001b[43msave_chart_data_str\u001b[49m(chart_data_str)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'save_chart_data_str' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "def build_creative_criteria_df(\n",
    "    runs_file_path=\"creative_bench_runs.json\",\n",
    "    min_occurrences=5,\n",
    "    n_neighbors=6\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads the runs JSON, extracts per-model creative criteria scores, applies transformations\n",
    "    (inverting negative criteria, combining certain criteria, etc.), calculates relative\n",
    "    scores, and returns a DataFrame containing both absolute and relative columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Columns = ['model', 'overall_score', <absolute criteria...>, <relative_criteria...>]\n",
    "    \"\"\"\n",
    "    # -- 1) Load JSON data --\n",
    "    if not os.path.exists(runs_file_path):\n",
    "        print(f\"File not found: {runs_file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    with open(runs_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    if not data:\n",
    "        print(f\"No data in file: {runs_file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # -- 2) Functions from your pipeline, condensed --\n",
    "\n",
    "    def extract_model_results(data_dict):\n",
    "        \"\"\"\n",
    "        For each model run, gather:\n",
    "          - overall_score (eqbench_creative_score)\n",
    "          - criteria_aggregates = mean of all judge_scores per criterion\n",
    "        Returns {model_name: {overall_score, criteria_aggregates:{crit: val}}}.\n",
    "        \"\"\"\n",
    "        models_data = {}\n",
    "        for run_key, run_data in data_dict.items():\n",
    "            model_name = run_data.get(\"test_model\", run_key)\n",
    "            overall_score = run_data.get('results', {}).get('benchmark_results', {}).get('eqbench_creative_score', None)\n",
    "\n",
    "            criteria_scores = defaultdict(list)\n",
    "            if 'creative_tasks' in run_data:\n",
    "                for iteration_dict in run_data['creative_tasks'].values():\n",
    "                    for prompt_info in iteration_dict.values():\n",
    "                        for mod_data in prompt_info.get('results_by_modifier', {}).values():\n",
    "                            if 'judge_scores' in mod_data:\n",
    "                                for crit, score in mod_data['judge_scores'].items():\n",
    "                                    # Coerce to float if numeric and check that score <= 20\n",
    "                                    try:\n",
    "                                        score_value = float(score)\n",
    "                                        if score_value <= 20:  # Only include scores that are <= 20\n",
    "                                            criteria_scores[crit].append(score_value)\n",
    "                                    except (ValueError, TypeError):\n",
    "                                        pass\n",
    "\n",
    "            criteria_aggregates = {\n",
    "                c: np.mean(scores) if scores else np.nan\n",
    "                for c, scores in criteria_scores.items()\n",
    "            }\n",
    "\n",
    "            models_data[model_name] = {\n",
    "                'overall_score': overall_score,\n",
    "                'criteria_aggregates': criteria_aggregates\n",
    "            }\n",
    "        return models_data\n",
    "\n",
    "    def create_models_df(models_data_dict, min_occ=5):\n",
    "        \"\"\"\n",
    "        Creates an initial DataFrame with columns:\n",
    "          model, overall_score, and each included criterion (that meets min occurrences).\n",
    "        \"\"\"\n",
    "        # List of included criteria (original approach)\n",
    "        included_criteria = [\n",
    "            \"Adherence to Instructions\",\n",
    "            \"Believable Character Actions\",\n",
    "            \"Nuanced Characters\",\n",
    "            \"Consistent Voice/Tone of Writing\",\n",
    "            \"Imagery and Descriptive Quality\",\n",
    "            \"Elegant Prose\",\n",
    "            \"Emotionally Engaging\",\n",
    "            \"Emotionally Complex\",\n",
    "            \"Coherent\",\n",
    "            \"Meandering\",\n",
    "            \"Weak Dialogue\",\n",
    "            \"Tell-Don't-Show\",\n",
    "            \"Unsurprising or Uncreative\",\n",
    "            \"Amateurish\",\n",
    "            \"Purple Prose\",\n",
    "            \"Overwrought\",\n",
    "            \"Incongruent Ending Positivity\",\n",
    "            \"Unearned Transformations\",\n",
    "            \"Well-earned Lightness or Darkness\",\n",
    "            \"Sentences Flow Naturally\",\n",
    "            \"Overall Reader Engagement\",\n",
    "            \"Overall Impression\"\n",
    "        ]\n",
    "\n",
    "        # Count occurrences\n",
    "        criteria_counts = defaultdict(int)\n",
    "        all_criteria_in_data = set()\n",
    "        for m_data in models_data_dict.values():\n",
    "            for c in m_data['criteria_aggregates'].keys():\n",
    "                all_criteria_in_data.add(c)\n",
    "                # see if it's in included_criteria (case-insensitive match)\n",
    "                for inc in included_criteria:\n",
    "                    if c.lower() == inc.lower():\n",
    "                        criteria_counts[c] += 1\n",
    "                        break\n",
    "\n",
    "        valid_criteria = {\n",
    "            c for c in criteria_counts\n",
    "            if criteria_counts[c] >= min_occ\n",
    "        }\n",
    "\n",
    "        # Build rows\n",
    "        rows = []\n",
    "        for model, model_data in models_data_dict.items():\n",
    "            row = {\n",
    "                'model': model,\n",
    "                'overall_score': model_data['overall_score']\n",
    "            }\n",
    "            for c in valid_criteria:\n",
    "                row[c] = model_data['criteria_aggregates'].get(c, np.nan)\n",
    "            rows.append(row)\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        df = df.dropna(subset=['overall_score'])\n",
    "        if not df.empty:\n",
    "            df = df.sort_values('overall_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def preprocess_criteria_scores(df):\n",
    "        \"\"\"\n",
    "        Invert negative criteria (20 - score).\n",
    "        \"\"\"\n",
    "        negative_criteria = [\n",
    "            \"Unearned Transformations\",\n",
    "            \"Incongruent Ending Positivity\",\n",
    "            \"Overwrought\",\n",
    "            \"Purple Prose\",\n",
    "            \"Amateurish\",\n",
    "            \"Unsurprising or Uncreative\",\n",
    "            \"Tell-Don't-Show\",\n",
    "            \"Weak Dialogue\",\n",
    "            \"Meandering\"\n",
    "        ]\n",
    "        processed_df = df.copy()\n",
    "        inverted_map = {}\n",
    "        for col in processed_df.columns:\n",
    "            if col not in ['model', 'overall_score']:\n",
    "                # check case-insensitive match\n",
    "                if any(n.lower() == col.lower() for n in negative_criteria):\n",
    "                    processed_df[col] = 20 - processed_df[col]\n",
    "                    new_col = f\"Inverted_{col}\"\n",
    "                    processed_df.rename(columns={col: new_col}, inplace=True)\n",
    "                    inverted_map[col] = new_col\n",
    "        return processed_df, inverted_map\n",
    "\n",
    "    def transform_criteria(df, inverted_map, apply_transformations=True):\n",
    "        \"\"\"\n",
    "        Rename, combine, ignore certain criteria.\n",
    "        \"\"\"\n",
    "        if not apply_transformations:\n",
    "            return df\n",
    "\n",
    "        transformed_df = df.copy()\n",
    "\n",
    "        # Criteria to ignore\n",
    "        ignore_criteria = [\"Overall Impression\", \"Overall Reader Engagement\"]\n",
    "        to_drop = []\n",
    "        for crit in ignore_criteria:\n",
    "            # check if it's in the DF or if it was inverted\n",
    "            if crit in transformed_df.columns:\n",
    "                to_drop.append(crit)\n",
    "            elif crit in inverted_map and inverted_map[crit] in transformed_df.columns:\n",
    "                to_drop.append(inverted_map[crit])\n",
    "\n",
    "        if to_drop:\n",
    "            transformed_df.drop(columns=to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "        # Rename map\n",
    "        rename_map = {\n",
    "            \"Inverted_Weak Dialogue\": \"Strong Dialogue\",\n",
    "            \"Inverted_Tell-Don't-Show\": \"Show-Don't-Tell\",\n",
    "            \"Inverted_Unsurprising or Uncreative\": \"Creativity\",\n",
    "            \"Inverted_Amateurish\": \"Avoids Amateurish Prose\",\n",
    "            \"Adherence to Instructions\": \"Instruction Following\",\n",
    "            \"Inverted_Meandering\": \"Pacing\",\n",
    "            \"Imagery and Descriptive Quality\": \"Descriptive Imagery\",\n",
    "            \"Consistent Voice/Tone of Writing\": \"Consistent Voice & Tone\",\n",
    "            \"Sentences Flow Naturally\": \"Sentence Flow\",\n",
    "        }\n",
    "        for old_name, new_name in rename_map.items():\n",
    "            if old_name in transformed_df.columns:\n",
    "                transformed_df.rename(columns={old_name: new_name}, inplace=True)\n",
    "\n",
    "        # Combine\n",
    "        combinations = {\n",
    "            \"Emotional Depth\": [\"Emotionally Complex\", \"Emotionally Engaging\"],\n",
    "            \"Avoids Positivity Bias\": [\"Well-earned Lightness or Darkness\", \"Inverted_Unearned Transformations\", \"Inverted_Incongruent Ending Positivity\"],\n",
    "            \"Avoids Purple Prose\": [\"Inverted_Overwrought\", \"Inverted_Purple Prose\"],\n",
    "            \"Believable Characters\": [\"Nuanced Characters\", \"Believable Character Actions\"],\n",
    "        }\n",
    "        drop_after = []\n",
    "        for new_name, src_cols in combinations.items():\n",
    "            existing_cols = [c for c in src_cols if c in transformed_df.columns]\n",
    "            if not existing_cols:\n",
    "                continue\n",
    "            transformed_df[new_name] = transformed_df[existing_cols].mean(axis=1, skipna=True)\n",
    "            drop_after.extend(existing_cols)\n",
    "        # drop the combined ones\n",
    "        drop_after = list(set(drop_after))\n",
    "        for col in drop_after:\n",
    "            if col in transformed_df.columns and col not in combinations:\n",
    "                # ensure we don't accidentally drop the newly created column\n",
    "                if col not in combinations.keys():\n",
    "                    transformed_df.drop(columns=[col], inplace=True, errors='ignore')\n",
    "\n",
    "        return transformed_df\n",
    "\n",
    "    def calculate_relative_scores(df, n_neighbors=3):\n",
    "        \"\"\"\n",
    "        For each model, compare each criterion to the average among the N neighbors above/below it.\n",
    "        Adds columns named 'relative_<criterion>'.\n",
    "        \"\"\"\n",
    "        if len(df) < 2:\n",
    "            # not enough models\n",
    "            base = df[['model', 'overall_score']].copy()\n",
    "            return base\n",
    "\n",
    "        # ensure sorted\n",
    "        sorted_df = df.sort_values('overall_score', ascending=False).reset_index(drop=True)\n",
    "        criteria_cols = [c for c in sorted_df.columns if c not in ['model', 'overall_score']]\n",
    "\n",
    "        relative_df = sorted_df[['model', 'overall_score']].copy()\n",
    "\n",
    "        for idx, row in sorted_df.iterrows():\n",
    "            start_i = max(0, idx - n_neighbors)\n",
    "            end_i = min(len(sorted_df) - 1, idx + n_neighbors)\n",
    "            neighbor_indices = [i for i in range(start_i, end_i + 1) if i != idx]\n",
    "\n",
    "            for crit in criteria_cols:\n",
    "                cur_val = row[crit]\n",
    "                if pd.isna(cur_val):\n",
    "                    rel_val = np.nan\n",
    "                else:\n",
    "                    neighbor_vals = sorted_df.loc[neighbor_indices, crit].dropna()\n",
    "                    if len(neighbor_vals) > 0:\n",
    "                        rel_val = cur_val - neighbor_vals.mean()\n",
    "                    else:\n",
    "                        rel_val = np.nan\n",
    "                relative_df.loc[idx, f'relative_{crit}'] = rel_val\n",
    "\n",
    "        return relative_df\n",
    "\n",
    "    # -- 3) Build the DataFrame --\n",
    "    # Step A: extract per-model aggregates\n",
    "    models_data_dict = extract_model_results(data)\n",
    "\n",
    "    # Step B: initial DF\n",
    "    df_raw = create_models_df(models_data_dict, min_occ=min_occurrences)\n",
    "    if df_raw.empty:\n",
    "        print(\"No data after creating models DF. Returning empty DataFrame.\")\n",
    "        return df_raw\n",
    "\n",
    "    # Step C: invert negative\n",
    "    df_processed, inverted_map = preprocess_criteria_scores(df_raw)\n",
    "\n",
    "    # Step D: transform\n",
    "    df_transformed = transform_criteria(df_processed, inverted_map, apply_transformations=True)\n",
    "\n",
    "    # Step E: relative\n",
    "    df_rel = calculate_relative_scores(df_transformed, n_neighbors=n_neighbors)\n",
    "\n",
    "    # Step F: merge\n",
    "    full_df = pd.merge(\n",
    "        df_transformed, df_rel,\n",
    "        on=['model', 'overall_score'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    return full_df\n",
    "\n",
    "\n",
    "def format_model_charts_js_object(\n",
    "    full_df,\n",
    "    top_n=5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a single JS object definition of the form:\n",
    "\n",
    "        const chartData = {\n",
    "          \"DisplayModelName\": {\n",
    "            \"absoluteRadar\": {\n",
    "              \"labels\": [...],\n",
    "              \"values\": [...]\n",
    "            },\n",
    "            \"relativeRadarLog\": {\n",
    "              \"labels\": [...],\n",
    "              \"values\": [...]\n",
    "            },\n",
    "            \"strengths\": [...],\n",
    "            \"weaknesses\": [...]\n",
    "          },\n",
    "          \"OtherModelName\": { ... }\n",
    "        };\n",
    "\n",
    "    - Skips any model in MODELS_TO_IGNORE.\n",
    "    - Renames model with MODEL_NAME_SUBS (model -> substituted name).\n",
    "    - top_n controls how many strengths/weaknesses to include.\n",
    "    - Rounds all numeric values to 2 decimals.\n",
    "    - Advanced normalization: Sets min->-1, median->0, max->1 with proportional scaling.\n",
    "\n",
    "    Args:\n",
    "        full_df (pd.DataFrame): DataFrame containing absolute & relative criteria columns\n",
    "                                (like from build_creative_criteria_df()).\n",
    "        top_n (int): How many top/bottom items to list as strengths/weaknesses.\n",
    "        MODEL_NAME_SUBS (dict): e.g. {\"openai/gpt-4\":\"GPT-4\"}\n",
    "        MODELS_TO_IGNORE (list): e.g. [\"mistralai/ministral-3b\"]\n",
    "\n",
    "    Returns:\n",
    "        str: Valid JS code as a string:\n",
    "             const chartData = { \"ModelA\": {...}, \"ModelB\": {...} };\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import math\n",
    "    import numpy as np\n",
    "\n",
    "    def get_updated_model_name(original: str) -> str:\n",
    "        # Same logic you use in your code:\n",
    "        return MODEL_NAME_SUBS.get(original, original)\n",
    "\n",
    "    def signed_log(x):\n",
    "        \"\"\"Signed log10 transform: sign(x)*log10(|x| + 1).\"\"\"\n",
    "        if x == 0:\n",
    "            return 0.0\n",
    "        return math.copysign(math.log10(abs(x) + 1), x)\n",
    "\n",
    "    # Identify columns\n",
    "    absolute_cols = [\n",
    "        c for c in full_df.columns\n",
    "        if c not in [\"model\", \"overall_score\"] and not c.startswith(\"relative_\")\n",
    "    ]\n",
    "    relative_cols = [c for c in full_df.columns if c.startswith(\"relative_\")]\n",
    "\n",
    "    # Build a Python dict to represent the final JS object\n",
    "    chart_data_dict = {}\n",
    "\n",
    "    for _, row in full_df.iterrows():\n",
    "        original_name = row[\"model\"]\n",
    "        if original_name in MODELS_TO_IGNORE:\n",
    "            continue\n",
    "\n",
    "        display_name = get_updated_model_name(original_name)\n",
    "\n",
    "        # (1) Gather absolute radar data\n",
    "        abs_labels = []\n",
    "        abs_values = []\n",
    "        for col in absolute_cols:\n",
    "            val = row[col]\n",
    "            if pd.isna(val):\n",
    "                continue\n",
    "            abs_labels.append(col)\n",
    "            abs_values.append(round(float(val), 2))  # round to 2 decimals\n",
    "\n",
    "        # (2) Gather relative radar (log scale) data\n",
    "        rel_labels = []\n",
    "        rel_values_log = []\n",
    "        for col in relative_cols:\n",
    "            val = row[col]\n",
    "            if pd.isna(val):\n",
    "                continue\n",
    "            base_name = col.replace(\"relative_\", \"\")\n",
    "            log_val = signed_log(float(val))\n",
    "            rel_labels.append(base_name)\n",
    "            rel_values_log.append(round(log_val, 2))  # round to 2 decimals\n",
    "\n",
    "        # (3) Strengths & Weaknesses (raw relative values)\n",
    "        rel_pairs = []\n",
    "        for col in relative_cols:\n",
    "            val = row[col]\n",
    "            if pd.isna(val):\n",
    "                continue\n",
    "            base_name = col.replace(\"relative_\", \"\")\n",
    "            rel_pairs.append((base_name, float(val)))\n",
    "        \n",
    "        # Skip if not enough relative pairs\n",
    "        if len(rel_pairs) < 3:  # Need at least 3 values for min/median/max\n",
    "            continue\n",
    "            \n",
    "        # Sort the values for finding median\n",
    "        sorted_values = sorted([pair[1] for pair in rel_pairs])\n",
    "        \n",
    "        # Find the min, max, and median values\n",
    "        min_value = sorted_values[0]\n",
    "        max_value = sorted_values[-1]\n",
    "        \n",
    "        # Find the median (middle value with equal number above and below)\n",
    "        n = len(sorted_values)\n",
    "        if n % 2 == 1:  # Odd number of values\n",
    "            median_value = sorted_values[n // 2]\n",
    "        else:  # Even number of values\n",
    "            median_value = (sorted_values[n // 2 - 1] + sorted_values[n // 2]) / 2\n",
    "        \n",
    "        # Create normalized pairs with min->-1, median->0, max->1\n",
    "        normalized_pairs = []\n",
    "        \n",
    "        # Handle edge cases\n",
    "        if min_value == max_value:  # All values are the same\n",
    "            normalized_pairs = [(crit, 0.0) for crit, val in rel_pairs]\n",
    "        elif min_value == median_value == max_value:  # All values are the same\n",
    "            normalized_pairs = [(crit, 0.0) for crit, val in rel_pairs]\n",
    "        elif min_value == median_value:  # Only two distinct values\n",
    "            normalized_pairs = [\n",
    "                (crit, -1.0 if val == min_value else 1.0) \n",
    "                for crit, val in rel_pairs\n",
    "            ]\n",
    "        elif median_value == max_value:  # Only two distinct values\n",
    "            normalized_pairs = [\n",
    "                (crit, -1.0 if val == min_value else 1.0) \n",
    "                for crit, val in rel_pairs\n",
    "            ]\n",
    "        else:\n",
    "            # Normal case: three different anchor points\n",
    "            for criterion, value in rel_pairs:\n",
    "                if value <= median_value:\n",
    "                    # Scale from min (-1) to median (0)\n",
    "                    if median_value > min_value:  # Avoid division by zero\n",
    "                        norm_val = -1.0 + (value - min_value) * (1.0) / (median_value - min_value)\n",
    "                    else:\n",
    "                        norm_val = -1.0\n",
    "                else:\n",
    "                    # Scale from median (0) to max (1)\n",
    "                    if max_value > median_value:  # Avoid division by zero\n",
    "                        norm_val = 0.0 + (value - median_value) * (1.0) / (max_value - median_value)\n",
    "                    else:\n",
    "                        norm_val = 1.0\n",
    "                        \n",
    "                normalized_pairs.append((criterion, norm_val))\n",
    "            \n",
    "        # Sort by normalized value (ascending)\n",
    "        normalized_pairs.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # Get top_n weaknesses (lowest values) and top_n strengths (highest values)\n",
    "        weaknesses = normalized_pairs[:top_n]\n",
    "        strengths = normalized_pairs[-top_n:]\n",
    "        strengths.reverse()  # Show highest first\n",
    "        \n",
    "        # Round normalized values to 2 decimal places for output\n",
    "        strengths_list = [\n",
    "            {\"criterion\": crit, \"relativeScore\": round(val, 2)}\n",
    "            for (crit, val) in strengths\n",
    "        ]\n",
    "        weaknesses_list = [\n",
    "            {\"criterion\": crit, \"relativeScore\": round(val, 2)}\n",
    "            for (crit, val) in weaknesses\n",
    "        ]\n",
    "\n",
    "        # Assemble the data structure for this model\n",
    "        chart_data_dict[display_name] = {\n",
    "            \"absoluteRadar\": {\n",
    "                \"labels\": abs_labels,\n",
    "                \"values\": abs_values\n",
    "            },\n",
    "            \"relativeRadarLog\": {\n",
    "                \"labels\": rel_labels,\n",
    "                \"values\": rel_values_log\n",
    "            },\n",
    "            \"strengths\": strengths_list,\n",
    "            \"weaknesses\": weaknesses_list\n",
    "        }\n",
    "\n",
    "    # Now produce valid JS code\n",
    "    js_object_str = json.dumps(chart_data_dict, indent=2)\n",
    "\n",
    "    # Return the final code as a string\n",
    "    return f\"const chartData = {js_object_str};\", js_object_str\n",
    "\n",
    "\n",
    "df = build_creative_criteria_df(\n",
    "    runs_file_path=\"creative_bench_runs.json\",\n",
    "    #runs_file_path=\"repro_testing.json\",\n",
    "    min_occurrences=5,\n",
    "    n_neighbors=10\n",
    ")\n",
    "chart_data_str = format_model_charts_js_object(df, top_n=5)\n",
    "print(chart_data_str)\n",
    "save_chart_data_str(chart_data_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chart data saved as raw string to chart_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def save_chart_data_str(chart_data_str, filename=\"chart_data.json\"):\n",
    "    \"\"\"Save chart data string to a JSON file.\"\"\"\n",
    "    try:\n",
    "        # If chart_data_str is already a JSON string, parse and re-save for proper formatting\n",
    "        if isinstance(chart_data_str, str):\n",
    "            # Try to parse as JSON to ensure it's valid\n",
    "            data = json.loads(chart_data_str)\n",
    "        else:\n",
    "            data = chart_data_str\n",
    "        \n",
    "        # Save to JSON file with proper formatting\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Chart data saved to {filename}\")\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        # If it's not valid JSON, save as raw string\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(chart_data_str)\n",
    "        print(f\"Chart data saved as raw string to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving chart data: {e}\")\n",
    "\n",
    "# ... existing code ...\n",
    "chart_data_str = format_model_charts_js_object(df, top_n=5)\n",
    "save_chart_data_str(chart_data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
